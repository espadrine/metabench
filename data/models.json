{
  "models": [
    {
      "name": "GPT-5.1 Codex",
      "company": "OpenAI",
      "url": "https://platform.openai.com/docs/models/gpt-5.1-codex",
      "release_date": "2025-11-12",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool", "image"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "LiveCodeBench",
          "score": 85.5,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-codex"
        },
        {
          "name": "Terminal-Bench",
          "score": 56.3,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-codex"
        },
        {
          "name": "SWE-bench Verified",
          "score": 70.4,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-codex"
        }
      ]
    },
    {
      "name": "GPT-5.1 High",
      "company": "OpenAI",
      "url": "https://openai.com/index/gpt-5-1/",
      "release_date": "2025-11-12",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 81,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 70,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.3,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 88.1,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "AIME 2025",
          "score": 94.0,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "FrontierMath (with tools)",
          "score": 26.7,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 85.4,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 67.0,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 95.6,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 77.9,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 90.0,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "SAGE",
          "score": 43.2,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "Finance Agent",
          "score": 55.9,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "CorpFin",
          "score": 64.6,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "CaseLaw",
          "score": 71.4,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "TaxEval",
          "score": 71.6,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "MortgageTax",
          "score": 61.4,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "AIME 2024+2025",
          "score": 93.3,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "MGSM",
          "score": 92.9,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "LegalBench",
          "score": 83.9,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "MedQA",
          "score": 96.4,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.6,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "MMLU Pro",
          "score": 86.4,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "MMMU",
          "score": 83.2,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "LiveCodeBench",
          "score": 86.5,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "IOI",
          "score": 21.5,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "Terminal-Bench",
          "score": 47.5,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "SWE-bench Verified",
          "score": 67.2,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "Vals Index",
          "score": 61.1,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "Vals Multimodal Index",
          "score": 59.7,
          "source": "https://www.vals.ai/models/openai_gpt-5.1-2025-11-13"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 69.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 57.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 94,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 87,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 87.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 26.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 86.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 43.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 72.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 75,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 42.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 81.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 26.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ARC AGI 2",
          "score": 17.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 88.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 94.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MathArena Apex",
          "score": 1.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 80.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot Pro",
          "score": 3.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 69.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.147,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 80.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench Pro",
          "score": 2243.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 47.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 80.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VendingBench 2",
          "score": 1473.43,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 50.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 34.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMLU",
          "score": 91.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 90.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 61.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 81.9,
          "source": "https://x.ai/news/grok-4-1-fast"
        }
      ]
    },
    {
      "name": "GPT-5.1 Medium",
      "company": "OpenAI",
      "url": "https://openai.com/index/gpt-5-1/",
      "release_date": "2025-11-12",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        }
      ]
    },
    {
      "name": "GPT-5.1 Low",
      "company": "OpenAI",
      "url": "https://openai.com/index/gpt-5-1/",
      "release_date": "2025-11-12",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        }
      ]
    },
    {
      "name": "GPT-5.1 None",
      "company": "OpenAI",
      "url": "https://openai.com/index/gpt-5-1/",
      "release_date": "2025-11-12",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 5,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 42.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 35.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 38,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 80.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 64.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 49.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 36.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 38,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 43.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 44,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 21.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 46.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 Codex High",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-upgrades-to-codex/",
      "release_date": "2025-09-15",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 77,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 68,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 74.5,
          "source": "https://openai.com/index/introducing-upgrades-to-codex/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 74.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 68.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 53.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 98.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 86.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 25.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 84,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 40.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 98.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 74.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 69,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 35.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 86.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 High",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 85,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "SWE-bench Verified",
          "score": 74.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.8,
          "source": "https://openai.com/index/introducing-upgrades-to-codex/"
        },
        {
          "name": "Aider",
          "score": 88,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "AIME 2025",
          "score": 94.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FrontierMath (with tools)",
          "score": 26.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 24.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "HMMT 2025",
          "score": 93.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 84.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 78.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 81.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 84.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 65.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 112,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 69.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 64,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 99,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 62.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 81.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 96.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 95.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 256k",
          "score": 86.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 78.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 73.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 90,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 88.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 86.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FActScore hallucination rate",
          "score": 2.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.8,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Terminal-Bench",
          "score": 43.8,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 81.1,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 62.6,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 96.7,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025",
          "score": 94.6,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 99.6,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMLU",
          "score": 89.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMU",
          "score": 84.2,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Finance Agent",
          "score": 46.9,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "SWE-bench Verified",
          "score": 74.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 43.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 73,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 54.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 65,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 76.4,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 77.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 35.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 80.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 63.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 94,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 87,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 85,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 26.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 85,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 43,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 73,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 76,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 85,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 31,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 69,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "AIME 2025",
          "score": 94.6,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "HMMT 2025",
          "score": 93.3,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 24.8,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "LiveCodeBench",
          "score": 86.8,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 26.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 41.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025",
          "score": 94.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 99.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025",
          "score": 93.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025 (with tools)",
          "score": 96.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 76,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU Pro",
          "score": 87.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU-Redux",
          "score": 95.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Longform Writing",
          "score": 71.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HealthBench",
          "score": 67.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp",
          "score": 54.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 63,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Seal-0",
          "score": 51.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FinSearchComp-T3",
          "score": 48.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FRAMES",
          "score": 86,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 74.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Multilingual (with tools)",
          "score": 55.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Multi-SWE-bench (with tools)",
          "score": 39.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SciCode",
          "score": 42.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "LiveCodeBench",
          "score": 87,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "OJ-Bench",
          "score": 56.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Terminal-Bench",
          "score": 43.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HumanEval",
          "score": 93.4,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GPQA",
          "score": 85.7,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.8,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "AIME 2025",
          "score": 94.6,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "FrontierMath (with tools)",
          "score": 26.3,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 84.2,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 62.6,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 96.7,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 81.1,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 90.0,
          "source": "https://openai.com/index/gpt-5-1-for-developers/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 68.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 52.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 94.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 84.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 99.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 95.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 94.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 73.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 75.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 30.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 84.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "BFCL v4 MultiTurn",
          "score": 61.60,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 45.5,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "FRAMES",
          "score": 86.0,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "X Browse",
          "score": 24.2,
          "source": "https://x.ai/news/grok-4-1-fast"
        }
      ]
    },
    {
      "name": "GPT-5 Medium",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 45,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 66.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 49.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 91.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 86.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 84.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 23.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 70.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 41.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 99.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 91.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 91.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 70.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 72.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 36.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 86.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 Low",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 18,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 61.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 46.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 83,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 86,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 80.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 76.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 39.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 98.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 83,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 66.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 58.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 24.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 84.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 Minimal",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 4.4,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "SWE-bench Verified",
          "score": 59,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 43.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 37.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 31.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 80.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 67.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 55.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 38.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 86.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 36.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 31.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 45.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 25,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 17.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 67,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 mini High",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 2,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 84,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "AIME 2025",
          "score": 91.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FrontierMath (with tools)",
          "score": 22.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 16.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "HMMT 2025",
          "score": 87.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 81.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 74.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 75.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 82.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 62.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 75,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 71,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 71.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 62.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 65.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 98.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 60,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 78.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 74.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 84.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 256k",
          "score": 58.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 73.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 64.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 86,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 78.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FActScore hallucination rate",
          "score": 3.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond (with tools)",
          "score": 82.3,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "AIME 2025",
          "score": 91.1,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "HMMT 2025",
          "score": 87.8,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 16.7,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "LiveCodeBench",
          "score": 77.4,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "GPQA",
          "score": 82.3,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 64.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 51.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 90.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 83.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 19.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 83.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 39.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 90.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 75.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 68,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 31.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 68.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 mini Medium",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 2,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 60.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 45.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 85,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 82.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 80.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 69.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 41,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 85,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 71.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 66,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 27,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 71.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Input cost",
          "score": 0.25,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 mini Minimal",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.25,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 2,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 41.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 35,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 46.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 77.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 68.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 54.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 36.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 46.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 45.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 35.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 13.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 31.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Input cost",
          "score": 0.25,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 nano High",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 0.4,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 150,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "AIME 2025",
          "score": 85.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FrontierMath (with tools)",
          "score": 9.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 71.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "HMMT 2025",
          "score": 75.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 75.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 62.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 62.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 66.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 50.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 49,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 54.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 48.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 54.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 56.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 96.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 41,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 62.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 35.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 43.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 256k",
          "score": 34.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 64,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 43.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 80.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 68.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 65.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FActScore hallucination rate",
          "score": 7.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA",
          "score": 71.2,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 51,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 42.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 83.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 78,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 67.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 78.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 36.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 83.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 67.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 41.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 11.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 36.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 nano Medium",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 0.4,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 49.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 42.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 78.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 77.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 67,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 7.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 76.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 33.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 78.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 65.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 40,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 16.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 30.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-5 nano Minimal",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-5/",
      "release_date": "2025-08-07",
      "capabilities": {
        "input": ["text", "image", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 0.4,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 29.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 27.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 27.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 55.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 42.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 47,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 29.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 27.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 32.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 20,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 6.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 25.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "o4-mini",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-o3-and-o4-mini/",
      "release_date": "2025-04-16",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 4,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 16,
          "source": "https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 76,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 60,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 81.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 92.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 75.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 72,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 68.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 19.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 62.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 81.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 36.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 92.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FrontierMath (with tools)",
          "score": 15.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 81.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "HMMT 2025",
          "score": 85,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 81.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 73.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 72,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 79.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 56.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 66,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 68.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 58.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 57.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 44.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 96.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 60.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 70.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 40.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 56.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 62.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 51.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 80,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 79.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 8.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FActScore hallucination rate",
          "score": 38.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 72
        },
        {
          "name": "SWE-bench Verified",
          "score": 69
        },
        {
          "name": "GPQA",
          "score": 81.4,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "o3 (high)",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-o3-and-o4-mini/",
      "release_date": "2025-04-16",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://web.archive.org/web/20250611095744/https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 8,
          "source": "https://web.archive.org/web/20250611095744/https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 54,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 20.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 88.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 72,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 79.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 48.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 69.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 82.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 57.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2024",
          "score": 91.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 88.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 77.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 79.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 20.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 81,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "AIME 2025",
          "score": 88.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FrontierMath (with tools)",
          "score": 15.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 20.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "HMMT 2025",
          "score": 81.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 82.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 76.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 78.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 83.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 64,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 86,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 79.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 60.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 47.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 98.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 64.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 80.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 58.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 55,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 77.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 72.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 88.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 84.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 5.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 6.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FActScore hallucination rate",
          "score": 23.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.1,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Terminal-Bench",
          "score": 30.2,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.3,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Retail",
          "score": 70.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Airline",
          "score": 52,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMLU",
          "score": 88.8,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMU",
          "score": 82.9,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "AIME 2025",
          "score": 88.9,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.1,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "Terminal-Bench",
          "score": 30.2,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.3,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Retail",
          "score": 70.4,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Airline",
          "score": 52,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMLU",
          "score": 88.8,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMU",
          "score": 82.9,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "AIME 2025",
          "score": 88.9,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.3,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "LiveCodeBench",
          "score": 72,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "USAMO 2025",
          "score": 21.7,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "HMMT 2025",
          "score": 77.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "AIME 2025",
          "score": 88.9,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "ARC AGI 2",
          "score": 6.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "Aider",
          "score": 76.9
        },
        {
          "name": "LiveCodeBench",
          "score": 78.4
        },
        {
          "name": "Codeforces",
          "score": 2706
        },
        {
          "name": "GPQA",
          "score": 83.3,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 65.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 52.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 88.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 85.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 20,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 80.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 41,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 99.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 90.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 88.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 71.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 69.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 34.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 80.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "o3-mini",
      "company": "OpenAI",
      "url": "https://openai.com/index/openai-o3-mini/",
      "release_date": "2025-01-31",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.1,
          "source": "https://web.archive.org/web/20250203052753/https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 4.4,
          "source": "https://web.archive.org/web/20250203052753/https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 51,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Codeforces",
          "score": 2073
        },
        {
          "name": "GPQA",
          "score": 77.2,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "SWE-bench Verified",
          "score": 49.3,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "o3-mini (medium)",
      "company": "OpenAI",
      "url": "https://openai.com/index/openai-o3-mini/",
      "release_date": "2025-01-31",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.1,
          "source": "https://web.archive.org/web/20250203052753/https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 4.4,
          "source": "https://web.archive.org/web/20250203052753/https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 48,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Aider",
          "score": 60.4
        },
        {
          "name": "Codeforces",
          "score": 2719
        },
        {
          "name": "AIME 2024",
          "score": 79.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 76.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT 2025",
          "score": 53.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 76.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 65.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        }
      ]
    },
    {
      "name": "GPT-4.1",
      "company": "OpenAI",
      "url": "https://openai.com/index/gpt-4-1/",
      "release_date": "2025-04-14",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://web.archive.org/web/20250417003454/https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 8,
          "source": "https://web.archive.org/web/20250417003454/https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 7.4,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 43,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2025",
          "score": 46.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 66.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "HMMT 2025",
          "score": 28.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 74.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 60.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 56.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 60.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 44.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 34,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 54.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 52.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 46.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 49.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 65.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 56,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 74,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 34,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 57.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 256k",
          "score": 56.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 61.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 58,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 85.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 75.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 78.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FActScore hallucination rate",
          "score": 6.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 54.6,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "Terminal-Bench",
          "score": 30.3,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 66.3,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Retail",
          "score": 68,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Airline",
          "score": 49.4,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMLU",
          "score": 83.7,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMU",
          "score": 74.8,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA",
          "score": 66.3,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "GPT-4.1 mini",
      "company": "OpenAI",
      "url": "https://openai.com/index/gpt-4-1/",
      "release_date": "2025-04-14",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.4,
          "source": "https://web.archive.org/web/20250417003454/https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 1.6,
          "source": "https://web.archive.org/web/20250417003454/https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 9.3,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 42,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2025",
          "score": 40.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA Diamond",
          "score": 65,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 3.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "HMMT 2025",
          "score": 35,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 72.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 58.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 56.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 55.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 42.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 31,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 23.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 31.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 42.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 45.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 54.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 51,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 66,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 44,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 47.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 256k",
          "score": 45.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 61.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 60.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 81.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 68.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "FActScore hallucination rate",
          "score": 10.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA",
          "score": 65,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "GPT-4.1 nano",
      "company": "OpenAI",
      "url": "https://openai.com/index/gpt-4-1/",
      "release_date": "2025-04-14",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.1,
          "source": "https://web.archive.org/web/20250417003454/https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 0.4,
          "source": "https://web.archive.org/web/20250417003454/https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 6.6,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 27,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "GPQA Diamond",
          "score": 50.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU",
          "score": 55.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MMMU-Pro",
          "score": 33,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 40.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMMMU",
          "score": 30.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "ERQA",
          "score": 26.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "SWE-Lancer",
          "score": 9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Aider",
          "score": 6.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 31.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "COLLIE",
          "score": 42.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 14,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 21.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 12.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 128k",
          "score": 36.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "MRCR: 2 needle 256k",
          "score": 22.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 25,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 9.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 19.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "VideoMME",
          "score": 55.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/"
        },
        {
          "name": "GPQA",
          "score": 50.3,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "gpt-oss-120b High",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-oss/",
      "release_date": "2025-08-05",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.15,
          "source": "https://openrouter.ai/openai/gpt-oss-120b"
        },
        {
          "name": "Output cost",
          "score": 0.6,
          "source": "https://openrouter.ai/openai/gpt-oss-120b"
        },
        {
          "name": "Size",
          "score": 117000000000,
          "source": "https://huggingface.co/openai/gpt-oss-120b"
        },
        {
          "name": "Active parameters",
          "score": 5100000000,
          "source": "https://huggingface.co/openai/gpt-oss-120b"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 110,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "Codeforces",
          "score": 2463
        },
        {
          "name": "Aider",
          "score": 41.8
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 62
        },
        {
          "name": "Codeforces (with tools)",
          "score": 2622
        },
        {
          "name": "GPQA",
          "score": 80.1,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 60.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 49.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 93.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 80.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 78.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 87.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 38.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 93.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 69,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 50.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 22,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 65.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "gpt-oss-120b Low",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-oss/",
      "release_date": "2025-08-05",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.15,
          "source": "https://openrouter.ai/openai/gpt-oss-120b"
        },
        {
          "name": "Output cost",
          "score": 0.59,
          "source": "https://openrouter.ai/openai/gpt-oss-120b"
        },
        {
          "name": "Size",
          "score": 117000000000,
          "source": "https://huggingface.co/openai/gpt-oss-120b"
        },
        {
          "name": "Active parameters",
          "score": 5100000000,
          "source": "https://huggingface.co/openai/gpt-oss-120b"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 9.9,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 47.5,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 37.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 66.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 77.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 67.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 70.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 36,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 66.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 58.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 43.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 45,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "gpt-oss-20b High",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-oss/",
      "release_date": "2025-08-05",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.06,
          "source": "https://openrouter.ai/openai/gpt-oss-20b"
        },
        {
          "name": "Output cost",
          "score": 0.2,
          "source": "https://openrouter.ai/openai/gpt-oss-20b"
        },
        {
          "name": "Size",
          "score": 21000000000,
          "source": "https://huggingface.co/openai/gpt-oss-20b"
        },
        {
          "name": "Active parameters",
          "score": 3600000000,
          "source": "https://huggingface.co/openai/gpt-oss-20b"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 90,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "Codeforces",
          "score": 2230
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 60
        },
        {
          "name": "Codeforces (with tools)",
          "score": 2516
        },
        {
          "name": "GPQA",
          "score": 71.5,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 52.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 40.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 89.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 74.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 68.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 9.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 77.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 34.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 89.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 65.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 34.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 9.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 60.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "gpt-oss-20b Low",
      "company": "OpenAI",
      "url": "https://openai.com/index/introducing-gpt-oss/",
      "release_date": "2025-08-05",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.06,
          "source": "https://openrouter.ai/openai/gpt-oss-20b"
        },
        {
          "name": "Output cost",
          "score": 0.2,
          "source": "https://openrouter.ai/openai/gpt-oss-20b"
        },
        {
          "name": "Size",
          "score": 21000000000,
          "source": "https://huggingface.co/openai/gpt-oss-20b"
        },
        {
          "name": "Active parameters",
          "score": 3600000000,
          "source": "https://huggingface.co/openai/gpt-oss-20b"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 44.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 34.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 62.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 71.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 61.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 65.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 34,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 62.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 57.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 31,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 4.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 50.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-4o",
      "company": "OpenAI",
      "url": "https://openai.com/index/hello-gpt-4o/",
      "release_date": "2024-05-13",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "tool", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 5,
          "source": "https://web.archive.org/web/20240514201030/https://openai.com/api/pricing/"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://web.archive.org/web/20240514201030/https://openai.com/api/pricing/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 5.7,
          "source": "https://artificialanalysis.ai/?models=gpt-5-codex"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 27,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "MMLU",
          "score": 88.7,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "GPQA",
          "score": 53.6,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "MATH",
          "score": 76.6,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "HumanEval",
          "score": 90.2,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "MGSM",
          "score": 90.5,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "DROP",
          "score": 83.4,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "AIME 2025",
          "score": 9.3,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "GPQA",
          "score": 53.6,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 32.3,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU Pro",
          "score": 72.6,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LOFT (128k)",
          "score": 78,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 38.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMMU",
          "score": 69.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "EgoSchema",
          "score": 72.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SWE-bench Verified",
          "score": 33.2,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GPQA",
          "score": 53.6,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU",
          "score": 88.7,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU Pro",
          "score": 72.6,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MATH",
          "score": 76.6,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "HumanEval",
          "score": 90.2,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMMU",
          "score": 69.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MathVista",
          "score": 63.8,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "DocVQA",
          "score": 92.8,
          "source": "https://x.ai/news/grok-2"
        }
      ]
    },
    {
      "name": "GPT-4 Turbo",
      "company": "OpenAI",
      "url": "https://openai.com/index/new-models-and-developer-products-announced-at-devday/",
      "release_date": "2023-11-06",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 10,
          "source": "https://web.archive.org/web/20231113130532/https://openai.com/pricing"
        },
        {
          "name": "Output cost",
          "score": 30,
          "source": "https://web.archive.org/web/20231113130532/https://openai.com/pricing"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 24,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "MMLU",
          "score": 86.5,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "GPQA",
          "score": 48,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "MATH",
          "score": 72.6,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "HumanEval",
          "score": 87.1,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "MGSM",
          "score": 88.5,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "DROP",
          "score": 86,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "GPQA",
          "score": 48.0,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU",
          "score": 86.5,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU Pro",
          "score": 63.7,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MATH",
          "score": 72.6,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "HumanEval",
          "score": 87.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMMU",
          "score": 63.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MathVista",
          "score": 58.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "DocVQA",
          "score": 87.2,
          "source": "https://x.ai/news/grok-2"
        }
      ]
    },
    {
      "name": "GPT-4",
      "company": "OpenAI",
      "url": "https://openai.com/index/new-models-and-developer-products-announced-at-devday/",
      "release_date": "2023-03-14",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 30,
          "source": "https://web.archive.org/web/20230330060044/https://openai.com/pricing"
        },
        {
          "name": "Output cost",
          "score": 60,
          "source": "https://web.archive.org/web/20230330060044/https://openai.com/pricing"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 21,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "MMLU",
          "score": 86.4,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "GPQA",
          "score": 35.7,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "MATH",
          "score": 42.5,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "HumanEval",
          "score": 67,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "MGSM",
          "score": 74.5,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "DROP",
          "score": 80.9,
          "source": "https://openai.com/index/hello-gpt-4o/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 38,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GSM8K",
          "score": 92.0,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MMLU",
          "score": 86.4,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HumanEval",
          "score": 67.0,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MATH",
          "score": 42.5,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HNHSME 2023",
          "score": 68.0,
          "source": "https://x.ai/news/grok"
        }
      ]
    },
    {
      "name": "GPT-3.5",
      "company": "OpenAI",
      "url": "https://openai.com/index/chatgpt/",
      "release_date": "2022-11-30",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://web.archive.org/web/20230510031654/https://openai.com/pricing"
        },
        {
          "name": "Output cost",
          "score": 2,
          "source": "https://web.archive.org/web/20230510031654/https://openai.com/pricing"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 8,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "DROP",
          "score": 70.2,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "HumanEval",
          "score": 68,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GPQA",
          "score": 30.8,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GSM8K",
          "score": 57.1,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MMLU",
          "score": 70.0,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HumanEval",
          "score": 48.1,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MATH",
          "score": 23.5,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HNHSME 2023",
          "score": 41,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 18.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "GPT-3",
      "company": "OpenAI",
      "url": "https://openai.com/index/language-models-are-few-shot-learners/",
      "release_date": "2020-05-28",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 20,
          "source": "https://web.archive.org/web/20230510031654/https://openai.com/pricing"
        },
        {
          "name": "Output cost",
          "score": 20,
          "source": "https://web.archive.org/web/20230510031654/https://openai.com/pricing"
        },
        {
          "name": "Size",
          "score": 175000000000,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "Active parameters",
          "score": 175000000000,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "LAMBADA",
          "score": 76.2,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "StoryCloze",
          "score": 91.8,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "TriviaQA",
          "score": 64.3,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "NaturalQuestions",
          "score": 14.6,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "WebQuestions",
          "score": 14.4,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "HellaSwag (one-shot)",
          "score": 78.1,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "BLEU (FR/EN)",
          "score": 21.2,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "Winogrande",
          "score": 70.2,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "PIQA",
          "score": 80.5,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "ARC (Challenge)",
          "score": 51.4,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "OpenBookQA",
          "score": 57.6,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "DROP",
          "score": 23.6,
          "source": "https://arxiv.org/abs/2005.14165"
        },
        {
          "name": "SuperGLUE",
          "score": 71.8,
          "source": "https://arxiv.org/abs/2005.14165"
        }
      ]
    },

    {
      "name": "Claude Haiku 4.5 Thinking",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-haiku-4-5",
      "release_date": "2025-10-15",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "Output cost",
          "score": 5,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 39,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 55,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 73.3,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "Terminal-Bench",
          "score": 41,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 83.2,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 63.6,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 83,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "OSWorld",
          "score": 50.7,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 96.3,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "AIME 2025",
          "score": 80.7,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "GPQA Diamond",
          "score": 73,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "MMMLU",
          "score": 83,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "MMMU",
          "score": 73.2,
          "source": "https://www.anthropic.com/news/claude-haiku-4-5"
        },
        {
          "name": "GPQA",
          "score": 73,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "SWE-bench Verified",
          "score": 73.3,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Claude Sonnet 4.5 Thinking",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-sonnet-4-5",
      "release_date": "2025-09-29",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 42,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 63,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 77.2,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Terminal-Bench",
          "score": 50,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 86.2,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 70,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 98,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "OSWorld",
          "score": 61.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025",
          "score": 87,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 100,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMLU",
          "score": 89.1,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMU",
          "score": 77.8,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Finance Agent",
          "score": 55.3,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "SWE-bench Verified",
          "score": 77.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 44.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 68,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 50,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 61.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 19.6,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 40.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 71.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 66,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 24.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 84.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 60.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 41,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 88,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 71,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 45,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 57,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 66,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 78,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 33,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 19.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 32,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025",
          "score": 87,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 100,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025",
          "score": 74.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025 (with tools)",
          "score": 88.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 65.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU Pro",
          "score": 87.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU-Redux",
          "score": 95.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Longform Writing",
          "score": 79.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HealthBench",
          "score": 44.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp",
          "score": 24.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 42.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Seal-0",
          "score": 53.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FinSearchComp-T3",
          "score": 44,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FRAMES",
          "score": 85,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 77.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Multilingual (with tools)",
          "score": 68,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Multi-SWE-bench (with tools)",
          "score": 44.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SciCode",
          "score": 44.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "LiveCodeBench",
          "score": 64,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "OJ-Bench",
          "score": 30.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Terminal-Bench",
          "score": 51,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ARC AGI 2",
          "score": 13.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 83.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 87.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 100.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MathArena Apex",
          "score": 1.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 68.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot Pro",
          "score": 36.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 68.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.145,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 77.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench Pro",
          "score": 1418.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 42.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 77.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 84.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VendingBench 2",
          "score": 3838.74,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 50.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 29.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMLU",
          "score": 89.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 90.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 47.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "BFCL v4 MultiTurn",
          "score": 68.68,
          "source": "https://x.ai/news/grok-4-1-fast"
        }
      ]
    },
    {
      "name": "Claude Sonnet 4.5",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-sonnet-4-5",
      "release_date": "2025-09-29",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 7.9,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 50,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "GPQA",
          "score": 83.4,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 78.1,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 41.2,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "FRAMES",
          "score": 85.0,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "X Browse",
          "score": 14.6,
          "source": "https://x.ai/news/grok-4-1-fast"
        }
      ]
    },
    {
      "name": "Claude Opus 4.1",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-opus-4-1",
      "release_date": "2025-08-05",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 15,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "Output cost",
          "score": 75,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 30,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 59,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 74.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Terminal-Bench",
          "score": 43.3,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "GPQA Diamond",
          "score": 80.9,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Retail",
          "score": 82.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Airline",
          "score": 56,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMLU",
          "score": 89.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMU",
          "score": 77.1,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "AIME 2025",
          "score": 78,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 74.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Terminal-Bench",
          "score": 46.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 86.8,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 63,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 71.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "OSWorld",
          "score": 44.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025",
          "score": 78,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "GPQA Diamond",
          "score": 81,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMLU",
          "score": 89.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMU",
          "score": 77.1,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Finance Agent",
          "score": 50.9,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "GPQA",
          "score": 80.9,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "SWE-bench Verified",
          "score": 74.5,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Claude Opus 4",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-4",
      "release_date": "2025-04-22",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 15,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "Output cost",
          "score": 75,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 27,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.5,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "Terminal-Bench",
          "score": 39.2,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 79.6,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Retail",
          "score": 81.4,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Airline",
          "score": 59.6,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMLU",
          "score": 88.8,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMU",
          "score": 76.5,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "AIME 2025",
          "score": 75.5,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Terminal-Bench",
          "score": 39.2,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "GPQA Diamond",
          "score": 79.6,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Retail",
          "score": 81.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Airline",
          "score": 59.6,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMLU",
          "score": 88.8,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMU",
          "score": 76.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "AIME 2025",
          "score": 75.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "GPQA Diamond",
          "score": 79.6,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "HMMT 2025",
          "score": 58.3,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "HMMT 2025",
          "score": 58.3,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "AIME 2025",
          "score": 75.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "ARC AGI 2",
          "score": 8.6,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 10.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 79.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 75.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 51.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 72,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 77.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 76.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 16.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.5,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 43.2,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "GPQA",
          "score": 79.6,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Claude Sonnet 4",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-4",
      "release_date": "2025-04-22",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 43,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 57,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 72.7,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "Terminal-Bench",
          "score": 33.5,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 75.4,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Retail",
          "score": 80.5,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Airline",
          "score": 60,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMLU",
          "score": 86.5,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMU",
          "score": 74.4,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "AIME 2025",
          "score": 70.5,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.7,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Terminal-Bench",
          "score": 35.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "GPQA Diamond",
          "score": 75.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Retail",
          "score": 80.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "τ-Bench Airline",
          "score": 60,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMLU",
          "score": 86.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMU",
          "score": 74.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "AIME 2025",
          "score": 70.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 7.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 75.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 70.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 48.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 61.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 79.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 74.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 39.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 72.7,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Terminal-Bench",
          "score": 36.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 83.8,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 63,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 49.6,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "OSWorld",
          "score": 42.2,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025",
          "score": 70.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "GPQA Diamond",
          "score": 76.1,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMLU",
          "score": 86.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMU",
          "score": 74.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Finance Agent",
          "score": 44.5,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 35.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 56.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 36.4,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 57.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 12.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 29.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 68.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 64.6,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 20.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 65.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 42,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 37,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Verified",
          "score": 72.7,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 53.3,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 35.7,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 36.4,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-Dev",
          "score": 67.1,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "AIME 2025",
          "score": 74,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 84,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 78,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 9.6,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 66,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 40,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 55,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 65,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 65,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 30,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA",
          "score": 75.4,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Claude Sonnet 3.7",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-3-7-sonnet",
      "release_date": "2025-02-24",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://claude.com/pricing#api"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 98,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 50,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 62.3,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "Terminal-Bench",
          "score": 35.2,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 78.2,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Retail",
          "score": 81.2,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "τ-Bench Airline",
          "score": 58.4,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMLU",
          "score": 85.9,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMU",
          "score": 75,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "AIME 2025",
          "score": 54.8,
          "source": "https://www.anthropic.com/news/claude-4"
        }
      ]
    },
    {
      "name": "Claude Sonnet 3.5",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-3-5-sonnet",
      "release_date": "2024-06-21",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://www.anthropic.com/news/claude-3-5-sonnet"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://www.anthropic.com/news/claude-3-5-sonnet"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 25,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2025",
          "score": 16,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "GPQA",
          "score": 65,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 40.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU Pro",
          "score": 78,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LOFT (128k)",
          "score": 69.9,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 28.4,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMMU",
          "score": 70.4,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "DROP",
          "score": 87.1,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "HumanEval",
          "score": 92,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "SWE-bench Verified",
          "score": 49,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GPQA",
          "score": 59.6,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU",
          "score": 88.3,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU Pro",
          "score": 76.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MATH",
          "score": 71.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "HumanEval",
          "score": 92.0,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMMU",
          "score": 68.3,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MathVista",
          "score": 67.7,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "DocVQA",
          "score": 95.2,
          "source": "https://x.ai/news/grok-2"
        }
      ]
    },
    {
      "name": "Claude 2",
      "company": "Anthropic",
      "url": "https://www.anthropic.com/news/claude-2",
      "release_date": "2023-07-11",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 8,
          "source": "https://www.prompthub.us/models/claude-2"
        },
        {
          "name": "Output cost",
          "score": 24,
          "source": "https://www.prompthub.us/models/claude-2"
        },
        {
          "name": "HumanEval",
          "score": 56,
          "source": "https://www.anthropic.com/news/claude-2"
        },
        {
          "name": "GSM8K",
          "score": 88,
          "source": "https://www.anthropic.com/news/claude-2"
        },
        {
          "name": "GSM8K",
          "score": 88,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MMLU",
          "score": 75,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HumanEval",
          "score": 70,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HNHSME 2023",
          "score": 55,
          "source": "https://x.ai/news/grok"
        }
      ]
    },

    {
      "name": "Gemini 3 Pro",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-3/",
      "release_date": "2025-11-18",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 12,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 37.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ARC AGI 2",
          "score": 31.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 91.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 95.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 100.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MathArena Apex",
          "score": 23.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 81.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot Pro",
          "score": 72.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 81.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.115,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 87.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench Pro",
          "score": 2439.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 54.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 85.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VendingBench 2",
          "score": 5478.16,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 70.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 72.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMLU",
          "score": 91.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 93.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 77.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 1M",
          "score": 26.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 87.1,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "BFCL v4 MultiTurn",
          "score": 63.00,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 55.9,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "FRAMES",
          "score": 90.9,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "X Browse",
          "score": 26.5,
          "source": "https://x.ai/news/grok-4-1-fast"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-2-5-model-family-expands/",
      "release_date": "2025-06-17",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 100,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 60,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 69,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 82.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 59.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 54.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 87.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 82,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Vibe-Eval",
          "score": 67.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMME",
          "score": 86.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 89.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 67.2,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMU",
          "score": 82,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.6,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "LiveCodeBench",
          "score": 74.2,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "USAMO 2025",
          "score": 34.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "HMMT 2025",
          "score": 82.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "ARC AGI 2",
          "score": 4.9,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "SWE-bench Verified",
          "score": 67.2,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMU",
          "score": 82,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Finance Agent",
          "score": 29.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 57.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 9.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 32.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 60.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 56,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 28.4,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 59.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 42.6,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 39.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 86,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 84,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 80,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 43,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 49,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 66,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 54,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 25,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA",
          "score": 86.4,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ARC AGI 2",
          "score": 4.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 88.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MathArena Apex",
          "score": 0.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 68.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot Pro",
          "score": 11.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 69.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.145,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench Pro",
          "score": 1775.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 32.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 59.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 54.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VendingBench 2",
          "score": 573.64,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 63.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 54.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMLU",
          "score": 89.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 91.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 58.0,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 1M",
          "score": 16.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro 0506",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-2-5-pro-updates/",
      "release_date": "2025-05-06",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 53,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 75.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 72.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 50.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 87.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 79.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Vibe-Eval",
          "score": 65.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMME",
          "score": 84.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR: 2-needle 128K",
          "score": 93,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 88.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2024",
          "score": 90.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Vibe-Eval",
          "score": 67.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "VideoMMMU",
          "score": 83.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "MRCR v2: 2-needle 128K",
          "score": 58,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 71.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 76.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.2,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMU",
          "score": 79.6,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://www.anthropic.com/news/claude-4"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Flash Thinking 0520",
      "company": "Google",
      "url": "https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/#flash-improvements",
      "release_date": "2025-03-25",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.3,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 2.5,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 93,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 51,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 82.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 72,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT 2025",
          "score": 64.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 62.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA",
          "score": 82.8,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "SWE-bench Verified",
          "score": 60.4,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "MMMU",
          "score": 79.7,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro 0325",
      "company": "Google",
      "url": "https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/",
      "release_date": "2025-03-25",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 54,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 84,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 86.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 70.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 68.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 52.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 81.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Vibe-Eval",
          "score": 69.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR: 2-needle 128K",
          "score": 94.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 89.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        }
      ]
    },
    {
      "name": "Gemma 3 27B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-12",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.119,
          "source": "https://openrouter.ai/google/gemma-3-27b-it"
        },
        {
          "name": "Output cost",
          "score": 0.20,
          "source": "https://openrouter.ai/google/gemma-3-27b-it"
        },
        {
          "name": "Size",
          "score": 27432406640,
          "source": "https://huggingface.co/google/gemma-3-27b-it"
        },
        {
          "name": "Active parameters",
          "score": 27432406640,
          "source": "https://huggingface.co/google/gemma-3-27b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 67.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 29.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 54.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 42.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 10.0,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 74.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU-Lite",
          "score": 75.1,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 89.0,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 60.3,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MMMU",
          "score": 64.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 22.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 12.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 20.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 66.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 42.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 13.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 21.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 88.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 25.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 20.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 31.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 5.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 3.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 10.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemma 3 12B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-12",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://openrouter.ai/google/gemma-3-12b-it"
        },
        {
          "name": "Output cost",
          "score": 0.1,
          "source": "https://openrouter.ai/google/gemma-3-12b-it"
        },
        {
          "name": "Size",
          "score": 12187325040,
          "source": "https://huggingface.co/google/gemma-3-12b-it"
        },
        {
          "name": "Active parameters",
          "score": 12187325040,
          "source": "https://huggingface.co/google/gemma-3-12b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 60.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 24.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 47.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 40.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 6.3,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 75.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU-Lite",
          "score": 69.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 83.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 54.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MMMU",
          "score": 59.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 20.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 10.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 18.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 59.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 34.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 13.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 17.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 85.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 22,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 18.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 36.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 6.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 10.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemma 3 4B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-12",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.04,
          "source": "https://openrouter.ai/google/gemma-3-4b-it"
        },
        {
          "name": "Output cost",
          "score": 0.08,
          "source": "https://openrouter.ai/google/gemma-3-4b-it"
        },
        {
          "name": "Size",
          "score": 4300079472,
          "source": "https://huggingface.co/google/gemma-3-4b-it"
        },
        {
          "name": "Active parameters",
          "score": 4300079472,
          "source": "https://huggingface.co/google/gemma-3-4b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 43.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 12.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 36.3,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 30.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 4.0,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 70.1,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU-Lite",
          "score": 54.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 75.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 43.0,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MMMU",
          "score": 48.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 14.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 6.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 12.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 41.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 29.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 11.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 7.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 76.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 6.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 12.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 28.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 5.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemma 3 1B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-13",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 1000000000,
          "source": "https://huggingface.co/google/gemma-3-1b-it"
        },
        {
          "name": "Active parameters",
          "score": 1000000000,
          "source": "https://huggingface.co/google/gemma-3-1b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 14.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 1.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 6.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 19.2,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 2.2,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 36.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU-Lite",
          "score": 34.2,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 48.0,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 15.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 6.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 0.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 3.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 13.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 23.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 1.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 48.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 3.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 19.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemma 3 270M",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-08-14",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 270000000,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "Active parameters",
          "score": 270000000,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "HellaSwag",
          "score": 37.7,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "PIQA",
          "score": 66.2,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "ARC-c",
          "score": 28.2,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "WinoGrande",
          "score": 52.3,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "BIG-Bench Hard",
          "score": 26.7,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "IF Eval",
          "score": 51.2,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 5.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 0.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 2.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 5.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 22.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 0.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 2.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 12.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 9.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemini 2.0 Flash",
      "company": "Google",
      "url": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
      "release_date": "2024-12-11",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.35,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 1.5,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 7.4,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 34,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "MMLU Pro",
          "score": 76.4,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "Natural2Code",
          "score": 92.9,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "BIRD-SQL",
          "score": 56.9,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "LiveCodeBench",
          "score": 35.1,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "FACTS Grounding",
          "score": 83.6,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "MATH",
          "score": 89.7,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "HiddenMath",
          "score": 63,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "GPQA Diamond",
          "score": 62.1,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "MRCR: 2 needle 1M",
          "score": 69.2,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "MMMU",
          "score": 70.7,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "Vibe-Eval",
          "score": 56.3,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "CoVoST2",
          "score": 39.2,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "EgoSchema",
          "score": 71.5,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "GPQA",
          "score": 64.7,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 36,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU Pro",
          "score": 79.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LOFT (128k)",
          "score": 75.6,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 44.3,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMMU",
          "score": 72.7,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "EgoSchema",
          "score": 71.9,
          "source": "https://x.ai/news/grok-3"
        }
      ]
    },

    {
      "name": "Grok 4.1 Fast Reasoning",
      "company": "xAI",
      "url": "https://x.ai/news/grok-4-1",
      "release_date": "2025-11-19",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "video", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.2,
          "source": "https://docs.x.ai/docs/models/grok-4-fast-reasoning"
        },
        {
          "name": "Output cost",
          "score": 0.5,
          "source": "https://docs.x.ai/docs/models/grok-4-fast-reasoning"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 71,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "BFCL v4 MultiTurn",
          "score": 69.73,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 64.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 49.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 89.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 85.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 82.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 44.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 89.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 52.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 68,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 22.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 93.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Grok 4.1 Fast Non-Reasoning",
      "company": "xAI",
      "url": "https://x.ai/news/grok-4-1",
      "release_date": "2025-11-19",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "video", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.2,
          "source": "https://docs.x.ai/docs/models/grok-4-fast-reasoning"
        },
        {
          "name": "Output cost",
          "score": 0.5,
          "source": "https://docs.x.ai/docs/models/grok-4-fast-reasoning"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 6.5,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 93.3,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 63.9,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "FRAMES",
          "score": 87.6,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "X Browse",
          "score": 56.3,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 38.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 27.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 34.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 74.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 63.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 39.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 29.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 34.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 36.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 22,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 13.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 63.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Grok 4 Fast",
      "company": "xAI",
      "url": "https://x.ai/news/grok-4-fast",
      "release_date": "2025-07-09",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "video", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.2,
          "source": "https://docs.x.ai/docs/models/grok-4-fast-reasoning"
        },
        {
          "name": "Output cost",
          "score": 0.5,
          "source": "https://docs.x.ai/docs/models/grok-4-fast-reasoning"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 61,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 60,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "AIME 2025",
          "score": 92,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "HMMT 2025",
          "score": 93.3,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 20,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "LiveCodeBench",
          "score": 80,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "BrowseComp (with tools)",
          "score": 44.9,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "SimpleQA (with tools)",
          "score": 95,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 66,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "BrowseComp (zh) (with tools)",
          "score": 51.2,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "GPQA",
          "score": 85.7,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 93.3,
          "source": "https://x.ai/news/grok-4-1-fast"
        }
      ]
    },
    {
      "name": "Grok 4",
      "company": "xAI",
      "url": "https://x.ai/news/grok-4",
      "release_date": "2025-07-09",
      "capabilities": {
        "input": ["text", "image", "video", "audio"],
        "output": ["text", "thinking", "tool", "image", "video", "audio"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://docs.x.ai/docs/models/grok-4-0709"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://docs.x.ai/docs/models/grok-4-0709"
        },
        {
          "name": "Size",
          "score": 3000000000000,
          "source": "https://youtu.be/q_mMV5OpRd4?si=jxsHZn336LhMraIz&t=1389"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 120,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 65,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 25.4,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 87.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "LiveCodeBench",
          "score": 79,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "USAMO 2025",
          "score": 37.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "HMMT 2025",
          "score": 90,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "AIME 2025",
          "score": 91.7,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "ARC AGI 2",
          "score": 15.9,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "BrowseComp (with tools)",
          "score": 43,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "SimpleQA (with tools)",
          "score": 94,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 58,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "BrowseComp (zh) (with tools)",
          "score": 45,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 25.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 41,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025",
          "score": 91.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 98.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025",
          "score": 90,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025 (with tools)",
          "score": 93.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 73.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA Diamond",
          "score": 87.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA",
          "score": 87.5,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 87.1,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "BFCL v4 MultiTurn",
          "score": 62.27,
          "source": "https://x.ai/news/grok-4-1-fast"
        }
      ]
    },
    {
      "name": "Grok 3 High",
      "company": "xAI",
      "url": "https://x.ai/news/grok-3",
      "release_date": "2025-02-19",
      "capabilities": {
        "input": ["text", "image", "video"],
        "output": ["text", "thinking", "tool", "image", "video"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://docs.x.ai/docs/models/grok-3"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://docs.x.ai/docs/models/grok-3"
        },
        {
          "name": "Size",
          "score": 3000000000000,
          "source": "https://youtu.be/q_mMV5OpRd4?si=jxsHZn336LhMraIz&t=1389"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 9.2,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 45,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2025",
          "score": 52.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "GPQA",
          "score": 75.4,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 57,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU Pro",
          "score": 79.9,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LOFT (128k)",
          "score": 83.3,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 43.6,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMMU",
          "score": 73.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "EgoSchema",
          "score": 74.5,
          "source": "https://x.ai/news/grok-3"
        }
      ]
    },
    {
      "name": "Grok 3",
      "company": "xAI",
      "url": "https://x.ai/news/grok-3",
      "release_date": "2025-02-19",
      "capabilities": {
        "input": ["text", "image", "video"],
        "output": ["text", "thinking", "tool", "image", "video"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 3,
          "source": "https://docs.x.ai/docs/models/grok-3"
        },
        {
          "name": "Output cost",
          "score": 15,
          "source": "https://docs.x.ai/docs/models/grok-3"
        },
        {
          "name": "Size",
          "score": 3000000000000,
          "source": "https://youtu.be/q_mMV5OpRd4?si=jxsHZn336LhMraIz&t=1389"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 9.2,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 45,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SimpleQA (with tools)",
          "score": 82,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 37,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "BrowseComp (zh) (with tools)",
          "score": 10.8,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "GPQA",
          "score": 84.6,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "MMMU",
          "score": 78,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Grok 3 Mini High",
      "company": "xAI",
      "url": "https://x.ai/news/grok-3",
      "release_date": "2025-02-19",
      "capabilities": {
        "input": ["text", "image", "video"],
        "output": ["text", "thinking", "tool", "image", "video"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.3,
          "source": "https://docs.x.ai/docs/models/grok-3-mini"
        },
        {
          "name": "Output cost",
          "score": 0.5,
          "source": "https://docs.x.ai/docs/models/grok-3-mini"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 110,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 57,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2025",
          "score": 39.7,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "GPQA",
          "score": 66.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 41.5,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU Pro",
          "score": 78.9,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LOFT (128k)",
          "score": 83.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 21.7,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMMU",
          "score": 69.4,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "EgoSchema",
          "score": 74.3,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "GPQA Diamond",
          "score": 79,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "HMMT 2025",
          "score": 74,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 11,
          "source": "https://x.ai/news/grok-4-fast"
        },
        {
          "name": "LiveCodeBench",
          "score": 70,
          "source": "https://x.ai/news/grok-4-fast"
        }
      ]
    },
    {
      "name": "Grok 2",
      "company": "xAI",
      "url": "https://x.ai/news/grok-2",
      "release_date": "2024-08-13",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 270000000000,
          "source": "https://huggingface.co/xai-org/grok-2/discussions/24"
        },
        {
          "name": "Active parameters",
          "score": 115500000000,
          "source": "https://huggingface.co/xai-org/grok-2/discussions/24"
        },
        {
          "name": "GPQA",
          "score": 56.0,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU",
          "score": 87.5,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMLU Pro",
          "score": 76.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MATH",
          "score": 50.6,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "HumanEval",
          "score": 88.4,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MMMU",
          "score": 66.1,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "MathVista",
          "score": 69.0,
          "source": "https://x.ai/news/grok-2"
        },
        {
          "name": "DocVQA",
          "score": 93.6,
          "source": "https://x.ai/news/grok-2"
        }
      ]
    },
    {
      "name": "Grok 1",
      "company": "xAI",
      "url": "https://x.ai/news/grok",
      "release_date": "2023-11-03",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 314000000000,
          "source": "https://github.com/xai-org/grok-1"
        },
        {
          "name": "Active parameters",
          "score": 78500000000,
          "source": "https://github.com/xai-org/grok-1"
        },
        {
          "name": "GSM8K",
          "score": 62.9,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MMLU",
          "score": 73.0,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HumanEval",
          "score": 63.2,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MATH",
          "score": 23.9,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HNHSME 2023",
          "score": 59.0,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 18.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Grok 0",
      "company": "xAI",
      "url": "https://x.ai/news/grok",
      "release_date": "2023-11-03",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 33000000000,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "Active parameters",
          "score": 33000000000,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "GSM8K",
          "score": 56.8,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MMLU",
          "score": 65.7,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HumanEval",
          "score": 39.7,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "MATH",
          "score": 15.7,
          "source": "https://x.ai/news/grok"
        },
        {
          "name": "HNHSME 2023",
          "score": 37.0,
          "source": "https://x.ai/news/grok"
        }
      ]
    },


    {
      "name": "DeepSeek V3.2 Exp",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250929",
      "release_date": "2025-09-29",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.28,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Output cost",
          "score": 0.42,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Size",
          "score": 684531386000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "Active parameters",
          "score": 37000000000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 62,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 57,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 67.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 30.6,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 57.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 37.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 55.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 40.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 47.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 63.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 71,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 27.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 66.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 26.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 34,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 85,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 80,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 79,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 38,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 54,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 69,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 34,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 29,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 19.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 20.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025",
          "score": 89.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 58.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025",
          "score": 83.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025 (with tools)",
          "score": 49.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 76,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA Diamond",
          "score": 79.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU Pro",
          "score": 85,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU-Redux",
          "score": 93.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Longform Writing",
          "score": 72.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HealthBench",
          "score": 46.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp",
          "score": 40.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 47.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Seal-0",
          "score": 38.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FinSearchComp-T3",
          "score": 27,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FRAMES",
          "score": 80.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 67.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Multilingual (with tools)",
          "score": 57.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Multi-SWE-bench (with tools)",
          "score": 30.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SciCode",
          "score": 37.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "LiveCodeBench",
          "score": 74.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "OJ-Bench",
          "score": 38.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Terminal-Bench",
          "score": 37.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA",
          "score": 79.9,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "DeepSeek V3.1",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250821",
      "release_date": "2025-08-21",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.56,
          "source": "https://api-docs.deepseek.com/news/news250821"
        },
        {
          "name": "Output cost",
          "score": 1.68,
          "source": "https://api-docs.deepseek.com/news/news250821"
        },
        {
          "name": "Size",
          "score": 684531386000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1"
        },
        {
          "name": "Active parameters",
          "score": 37000000000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 63,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 45,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 66,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 54.5,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 29,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 31.3,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-Dev",
          "score": 53.3,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "GPQA",
          "score": 74.9,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "DeepSeek-V3-0324",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250325",
      "release_date": "2025-03-24",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.27,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Output cost",
          "score": 1.1,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Size",
          "score": 684531386000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"
        },
        {
          "name": "Active parameters",
          "score": 37000000000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 11,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 41,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2025",
          "score": 39.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "GPQA",
          "score": 59.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 33.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU Pro",
          "score": 75.9,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 24.9,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "Terminal-Bench",
          "score": 2.5
        },
        {
          "name": "Aider",
          "score": 55.1
        },
        {
          "name": "SWE-bench Verified",
          "score": 38.8
        },
        {
          "name": "LiveCodeBench",
          "score": 46.9
        },
        {
          "name": "DROP",
          "score": 91.6,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "DeepSeek R1 0528",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250528",
      "release_date": "2025-05-28",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.55,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Output cost",
          "score": 2.19,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Size",
          "score": 684531386000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Active parameters",
          "score": 37000000000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 99,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 52,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "MMLU-Redux",
          "score": 93.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "MMLU Pro",
          "score": 85,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 81,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SimpleQA",
          "score": 27.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "FRAMES",
          "score": 83,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 73.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Codeforces",
          "score": 1930,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SWE-bench Verified",
          "score": 57.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 71.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2024",
          "score": 91.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 87.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT 2025",
          "score": 79.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "CNMO 2024",
          "score": 86.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 81,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 87.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 70.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 71.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 57.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 27.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 82.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench",
          "score": 17.5
        },
        {
          "name": "GPQA",
          "score": 81,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "DeepSeek R1",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250120",
      "release_date": "2025-01-20",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.55,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Output cost",
          "score": 2.19,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Size",
          "score": 684531386000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1"
        },
        {
          "name": "Active parameters",
          "score": 37000000000,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 72,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 44,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Aider",
          "score": 56.9
        },
        {
          "name": "MMLU-Redux",
          "score": 92.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "MMLU Pro",
          "score": 84,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 71.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SimpleQA",
          "score": 30.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "FRAMES",
          "score": 82.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 63.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Codeforces",
          "score": 1530,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SWE-bench Verified",
          "score": 49.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 53.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2024",
          "score": 79.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 70,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT 2025",
          "score": 41.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "CNMO 2024",
          "score": 78.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "BFCL v3 MultiTurn",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "τ-Bench Airline",
          "score": 53.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "τ-Bench Retail",
          "score": 63.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA",
          "score": 73.3,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "DeepSeek-R1-0528-Qwen3-8B",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250528",
      "release_date": "2025-01-20",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.18,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 2.1,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 8190735360,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
        },
        {
          "name": "Active parameters",
          "score": 8190735360,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 94,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 31,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 86,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 76.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT 2025",
          "score": 61.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 61.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 60.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        }
      ]
    },

    {
      "name": "Qwen3-235B-A22B",
      "company": "Alibaba",
      "url": "https://qwen.ai/blog?id=1e3fa5c2d4662af2855586055ad037ed9e555125&from=research.research-list",
      "release_date": "2025-04-28",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.7,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 2.8,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 235093634560,
          "source": "https://huggingface.co/Qwen/Qwen3-235B-A22B"
        },
        {
          "name": "Active parameters",
          "score": 22000000000,
          "source": "https://huggingface.co/Qwen/Qwen3-235B-A22B"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 85,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 57,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 85.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 81.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 71.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 66.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 65,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 11.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT 2025",
          "score": 62.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA",
          "score": 81.1,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Qwen3-235B-Thinking 2507",
      "company": "Alibaba",
      "url": "https://x.com/Alibaba_Qwen/status/1948688466386280706",
      "release_date": "2025-07-25",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.7,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 8.4,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 235093634560,
          "source": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"
        },
        {
          "name": "Active parameters",
          "score": 22000000000,
          "source": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 110,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 57,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "LiveCodeBench",
          "score": 78.2
        }
      ]
    },
    {
      "name": "Qwen3-Coder 480B-A35B-Instruct",
      "company": "Alibaba",
      "url": "https://qwen.ai/blog?id=d927d7d2e59d059045ce758ded34f98c0186d2d7&from=research.research-list",
      "release_date": "2025-07-22",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.5,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 7.5,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 480154875392,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 35000000000,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 9.7,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 42,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.6,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 54.7,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 32.7,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 37.5,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-Dev",
          "score": 64.7,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        }
      ]
    },
    {
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "company": "Alibaba",
      "url": "https://qwen.ai/blog?id=qwen3-coder",
      "release_date": "2025-07-22",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.45,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 2.25,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 30532122624,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 3000000000,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 14,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 33,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Terminal-Bench",
          "score": 31.3
        },
        {
          "name": "Aider",
          "score": 33.3
        },
        {
          "name": "SWE-bench Verified",
          "score": 51.6
        }
      ]
    },
    {
      "name": "Qwen3-32B",
      "company": "Alibaba",
      "url": "https://qwen.ai/blog?id=1e3fa5c2d4662af2855586055ad037ed9e555125&from=research.research-list",
      "release_date": "2025-04-28",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.7,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 8.4,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 32762123264,
          "source": "https://huggingface.co/Qwen/Qwen3-32B"
        },
        {
          "name": "Active parameters",
          "score": 32762123264,
          "source": "https://huggingface.co/Qwen/Qwen3-32B"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 55,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 39,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 81.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 72.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 68.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        }
      ]
    },
    {
      "name": "Qwen3-8B",
      "company": "Alibaba",
      "url": "https://qwen.ai/blog?id=1e3fa5c2d4662af2855586055ad037ed9e555125&from=research.research-list",
      "release_date": "2025-04-28",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.18,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 2.1,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 8190735360,
          "source": "https://huggingface.co/Qwen/Qwen3-8B"
        },
        {
          "name": "Active parameters",
          "score": 8190735360,
          "source": "https://huggingface.co/Qwen/Qwen3-8B"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 70,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 28,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 76,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 67.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 62,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        }
      ]
    },

    {
      "name": "Phi 4 Reasoning Plus 14B",
      "company": "Microsoft",
      "url": "https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/",
      "release_date": "2025-04-30",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.07,
          "source": "https://openrouter.ai/microsoft/phi-4-reasoning-plus"
        },
        {
          "name": "Output cost",
          "score": 0.35,
          "source": "https://openrouter.ai/microsoft/phi-4-reasoning-plus"
        },
        {
          "name": "Size",
          "score": 14659507200,
          "source": "https://huggingface.co/microsoft/Phi-4-reasoning-plus"
        },
        {
          "name": "Active parameters",
          "score": 14659507200,
          "source": "https://huggingface.co/microsoft/Phi-4-reasoning-plus"
        },
        {
          "name": "AIME 2024",
          "score": 81.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 78,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT 2025",
          "score": 53.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 69.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "DROP",
          "score": 75.5,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "HumanEval",
          "score": 82.6,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GPQA",
          "score": 68.9,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },

    {
      "name": "GLM-4.6",
      "company": "Z.ai",
      "url": "https://x.com/Zai_org/status/1973034639708344767",
      "release_date": "2025-09-30",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.6,
          "source": "https://docs.z.ai/guides/overview/pricing"
        },
        {
          "name": "Output cost",
          "score": 2.2,
          "source": "https://docs.z.ai/guides/overview/pricing"
        },
        {
          "name": "Size",
          "score": 358337791296,
          "source": "https://huggingface.co/zai-org/GLM-4.5"
        },
        {
          "name": "Active parameters",
          "score": 32000000000,
          "source": "https://huggingface.co/zai-org/GLM-4.5"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 86,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 56,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 68,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 30,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 53.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 40.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 59.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 45.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 49.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 71.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 70,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 30.4,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 75.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 29.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 35,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 86,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 83,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 78,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 70,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 38,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 43,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 54,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 71,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 23,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA",
          "score": 81,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "GLM-4.5",
      "company": "Z.ai",
      "url": "https://x.com/Zai_org/status/1949831552189518044",
      "release_date": "2025-07-28",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.6,
          "source": "https://docs.z.ai/guides/overview/pricing"
        },
        {
          "name": "Output cost",
          "score": 2.2,
          "source": "https://docs.z.ai/guides/overview/pricing"
        },
        {
          "name": "Size",
          "score": 358337791296,
          "source": "https://huggingface.co/zai-org/GLM-4.5"
        },
        {
          "name": "Active parameters",
          "score": 32000000000,
          "source": "https://huggingface.co/zai-org/GLM-4.5"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 100,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 51,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 64.2,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 52.7,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 31.7,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 39.9,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-Dev",
          "score": 63.2,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "GPQA",
          "score": 79.1,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "GLM-4.5-Air",
      "company": "Z.ai",
      "url": "https://x.com/Zai_org/status/1949831552189518044",
      "release_date": "2025-07-28",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.2,
          "source": "https://docs.z.ai/guides/overview/pricing"
        },
        {
          "name": "Output cost",
          "score": 1.1,
          "source": "https://docs.z.ai/guides/overview/pricing"
        },
        {
          "name": "Size",
          "score": 110468824832,
          "source": "https://huggingface.co/zai-org/GLM-4.5-Air"
        },
        {
          "name": "Active parameters",
          "score": 12000000000,
          "source": "https://huggingface.co/zai-org/GLM-4.5-Air"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 110,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 49,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Terminal-Bench",
          "score": 30
        },
        {
          "name": "SWE-bench Verified",
          "score": 57.6
        },
        {
          "name": "LiveCodeBench",
          "score": 70.7
        },
        {
          "name": "GPQA",
          "score": 75,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },

    {
      "name": "Kimi K2 Thinking",
      "company": "Moonshot AI",
      "url": "https://moonshotai.github.io/Kimi-K2/thinking.html",
      "release_date": "2025-11-07",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.15,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Output cost",
          "score": 2.5,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Size",
          "score": 1029173256720,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Thinking"
        },
        {
          "name": "Active parameters",
          "score": 32000000000,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Thinking"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 140,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 67,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 23.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 44.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025",
          "score": 94.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 99.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025",
          "score": 89.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025 (with tools)",
          "score": 95.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 78.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA Diamond",
          "score": 84.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU Pro",
          "score": 84.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU-Redux",
          "score": 94.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Longform Writing",
          "score": 73.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HealthBench",
          "score": 58,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp",
          "score": 60.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 62.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Seal-0",
          "score": 56.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FinSearchComp-T3",
          "score": 47.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FRAMES",
          "score": 87,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 71.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Multilingual (with tools)",
          "score": 61.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Multi-SWE-bench (with tools)",
          "score": 41.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SciCode",
          "score": 44.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "LiveCodeBench",
          "score": 83.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "OJ-Bench",
          "score": 48.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Terminal-Bench",
          "score": 47.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        }
      ]
    },
    {
      "name": "Kimi K2 0905",
      "company": "Moonshot AI",
      "url": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905",
      "release_date": "2025-09-05",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.15,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Output cost",
          "score": 2.5,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Size",
          "score": 1029173256720,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 32000000000,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 16,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 50,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.2,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 55.9,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 33.5,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 44.5,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-Dev",
          "score": 66.6,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 33.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 55.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 44.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 54.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 14.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 28.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 60.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 61,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 26.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 70.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 29.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 30,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 57,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 82,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 77,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 6.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 61,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 31,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 42,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 52,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 73,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 23,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 7.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 21.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025",
          "score": 51,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 75.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025",
          "score": 38.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT 2025 (with tools)",
          "score": 70.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 45.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA Diamond",
          "score": 74.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU Pro",
          "score": 81.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU-Redux",
          "score": 92.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Longform Writing",
          "score": 62.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HealthBench",
          "score": 43.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp",
          "score": 7.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 22.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Seal-0",
          "score": 25.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FinSearchComp-T3",
          "score": 10.4,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FRAMES",
          "score": 58.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 69.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Multilingual (with tools)",
          "score": 55.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Multi-SWE-bench (with tools)",
          "score": 33.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SciCode",
          "score": 30.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "LiveCodeBench",
          "score": 56.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "OJ-Bench",
          "score": 25.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Terminal-Bench",
          "score": 44.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HumanEval",
          "score": 94.5,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "GPQA",
          "score": 75.8,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Kimi K2",
      "company": "Moonshot AI",
      "url": "https://moonshotai.github.io/Kimi-K2/",
      "release_date": "2025-07-11",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.15,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Output cost",
          "score": 2.5,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Size",
          "score": 1029173256720,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 32000000000,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 30,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 48,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 65.8,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 47.3,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 31.3,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 37.5,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-Dev",
          "score": 61.9,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "GPQA",
          "score": 75.1,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "HumanEval",
          "score": 93.3,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },

    {
      "name": "MiniMax M2",
      "company": "MiniMax",
      "url": "https://huggingface.co/MiniMaxAI/MiniMax-M2",
      "release_date": "2025-10-27",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.3,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Output cost",
          "score": 1.2,
          "source": "https://platform.moonshot.ai/docs/pricing/chat#product-pricing"
        },
        {
          "name": "Size",
          "score": 240418294272,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Active parameters",
          "score": 10000000000,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 120,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 61,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.4,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 36.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 56.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 46.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 66.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 44,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 48.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 75.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 72,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 31.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 77.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 65.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 36,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 78,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU Pro",
          "score": 82,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 78,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 12.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 83,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 36,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 72,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 61,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 87,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 24,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        }
      ]
    },

    {
      "name": "Devstral Small 1.1",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/devstral-2507",
      "release_date": "2025-06-10",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.1,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 0.3,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Size",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2507"
        },
        {
          "name": "Active parameters",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2507"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 5.4,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 27,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 53.6
        }
      ]
    },
    {
      "name": "Devstral Small 1.0",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/devstral",
      "release_date": "2025-05-21",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.1,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 0.3,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Size",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2507"
        },
        {
          "name": "Active parameters",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2507"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 20,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "SWE-bench Verified",
          "score": 46.8
        }
      ]
    },
    {
      "name": "Magistral Medium 1.2",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/magistral",
      "release_date": "2025-09-24",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 77,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 52,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 91.82,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "AIME 2025",
          "score": 83.48,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "GPQA Diamond",
          "score": 76.26,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "LiveCodeBench",
          "score": 75,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "GPQA",
          "score": 70.8,
          "source": "https://llm-stats.com/benchmarks"
        }
      ]
    },
    {
      "name": "Magistral Medium 1.1",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/magistral",
      "release_date": "2025-07-24",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "AIME 2024",
          "score": 72.03,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "AIME 2025",
          "score": 60.99,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "GPQA Diamond",
          "score": 71.46,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "LiveCodeBench",
          "score": 59.35,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        }
      ]
    },
    {
      "name": "Magistral Medium 1.0",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/magistral",
      "release_date": "2025-06-10",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 150,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 33,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 73.59,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "AIME 2025",
          "score": 64.95,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "GPQA Diamond",
          "score": 70.83,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "LiveCodeBench",
          "score": 59.36,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        }
      ]
    },
    {
      "name": "Magistral Small 1.2",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/magistral",
      "release_date": "2025-09-24",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 1.5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Size",
          "score": 24011361280,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "Active parameters",
          "score": 24011361280,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 62,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 43,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 86.14,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "AIME 2025",
          "score": 77.34,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "GPQA Diamond",
          "score": 70.07,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        },
        {
          "name": "LiveCodeBench",
          "score": 70.88,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2509"
        }
      ]
    },
    {
      "name": "Magistral Small 1.1",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/magistral",
      "release_date": "2025-07-24",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 1.5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Size",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "Active parameters",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "AIME 2024",
          "score": 70.52,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "AIME 2025",
          "score": 62.03,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "GPQA Diamond",
          "score": 65.78,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        },
        {
          "name": "LiveCodeBench",
          "score": 59.17,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2507"
        }
      ]
    },
    {
      "name": "Magistral Small 1.0",
      "company": "Mistral AI",
      "url": "https://mistral.ai/news/magistral",
      "release_date": "2025-06-10",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "thinking", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Output cost",
          "score": 1.5,
          "source": "https://mistral.ai/pricing#api-pricing"
        },
        {
          "name": "Size",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "Active parameters",
          "score": 23572403200,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 140,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 32,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 70.68,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "AIME 2025",
          "score": 62.76,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "GPQA Diamond",
          "score": 68.18,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        },
        {
          "name": "LiveCodeBench",
          "score": 55.84,
          "source": "https://huggingface.co/mistralai/Magistral-Small-2506"
        }
      ]
    },


    {
      "name": "Llama 4 Maverick",
      "company": "Meta",
      "url": "https://www.llama.com/models/llama-4/",
      "release_date": "2025-04-05",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.27,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.85,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 400000000000,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 17000000000,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MMMU",
          "score": 73.4,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MMMU-Pro",
          "score": 59.6,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MathVista",
          "score": 73.7,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "ChartQA",
          "score": 90.0,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "DocVQA",
          "score": 94.4,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "LiveCodeBench",
          "score": 43.4,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MMLU Pro",
          "score": 80.5,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "GPQA Diamond",
          "score": 69.8,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MGSM",
          "score": 92.3,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 35.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 26.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 19.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 80.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 67.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 39.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 33.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 88.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 39,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 19.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 43,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 46,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 6.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 17.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 4 Scout",
      "company": "Meta",
      "url": "https://www.llama.com/models/llama-4/",
      "release_date": "2025-04-05",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.14,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.55,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 109000000000,
          "source": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 17000000000,
          "source": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct"
        },
        {
          "name": "MMMU",
          "score": 69.4,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MMMU-Pro",
          "score": 52.2,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MathVista",
          "score": 70.7,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "ChartQA",
          "score": 88.8,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "DocVQA",
          "score": 94.4,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "LiveCodeBench",
          "score": 32.8,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MMLU Pro",
          "score": 74.3,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "GPQA Diamond",
          "score": 57.2,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "MGSM",
          "score": 90.6,
          "source": "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 28.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 16.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 14,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 75.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 58.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 29.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 17,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 84.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 28.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 14,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 39.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 25.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 1.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 15.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.3 Instruct 70B",
      "company": "Meta",
      "url": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
      "release_date": "2024-12-06",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.1,
          "source": "https://www.llama.com/models/llama-3/"
        },
        {
          "name": "Output cost",
          "score": 0.4,
          "source": "https://www.llama.com/models/llama-3/"
        },
        {
          "name": "Size",
          "score": 70553706496,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 70553706496,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "MMLU (thinking)",
          "score": 86,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "MMLU Pro (thinking)",
          "score": 68.9,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "IFEval",
          "score": 92.1,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "GPQA Diamond (thinking)",
          "score": 50.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "HumanEval",
          "score": 88.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "MBPP EvalPlus",
          "score": 87.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "MATH (thinking)",
          "score": 77.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "BFCL v2",
          "score": 77.3,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "MGSM",
          "score": 91.1,
          "source": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 27.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 19.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 7.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 71.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 49.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 28.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 26,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 77.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 30,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 7.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 47.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 15,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 2.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 26.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.2 Instruct 90B Vision",
      "company": "Meta",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision",
      "release_date": "2024-09-25",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.72,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.72,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 88800000000,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision"
        },
        {
          "name": "Active parameters",
          "score": 88800000000,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-90B-Vision"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 18.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 67.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 43.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 21.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 24,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 62.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.2 Instruct 11B Vision",
      "company": "Meta",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision",
      "release_date": "2024-09-25",
      "capabilities": {
        "input": ["text", "image"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.16,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.16,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 10600000000,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision"
        },
        {
          "name": "Active parameters",
          "score": 10600000000,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 15.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 7.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 1.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 46.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 22.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 11,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 11.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 51.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 9.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 1.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 30.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 11.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 14.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.2 Instruct 3B",
      "company": "Meta",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
      "release_date": "2024-09-25",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.06,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.06,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 3212749824,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 3212749824,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 11.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 3.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 34.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 25.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 8.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 48.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 6.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 3.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 26.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 21.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.2 Instruct 1B",
      "company": "Meta",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
      "release_date": "2024-09-25",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.06,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 1230000000,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 1230000000,
          "source": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 8.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 1.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 20,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 19.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 1.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 1.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 14,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 22.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 12.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.1 Instruct 405B",
      "company": "Meta",
      "url": "https://ai.meta.com/blog/meta-llama-3-1/",
      "release_date": "2024-07-23",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1,
          "source": "https://www.llama.com/models/llama-3/"
        },
        {
          "name": "Output cost",
          "score": 1.8,
          "source": "https://www.llama.com/models/llama-3/"
        },
        {
          "name": "Size",
          "score": 405886943232,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "Active parameters",
          "score": 405886943232,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "MMLU",
          "score": 87.3,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "MMLU Pro (thinking)",
          "score": 73.3,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "AGIEval English",
          "score": 71.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "CommonSenseQA",
          "score": 85.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "Winogrande",
          "score": 86.7,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "BIG-Bench Hard (thinking)",
          "score": 85.9,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "ARC-Challenge",
          "score": 96.9,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "TriviaQA-Wiki",
          "score": 91.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "SQuAD",
          "score": 89.3,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "QuAC",
          "score": 53.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "BoolQ",
          "score": 80.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "DROP",
          "score": 84.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "IFEval",
          "score": 88.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "GPQA",
          "score": 50.7,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "HumanEval",
          "score": 89.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "MBPP",
          "score": 88.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "Multipl-E HumanEval",
          "score": 75.2,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "Multipl-E MBPP",
          "score": 65.7,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "GSM8K (thinking)",
          "score": 96.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "MATH (thinking)",
          "score": 73.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "API-Bank",
          "score": 92.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "BFCL",
          "score": 88.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "Gorilla",
          "score": 35.3,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "Nexus",
          "score": 58.7,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "MGSM (thinking)",
          "score": 91.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-405B"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 28.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 22.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 73.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 51.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 30.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 29.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 70.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 21.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 39,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 24.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 6.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 19,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.1 Instruct 70B",
      "company": "Meta",
      "url": "https://ai.meta.com/blog/meta-llama-3-1/",
      "release_date": "2024-07-23",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.72,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.72,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 70553706496,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 70553706496,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct"
        },
        {
          "name": "MMLU",
          "score": 83.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "MMLU Pro (thinking)",
          "score": 66.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "AGIEval English",
          "score": 64.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "CommonSenseQA",
          "score": 84.1,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "Winogrande",
          "score": 83.3,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "BIG-Bench Hard (thinking)",
          "score": 81.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "ARC-Challenge",
          "score": 94.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "TriviaQA-Wiki",
          "score": 89.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "SQuAD",
          "score": 81.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "QuAC",
          "score": 51.1,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "BoolQ",
          "score": 79.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "DROP",
          "score": 79.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "IFEval",
          "score": 87.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "GPQA",
          "score": 46.7,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "HumanEval",
          "score": 80.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "MBPP",
          "score": 86.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "Multipl-E HumanEval",
          "score": 65.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "Multipl-E MBPP",
          "score": 62.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "GSM8K (thinking)",
          "score": 95.1,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "MATH (thinking)",
          "score": 68.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "API-Bank",
          "score": 90.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "BFCL",
          "score": 84.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "Gorilla",
          "score": 29.7,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "Nexus",
          "score": 56.7,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "MGSM (thinking)",
          "score": 86.9,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-70B"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 22.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 17.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 67.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 40.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 23.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 26.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 64.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 17.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 34.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 6.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 2.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 15.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3.1 Instruct 8B",
      "company": "Meta",
      "url": "https://ai.meta.com/blog/meta-llama-3-1/",
      "release_date": "2024-07-23",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 8030261248,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 8030261248,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
        },
        {
          "name": "MMLU",
          "score": 69.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "MMLU Pro (thinking)",
          "score": 48.3,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "AGIEval English",
          "score": 47.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "CommonSenseQA",
          "score": 75.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "Winogrande",
          "score": 60.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "BIG-Bench Hard (thinking)",
          "score": 64.2,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "ARC-Challenge",
          "score": 83.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "TriviaQA-Wiki",
          "score": 77.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "SQuAD",
          "score": 77.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "QuAC",
          "score": 44.9,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "BoolQ",
          "score": 75.0,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "DROP",
          "score": 59.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "IFEval",
          "score": 80.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "GPQA",
          "score": 30.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "HumanEval",
          "score": 72.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "MBPP",
          "score": 72.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "Multipl-E HumanEval",
          "score": 50.8,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "Multipl-E MBPP",
          "score": 52.4,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "GSM8K (thinking)",
          "score": 84.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "MATH (thinking)",
          "score": 51.9,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "API-Bank",
          "score": 82.6,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "BFCL",
          "score": 76.1,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "Gorilla",
          "score": 8.2,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "Nexus",
          "score": 38.5,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "MGSM (thinking)",
          "score": 68.9,
          "source": "https://huggingface.co/meta-llama/Llama-3.1-8B"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 16.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 8.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 4.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 47.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 25.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 11.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 13.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 51.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 7.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 4.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 28.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 15.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 16.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3 Instruct 70B",
      "company": "Meta",
      "url": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct",
      "release_date": "2024-04-18",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.65,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.88,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 70553706496,
          "source": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 70553706496,
          "source": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 13,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 57.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 37.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 19.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 18.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 48.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 3 Instruct 8B",
      "company": "Meta",
      "url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
      "release_date": "2024-04-18",
      "capabilities": {
        "input": ["text"],
        "output": ["text", "tool"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.16,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 8030261248,
          "source": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct"
        },
        {
          "name": "Active parameters",
          "score": 8030261248,
          "source": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 40.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 29.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 9.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 11.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 49.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 2 Chat 70B",
      "company": "Meta",
      "url": "https://www.llama.com/llama2/",
      "release_date": "2023-07-18",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 68976658432,
          "source": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf"
        },
        {
          "name": "Active parameters",
          "score": 68976658432,
          "source": "https://huggingface.co/meta-llama/Llama-2-70b-chat-hf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 5.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 40.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 32.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 9.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 32.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 2 Chat 13B",
      "company": "Meta",
      "url": "https://www.llama.com/llama2/",
      "release_date": "2023-07-18",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 13015869440,
          "source": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf"
        },
        {
          "name": "Active parameters",
          "score": 13015869440,
          "source": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 5.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 40.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 32.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 9.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 11.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 32.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 1.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 2 Chat 7B",
      "company": "Meta",
      "url": "https://www.llama.com/llama2/",
      "release_date": "2023-07-18",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0.25,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 6738417664,
          "source": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf"
        },
        {
          "name": "Active parameters",
          "score": 6738417664,
          "source": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 11.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU Pro",
          "score": 16.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 22.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 0.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 5.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Llama 65B",
      "company": "Meta",
      "url": "https://arxiv.org/abs/2302.13971",
      "release_date": "2023-02-24",
      "capabilities": {
        "input": ["text"],
        "output": ["text"]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 65200000000,
          "source": "https://arxiv.org/abs/2302.13971"
        },
        {
          "name": "Active parameters",
          "score": 65200000000,
          "source": "https://arxiv.org/abs/2302.13971"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    }
  ]
}
