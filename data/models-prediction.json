{
  "models": [
    {
      "name": "DeepSeek R1 0528",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "GPQA Diamond",
          "score": 81,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 27.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "FRAMES",
          "score": 83,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 73.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 1930,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 57.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 71.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 91.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 87.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 79.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 86.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Terminal-Bench",
          "score": 17.5,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000010310186,
          "source": "Multivariate regression",
          "stdDev": 1.739514909752563e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 54.86511483096955,
          "source": "Multivariate regression",
          "stdDev": 0.008577045818364064
        },
        {
          "name": "Tau-Bench Retail",
          "score": 82.48638405622714,
          "source": "Multivariate regression",
          "stdDev": 0.023551318932148037
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 23.06929118304295,
          "source": "Multivariate regression",
          "stdDev": 0.007831639280390674
        },
        {
          "name": "MMMU",
          "score": 77.42615850976736,
          "source": "Multivariate regression",
          "stdDev": 0.012381200295680846
        },
        {
          "name": "MMMU-Pro",
          "score": 57.129460298694426,
          "source": "Multivariate regression",
          "stdDev": 0.03734932082669016
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 81.42924697148547,
          "source": "Multivariate regression",
          "stdDev": 0.0256801845715694
        },
        {
          "name": "VideoMMMU",
          "score": 71.77494315180556,
          "source": "Multivariate regression",
          "stdDev": 0.015695838818386487
        },
        {
          "name": "ERQA",
          "score": 63.630373714794146,
          "source": "Multivariate regression",
          "stdDev": 0.016998348916853402
        },
        {
          "name": "SWE-Lancer",
          "score": 51.82212597116751,
          "source": "Multivariate regression",
          "stdDev": 0.03746560376198223
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 43.494583659944524,
          "source": "Multivariate regression",
          "stdDev": 0.016092690377463702
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 44.14302568604239,
          "source": "Multivariate regression",
          "stdDev": 0.016233435257038506
        },
        {
          "name": "COLLIE",
          "score": 50.61335597249433,
          "source": "Multivariate regression",
          "stdDev": 0.03142051055048308
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 58.780218835022595,
          "source": "Multivariate regression",
          "stdDev": 0.011042822537394248
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 56.11020673723246,
          "source": "Multivariate regression",
          "stdDev": 0.02091840212173117
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 80.5729892464052,
          "source": "Multivariate regression",
          "stdDev": 0.027814920597911654
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 57.386838406505944,
          "source": "Multivariate regression",
          "stdDev": 0.03563048728952525
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 57.142194625711596,
          "source": "Multivariate regression",
          "stdDev": 0.04542853966412251
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 63.26091466446826,
          "source": "Multivariate regression",
          "stdDev": 0.0310743496862982
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 83.88096907383823,
          "source": "Multivariate regression",
          "stdDev": 0.07662454828652167
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.1269155903392,
          "source": "Multivariate regression",
          "stdDev": 0.004783958148708554
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 80.22798451891765,
          "source": "Multivariate regression",
          "stdDev": 0.034107354453670774
        },
        {
          "name": "VideoMME",
          "score": 89.76137522775451,
          "source": "Multivariate regression",
          "stdDev": 0.14552475747349478
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.8548160768558191,
          "source": "Multivariate regression",
          "stdDev": 0.0017704430764541549
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.012279645949377,
          "source": "Multivariate regression",
          "stdDev": 0.0030236294248787
        },
        {
          "name": "FActScore hallucination rate",
          "score": 16.229320242245308,
          "source": "Multivariate regression",
          "stdDev": 0.012184923699798407
        },
        {
          "name": "MMMLU",
          "score": 85.86368081743773,
          "source": "Multivariate regression",
          "stdDev": 0.0027619106528165216
        }
      ]
    },
    {
      "name": "DeepSeek R1",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "MMLU-Pro",
          "score": 84,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "GPQA Diamond",
          "score": 71.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 30.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "FRAMES",
          "score": 82.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 63.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 1530,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 49.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 55.099999999999994,
          "source": "Multiple: Score 56.9 at undefined; Score 53.3 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 2.545584412271572
        },
        {
          "name": "AIME 2024",
          "score": 79.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 70,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 41.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 78.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Terminal-Bench",
          "score": 17.704337213165218,
          "source": "Multivariate regression",
          "stdDev": 0.009845138177427125
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Airline",
          "score": 53.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Retail",
          "score": 63.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 15.363876943488364,
          "source": "Multivariate regression",
          "stdDev": 0.0075841859518693995
        },
        {
          "name": "MMMU",
          "score": 69.40907692859335,
          "source": "Multivariate regression",
          "stdDev": 0.012342627210013321
        },
        {
          "name": "MMMU-Pro",
          "score": 65.75616326318641,
          "source": "Multivariate regression",
          "stdDev": 0.03620840270394817
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 58.67204895565641,
          "source": "Multivariate regression",
          "stdDev": 0.025754350640144204
        },
        {
          "name": "VideoMMMU",
          "score": 48.54656412595784,
          "source": "Multivariate regression",
          "stdDev": 0.01563496106742692
        },
        {
          "name": "ERQA",
          "score": 52.28550373956129,
          "source": "Multivariate regression",
          "stdDev": 0.016658324468631778
        },
        {
          "name": "SWE-Lancer",
          "score": 69.15485240429962,
          "source": "Multivariate regression",
          "stdDev": 0.03726141001340874
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 52.63955078037378,
          "source": "Multivariate regression",
          "stdDev": 0.015853872998534548
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 42.87493014309261,
          "source": "Multivariate regression",
          "stdDev": 0.016174581033573894
        },
        {
          "name": "COLLIE",
          "score": 104.49001843746635,
          "source": "Multivariate regression",
          "stdDev": 0.029928176504391626
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 41.84508916585537,
          "source": "Multivariate regression",
          "stdDev": 0.010647105744977181
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 61.86364241182366,
          "source": "Multivariate regression",
          "stdDev": 0.020363972199271368
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 65.13116382582291,
          "source": "Multivariate regression",
          "stdDev": 0.027400394600705664
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 53.300501238109064,
          "source": "Multivariate regression",
          "stdDev": 0.034982213441998214
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 55.27879730547198,
          "source": "Multivariate regression",
          "stdDev": 0.0465893092828414
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 68.923871133447,
          "source": "Multivariate regression",
          "stdDev": 0.0303288450363485
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 49.64340233799874,
          "source": "Multivariate regression",
          "stdDev": 0.07622523364256413
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 81.55840353107966,
          "source": "Multivariate regression",
          "stdDev": 0.004845854105970265
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 51.53156806238371,
          "source": "Multivariate regression",
          "stdDev": 0.033770156118007294
        },
        {
          "name": "VideoMME",
          "score": 85.64971465937776,
          "source": "Multivariate regression",
          "stdDev": 0.14636118222643418
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.3475949349721006,
          "source": "Multivariate regression",
          "stdDev": 0.0017321542183708193
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 0.7217465057678254,
          "source": "Multivariate regression",
          "stdDev": 0.0030038517955188
        },
        {
          "name": "FActScore hallucination rate",
          "score": 16.884717734784488,
          "source": "Multivariate regression",
          "stdDev": 0.012027371629091864
        },
        {
          "name": "MMMLU",
          "score": 83.36243104120666,
          "source": "Multivariate regression",
          "stdDev": 0.0026853152404724572
        }
      ]
    },
    {
      "name": "DeepSeek-R1-0528-Qwen3-8B",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.07855142164762,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.19956766296664,
          "source": "Multivariate regression",
          "stdDev": 0.0021960830295598317
        },
        {
          "name": "GPQA Diamond",
          "score": 61.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 30.096489273553736,
          "source": "Multivariate regression",
          "stdDev": 0.0017508572949341344
        },
        {
          "name": "FRAMES",
          "score": 82.73887811381525,
          "source": "Multivariate regression",
          "stdDev": 0.0002983693789649927
        },
        {
          "name": "Humanity's Last Exam",
          "score": 16.246278645769365,
          "source": "Multivariate regression",
          "stdDev": 0.0070833638818121325
        },
        {
          "name": "LiveCodeBench",
          "score": 60.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2830.0438519302133,
          "source": "Multivariate regression",
          "stdDev": 0.44502717665585084
        },
        {
          "name": "SWE-bench Verified",
          "score": 56.69634038587549,
          "source": "Multivariate regression",
          "stdDev": 0.021859888907644006
        },
        {
          "name": "Aider",
          "score": 56.9357113580063,
          "source": "Multivariate regression",
          "stdDev": 0.03821940188547982
        },
        {
          "name": "AIME 2024",
          "score": 86,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 76.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 61.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 82.67479655310345,
          "source": "Multivariate regression",
          "stdDev": 0.011722281974639641
        },
        {
          "name": "Terminal-Bench",
          "score": 37.305850519412786,
          "source": "Multivariate regression",
          "stdDev": 0.010271797047269252
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999945344738,
          "source": "Multivariate regression",
          "stdDev": 1.7351589722338323e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.05172869510427,
          "source": "Multivariate regression",
          "stdDev": 0.008604798203823236
        },
        {
          "name": "Tau-Bench Retail",
          "score": 69.85150016533844,
          "source": "Multivariate regression",
          "stdDev": 0.023632167076029647
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 16.66930608059809,
          "source": "Multivariate regression",
          "stdDev": 0.007831639280390674
        },
        {
          "name": "MMMU",
          "score": 79.53374264153734,
          "source": "Multivariate regression",
          "stdDev": 0.012496205172410792
        },
        {
          "name": "MMMU-Pro",
          "score": 73.57464741710942,
          "source": "Multivariate regression",
          "stdDev": 0.036731395277439856
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 62.09368017727397,
          "source": "Multivariate regression",
          "stdDev": 0.0256801845715694
        },
        {
          "name": "VideoMMMU",
          "score": 71.40540825695876,
          "source": "Multivariate regression",
          "stdDev": 0.01572618932002201
        },
        {
          "name": "ERQA",
          "score": 47.04615184431414,
          "source": "Multivariate regression",
          "stdDev": 0.017054360572355206
        },
        {
          "name": "SWE-Lancer",
          "score": 44.508213778675554,
          "source": "Multivariate regression",
          "stdDev": 0.03726141001340874
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 63.77500944331064,
          "source": "Multivariate regression",
          "stdDev": 0.016210779773056502
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 49.39134223265117,
          "source": "Multivariate regression",
          "stdDev": 0.01652456242714231
        },
        {
          "name": "COLLIE",
          "score": 69.68893248231132,
          "source": "Multivariate regression",
          "stdDev": 0.031902446009326915
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 57.71282013594367,
          "source": "Multivariate regression",
          "stdDev": 0.010956120707603118
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 73.09783127928338,
          "source": "Multivariate regression",
          "stdDev": 0.021099974925522947
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 24.54403277874485,
          "source": "Multivariate regression",
          "stdDev": 0.028019884005202538
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 51.209429395075176,
          "source": "Multivariate regression",
          "stdDev": 0.03519963133846746
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 76.3248455822972,
          "source": "Multivariate regression",
          "stdDev": 0.04559617314070614
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 56.42838256481605,
          "source": "Multivariate regression",
          "stdDev": 0.03064167631783493
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 65.85558144412539,
          "source": "Multivariate regression",
          "stdDev": 0.0760247898105512
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 85.31514783881472,
          "source": "Multivariate regression",
          "stdDev": 0.00480881213478927
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 70.93535085032713,
          "source": "Multivariate regression",
          "stdDev": 0.03399532663907034
        },
        {
          "name": "VideoMME",
          "score": 67.03791839490844,
          "source": "Multivariate regression",
          "stdDev": 0.14552475747349478
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.957266727296492,
          "source": "Multivariate regression",
          "stdDev": 0.0017662297488635517
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.0524312801360622,
          "source": "Multivariate regression",
          "stdDev": 0.00306280157341181
        },
        {
          "name": "FActScore hallucination rate",
          "score": 19.395854280401863,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 87.82852474032707,
          "source": "Multivariate regression",
          "stdDev": 0.0027293472699191673
        }
      ]
    },
    {
      "name": "GPT-5 High",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.10967391525779,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.6240048067539,
          "source": "Multivariate regression",
          "stdDev": 0.0021960830295598317
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 30.17719381805596,
          "source": "Multivariate regression",
          "stdDev": 0.001746596721063631
        },
        {
          "name": "FRAMES",
          "score": 82.56149422996045,
          "source": "Multivariate regression",
          "stdDev": 0.0002968045884573551
        },
        {
          "name": "Humanity's Last Exam",
          "score": 24.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 62.78556799733488,
          "source": "Multivariate regression",
          "stdDev": 0.018344005853313302
        },
        {
          "name": "Codeforces",
          "score": 1814.8560345375608,
          "source": "Multivariate regression",
          "stdDev": 0.43616130956594246
        },
        {
          "name": "SWE-bench Verified",
          "score": 74.9,
          "source": "Multiple: Score 74.9 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 74.9 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 74.9 at undefined",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 88,
          "source": "Multiple: Score 88 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 88 at https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 83.90702651260904,
          "source": "Multivariate regression",
          "stdDev": 0.006879568227906105
        },
        {
          "name": "AIME 2025",
          "score": 94.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 93.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 84.09477719762612,
          "source": "Multivariate regression",
          "stdDev": 0.011843686826414323
        },
        {
          "name": "Terminal-Bench",
          "score": 25.36098668379705,
          "source": "Multivariate regression",
          "stdDev": 0.010248559773065005
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.0000003694847,
          "source": "Multivariate regression",
          "stdDev": 1.741744817361735e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 54.27570162510546,
          "source": "Multivariate regression",
          "stdDev": 0.008632461368967875
        },
        {
          "name": "Tau-Bench Retail",
          "score": 68.45896515083311,
          "source": "Multivariate regression",
          "stdDev": 0.02371273957127275
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 26.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU",
          "score": 84.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 78.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 81.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 84.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 65.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 112,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 69.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 64,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "COLLIE",
          "score": 99,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 62.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 81.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 96.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 95.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 86.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 78.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 73.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 90,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 88.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMME",
          "score": 86.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "FActScore hallucination rate",
          "score": 2.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMLU",
          "score": 83.83262105104069,
          "source": "Multivariate regression",
          "stdDev": 0.0027780492114619693
        }
      ]
    },
    {
      "name": "GPT-5 Medium",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.99134874462024,
          "source": "Multivariate regression",
          "stdDev": 0.00040558495386635224
        },
        {
          "name": "MMLU-Pro",
          "score": 84.23512899911967,
          "source": "Multivariate regression",
          "stdDev": 0.0021271477261449743
        },
        {
          "name": "GPQA Diamond",
          "score": 82.27143351509702,
          "source": "Multivariate regression",
          "stdDev": 0.0117831049272791
        },
        {
          "name": "SimpleQA",
          "score": 28.23784327478812,
          "source": "Multivariate regression",
          "stdDev": 0.001746596721063631
        },
        {
          "name": "FRAMES",
          "score": 82.58741678152192,
          "source": "Multivariate regression",
          "stdDev": 0.0002991487048129461
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.39602261853868,
          "source": "Multivariate regression",
          "stdDev": 0.006981656852606784
        },
        {
          "name": "LiveCodeBench",
          "score": 80.59620686260544,
          "source": "Multivariate regression",
          "stdDev": 0.018291943639580248
        },
        {
          "name": "Codeforces",
          "score": 2620.8506527317513,
          "source": "Multivariate regression",
          "stdDev": 0.44502717665585084
        },
        {
          "name": "SWE-bench Verified",
          "score": 72,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 63.897357951046274,
          "source": "Multivariate regression",
          "stdDev": 0.037717047973397505
        },
        {
          "name": "AIME 2024",
          "score": 84.60924575871192,
          "source": "Multivariate regression",
          "stdDev": 0.006879568227906105
        },
        {
          "name": "AIME 2025",
          "score": 76.46379845861111,
          "source": "Multivariate regression",
          "stdDev": 0.02114972882014868
        },
        {
          "name": "HMMT 2025",
          "score": 86.28596302000767,
          "source": "Multivariate regression",
          "stdDev": 0.03775032419014487
        },
        {
          "name": "CNMO 2024",
          "score": 81.53500166704197,
          "source": "Multivariate regression",
          "stdDev": 0.011138242871444038
        },
        {
          "name": "Terminal-Bench",
          "score": 25.303615583578505,
          "source": "Multivariate regression",
          "stdDev": 0.010084399700262993
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.999999686831025,
          "source": "Multivariate regression",
          "stdDev": 1.7502334404879304e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 57.12436380956064,
          "source": "Multivariate regression",
          "stdDev": 0.008577045818364064
        },
        {
          "name": "Tau-Bench Retail",
          "score": 81.50418306832981,
          "source": "Multivariate regression",
          "stdDev": 0.022894257911510358
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.495889017291645,
          "source": "Multivariate regression",
          "stdDev": 0.007862023338579025
        },
        {
          "name": "MMMU",
          "score": 71.71336093264144,
          "source": "Multivariate regression",
          "stdDev": 0.01206916427224841
        },
        {
          "name": "MMMU-Pro",
          "score": 70.67362886086829,
          "source": "Multivariate regression",
          "stdDev": 0.037553036565336914
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 72.18288184727942,
          "source": "Multivariate regression",
          "stdDev": 0.024926389770153663
        },
        {
          "name": "VideoMMMU",
          "score": 41.21216615566573,
          "source": "Multivariate regression",
          "stdDev": 0.015847010058518903
        },
        {
          "name": "ERQA",
          "score": 68.14374821409852,
          "source": "Multivariate regression",
          "stdDev": 0.016829195465043887
        },
        {
          "name": "SWE-Lancer",
          "score": 65.41693680099763,
          "source": "Multivariate regression",
          "stdDev": 0.03611771499338804
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 61.604580860216316,
          "source": "Multivariate regression",
          "stdDev": 0.01615184299755682
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 48.12089501309349,
          "source": "Multivariate regression",
          "stdDev": 0.016292076874274603
        },
        {
          "name": "COLLIE",
          "score": 94.00840425933063,
          "source": "Multivariate regression",
          "stdDev": 0.03178264725989276
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 44.494966363274955,
          "source": "Multivariate regression",
          "stdDev": 0.01091251147276206
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 61.7870762513887,
          "source": "Multivariate regression",
          "stdDev": 0.02091840212173117
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 42.21401073256425,
          "source": "Multivariate regression",
          "stdDev": 0.028019884005202538
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 39.48036288962578,
          "source": "Multivariate regression",
          "stdDev": 0.034872996182867204
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 55.17024234514068,
          "source": "Multivariate regression",
          "stdDev": 0.04592960464887818
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 70.12543028682848,
          "source": "Multivariate regression",
          "stdDev": 0.030827851358209205
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 77.00608131911804,
          "source": "Multivariate regression",
          "stdDev": 0.0760247898105512
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.40974297861965,
          "source": "Multivariate regression",
          "stdDev": 0.00480881213478927
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 49.26735099332342,
          "source": "Multivariate regression",
          "stdDev": 0.03388292842665515
        },
        {
          "name": "VideoMME",
          "score": 84.1289675519381,
          "source": "Multivariate regression",
          "stdDev": 0.14169976085096075
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 3.5350215612671576,
          "source": "Multivariate regression",
          "stdDev": 0.0017955154285406569
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.5658949786733274,
          "source": "Multivariate regression",
          "stdDev": 0.00304327852628429
        },
        {
          "name": "FActScore hallucination rate",
          "score": 12.418561164672724,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 86.78384760644144,
          "source": "Multivariate regression",
          "stdDev": 0.0027619106528165216
        }
      ]
    },
    {
      "name": "GPT-5 Low",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.29112450259629,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 84.3271464513926,
          "source": "Multivariate regression",
          "stdDev": 0.0021687718605630023
        },
        {
          "name": "GPQA Diamond",
          "score": 74.77748478505147,
          "source": "Multivariate regression",
          "stdDev": 0.011413084284259568
        },
        {
          "name": "SimpleQA",
          "score": 29.07357263725949,
          "source": "Multivariate regression",
          "stdDev": 0.0017380442409911585
        },
        {
          "name": "FRAMES",
          "score": 82.59705053631603,
          "source": "Multivariate regression",
          "stdDev": 0.0002888535110679158
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.447168768603184,
          "source": "Multivariate regression",
          "stdDev": 0.0070326942308660025
        },
        {
          "name": "LiveCodeBench",
          "score": 76.57077281769466,
          "source": "Multivariate regression",
          "stdDev": 0.018082195872800688
        },
        {
          "name": "Codeforces",
          "score": 1889.5208780187932,
          "source": "Multivariate regression",
          "stdDev": 0.43616130956594246
        },
        {
          "name": "SWE-bench Verified",
          "score": 69,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 55.563644010488645,
          "source": "Multivariate regression",
          "stdDev": 0.037818052598710294
        },
        {
          "name": "AIME 2024",
          "score": 87.0361909611002,
          "source": "Multivariate regression",
          "stdDev": 0.0068448244567857275
        },
        {
          "name": "AIME 2025",
          "score": 83.60587487140504,
          "source": "Multivariate regression",
          "stdDev": 0.02101401873196534
        },
        {
          "name": "HMMT 2025",
          "score": 77.04189346391368,
          "source": "Multivariate regression",
          "stdDev": 0.03855025463873146
        },
        {
          "name": "CNMO 2024",
          "score": 79.85722431341189,
          "source": "Multivariate regression",
          "stdDev": 0.011681533305887339
        },
        {
          "name": "Terminal-Bench",
          "score": 27.604567561526267,
          "source": "Multivariate regression",
          "stdDev": 0.010037003686273015
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999980499618,
          "source": "Multivariate regression",
          "stdDev": 1.733051971604146e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 53.03880358613017,
          "source": "Multivariate regression",
          "stdDev": 0.008493244580000454
        },
        {
          "name": "Tau-Bench Retail",
          "score": 76.30489700782482,
          "source": "Multivariate regression",
          "stdDev": 0.023307091874510633
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 13.589572283938296,
          "source": "Multivariate regression",
          "stdDev": 0.007739771465847604
        },
        {
          "name": "MMMU",
          "score": 77.99778356536467,
          "source": "Multivariate regression",
          "stdDev": 0.01230393319751676
        },
        {
          "name": "MMMU-Pro",
          "score": 64.3254147245978,
          "source": "Multivariate regression",
          "stdDev": 0.03693851902946342
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 74.7704025756662,
          "source": "Multivariate regression",
          "stdDev": 0.0256801845715694
        },
        {
          "name": "VideoMMMU",
          "score": 54.51343628366607,
          "source": "Multivariate regression",
          "stdDev": 0.014980815963605733
        },
        {
          "name": "ERQA",
          "score": 54.5070712925657,
          "source": "Multivariate regression",
          "stdDev": 0.016772431885920456
        },
        {
          "name": "SWE-Lancer",
          "score": 68.52232941759291,
          "source": "Multivariate regression",
          "stdDev": 0.03766869063708423
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 51.69623429804,
          "source": "Multivariate regression",
          "stdDev": 0.015733104963357926
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 48.710346984865254,
          "source": "Multivariate regression",
          "stdDev": 0.01652456242714231
        },
        {
          "name": "COLLIE",
          "score": 106.69417541663245,
          "source": "Multivariate regression",
          "stdDev": 0.03178264725989276
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 53.02271617950686,
          "source": "Multivariate regression",
          "stdDev": 0.010780625385103817
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 72.15500744454067,
          "source": "Multivariate regression",
          "stdDev": 0.02091840212173117
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 49.716853229771175,
          "source": "Multivariate regression",
          "stdDev": 0.025823599370161977
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 56.44615878295917,
          "source": "Multivariate regression",
          "stdDev": 0.03519963133846746
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 51.510482501737755,
          "source": "Multivariate regression",
          "stdDev": 0.045763192569353725
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 68.32639996285934,
          "source": "Multivariate regression",
          "stdDev": 0.030827851358209205
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 61.59640276730238,
          "source": "Multivariate regression",
          "stdDev": 0.07562230827929342
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 86.35513127339473,
          "source": "Multivariate regression",
          "stdDev": 0.004746433155532965
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 85.26564425020047,
          "source": "Multivariate regression",
          "stdDev": 0.033657005952748315
        },
        {
          "name": "VideoMME",
          "score": 84.63925310493067,
          "source": "Multivariate regression",
          "stdDev": 0.14341235468124588
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.306613289357429,
          "source": "Multivariate regression",
          "stdDev": 0.0017321542183708193
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 4.051025177816115,
          "source": "Multivariate regression",
          "stdDev": 0.002943721749892332
        },
        {
          "name": "FActScore hallucination rate",
          "score": 28.027718272766208,
          "source": "Multivariate regression",
          "stdDev": 0.011947816523175748
        },
        {
          "name": "MMMLU",
          "score": 87.78106173986815,
          "source": "Multivariate regression",
          "stdDev": 0.0027019113434523967
        }
      ]
    },
    {
      "name": "GPT-5 Minimal",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.60071991619989,
          "source": "Multivariate regression",
          "stdDev": 0.00040558495386635224
        },
        {
          "name": "MMLU-Pro",
          "score": 85.0231870798323,
          "source": "Multivariate regression",
          "stdDev": 0.0021549864821837086
        },
        {
          "name": "GPQA Diamond",
          "score": 63.57224713990386,
          "source": "Multivariate regression",
          "stdDev": 0.011537743099446766
        },
        {
          "name": "SimpleQA",
          "score": 29.10034194121735,
          "source": "Multivariate regression",
          "stdDev": 0.0017034049706666206
        },
        {
          "name": "FRAMES",
          "score": 82.98181488948657,
          "source": "Multivariate regression",
          "stdDev": 0.0002944418106645466
        },
        {
          "name": "Humanity's Last Exam",
          "score": 9.419620920915975,
          "source": "Multivariate regression",
          "stdDev": 0.006895755180692209
        },
        {
          "name": "LiveCodeBench",
          "score": 58.768801395027275,
          "source": "Multivariate regression",
          "stdDev": 0.018187372125954733
        },
        {
          "name": "Codeforces",
          "score": 2218.1282220818957,
          "source": "Multivariate regression",
          "stdDev": 0.43616130956594246
        },
        {
          "name": "SWE-bench Verified",
          "score": 59,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 48.390436962837214,
          "source": "Multivariate regression",
          "stdDev": 0.03669171245002158
        },
        {
          "name": "AIME 2024",
          "score": 86.19641400557438,
          "source": "Multivariate regression",
          "stdDev": 0.00656025339286426
        },
        {
          "name": "AIME 2025",
          "score": 64.41421139157791,
          "source": "Multivariate regression",
          "stdDev": 0.02105935259926579
        },
        {
          "name": "HMMT 2025",
          "score": 72.47870052002821,
          "source": "Multivariate regression",
          "stdDev": 0.03785124001921584
        },
        {
          "name": "CNMO 2024",
          "score": 84.9820864971646,
          "source": "Multivariate regression",
          "stdDev": 0.01139221225933363
        },
        {
          "name": "Terminal-Bench",
          "score": 34.44042221879698,
          "source": "Multivariate regression",
          "stdDev": 0.00998938279784351
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999907595354,
          "source": "Multivariate regression",
          "stdDev": 1.709151799996951e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 57.706590988590136,
          "source": "Multivariate regression",
          "stdDev": 0.008351707472408949
        },
        {
          "name": "Tau-Bench Retail",
          "score": 85.87439821103813,
          "source": "Multivariate regression",
          "stdDev": 0.02338878425469149
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 19.36896196221224,
          "source": "Multivariate regression",
          "stdDev": 0.007677915604325338
        },
        {
          "name": "MMMU",
          "score": 78.21406674032939,
          "source": "Multivariate regression",
          "stdDev": 0.012187114062801587
        },
        {
          "name": "MMMU-Pro",
          "score": 71.99419012896999,
          "source": "Multivariate regression",
          "stdDev": 0.036731395277439856
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 50.289079625426865,
          "source": "Multivariate regression",
          "stdDev": 0.025306093995355074
        },
        {
          "name": "VideoMMMU",
          "score": 79.22274765397833,
          "source": "Multivariate regression",
          "stdDev": 0.015481719413486486
        },
        {
          "name": "ERQA",
          "score": 46.79237974747829,
          "source": "Multivariate regression",
          "stdDev": 0.016543430020300846
        },
        {
          "name": "SWE-Lancer",
          "score": 35.115675573935164,
          "source": "Multivariate regression",
          "stdDev": 0.037363646378781167
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 39.78527163628594,
          "source": "Multivariate regression",
          "stdDev": 0.016092690377463702
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 63.06459736084466,
          "source": "Multivariate regression",
          "stdDev": 0.016350508172839333
        },
        {
          "name": "COLLIE",
          "score": 54.902578471359334,
          "source": "Multivariate regression",
          "stdDev": 0.03129886721147858
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 47.602753846151586,
          "source": "Multivariate regression",
          "stdDev": 0.010934337830951022
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 63.79682736385462,
          "source": "Multivariate regression",
          "stdDev": 0.020596798462303785
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 45.55698952175857,
          "source": "Multivariate regression",
          "stdDev": 0.027190761895862812
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 67.84573339216331,
          "source": "Multivariate regression",
          "stdDev": 0.03443266304898984
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 41.967993646965084,
          "source": "Multivariate regression",
          "stdDev": 0.04492188607824978
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 49.38347571942353,
          "source": "Multivariate regression",
          "stdDev": 0.030579366087303723
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 55.84569341963555,
          "source": "Multivariate regression",
          "stdDev": 0.07521767314427169
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 92.44521931638062,
          "source": "Multivariate regression",
          "stdDev": 0.0047964012403202624
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 71.43392770426757,
          "source": "Multivariate regression",
          "stdDev": 0.033657005952748315
        },
        {
          "name": "VideoMME",
          "score": 65.8073787333019,
          "source": "Multivariate regression",
          "stdDev": 0.1446834973751999
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": -0.7386373735620637,
          "source": "Multivariate regression",
          "stdDev": 0.001753529025191503
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.8343514194006332,
          "source": "Multivariate regression",
          "stdDev": 0.0030334698850932556
        },
        {
          "name": "FActScore hallucination rate",
          "score": 8.960333353434464,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 86.82730754041015,
          "source": "Multivariate regression",
          "stdDev": 0.002712919009600568
        }
      ]
    },
    {
      "name": "GPT-5 mini High",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.1738758615984,
          "source": "Multivariate regression",
          "stdDev": 0.00037702441964944334
        },
        {
          "name": "MMLU-Pro",
          "score": 84.71815124982922,
          "source": "Multivariate regression",
          "stdDev": 0.001997076775155432
        },
        {
          "name": "GPQA Diamond",
          "score": 82.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.27436935101776,
          "source": "Multivariate regression",
          "stdDev": 0.001585609757491329
        },
        {
          "name": "FRAMES",
          "score": 82.67110465143209,
          "source": "Multivariate regression",
          "stdDev": 0.00027139908589160727
        },
        {
          "name": "Humanity's Last Exam",
          "score": 16.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 70.98915206860556,
          "source": "Multivariate regression",
          "stdDev": 0.016539650717701998
        },
        {
          "name": "Codeforces",
          "score": 2034.3603558755403,
          "source": "Multivariate regression",
          "stdDev": 0.4225138316816124
        },
        {
          "name": "SWE-bench Verified",
          "score": 71,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 71.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 87.07321736822209,
          "source": "Multivariate regression",
          "stdDev": 0.006262765149114409
        },
        {
          "name": "AIME 2025",
          "score": 91.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 87.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 81.25966889072426,
          "source": "Multivariate regression",
          "stdDev": 0.010656924358500682
        },
        {
          "name": "Terminal-Bench",
          "score": 34.40825156152306,
          "source": "Multivariate regression",
          "stdDev": 0.00932272306841555
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000012021787,
          "source": "Multivariate regression",
          "stdDev": 1.5927424528916333e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 51.84129110628621,
          "source": "Multivariate regression",
          "stdDev": 0.0077597857277523444
        },
        {
          "name": "Tau-Bench Retail",
          "score": 74.1535149586285,
          "source": "Multivariate regression",
          "stdDev": 0.021520034597294554
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 22.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU",
          "score": 81.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 74.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 75.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 82.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 62.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 75,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 62.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 65.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "COLLIE",
          "score": 98.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 60,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 78.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 74.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 84.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 58.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 73.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 64.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 86,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMME",
          "score": 78.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "FActScore hallucination rate",
          "score": 3.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMLU",
          "score": 86.49983986858764,
          "source": "Multivariate regression",
          "stdDev": 0.0025369386194059903
        }
      ]
    },
    {
      "name": "GPT-5 nano High",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.09661306823702,
          "source": "Multivariate regression",
          "stdDev": 0.0003962935455011187
        },
        {
          "name": "MMLU-Pro",
          "score": 84.33181266815548,
          "source": "Multivariate regression",
          "stdDev": 0.0020775324767930508
        },
        {
          "name": "GPQA Diamond",
          "score": 71.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.8816330150252,
          "source": "Multivariate regression",
          "stdDev": 0.001663573876732597
        },
        {
          "name": "FRAMES",
          "score": 82.69790670191415,
          "source": "Multivariate regression",
          "stdDev": 0.0002815055936753174
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 72.59019533677025,
          "source": "Multivariate regression",
          "stdDev": 0.017546860723622482
        },
        {
          "name": "Codeforces",
          "score": 1978.2572343983938,
          "source": "Multivariate regression",
          "stdDev": 0.4225138316816124
        },
        {
          "name": "SWE-bench Verified",
          "score": 54.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 48.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 81.43708209659732,
          "source": "Multivariate regression",
          "stdDev": 0.0065238092722261515
        },
        {
          "name": "AIME 2025",
          "score": 85.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 75.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 80.18277604268678,
          "source": "Multivariate regression",
          "stdDev": 0.01109534947385019
        },
        {
          "name": "Terminal-Bench",
          "score": 41.22849671115205,
          "source": "Multivariate regression",
          "stdDev": 0.009649458454597755
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.999999798468934,
          "source": "Multivariate regression",
          "stdDev": 1.6518874979166076e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 55.41561904328322,
          "source": "Multivariate regression",
          "stdDev": 0.0079719592728545
        },
        {
          "name": "Tau-Bench Retail",
          "score": 70.51801111304592,
          "source": "Multivariate regression",
          "stdDev": 0.022388811083329203
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 9.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU",
          "score": 75.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 62.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 62.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 66.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 50.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 49,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 54.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 56.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "COLLIE",
          "score": 96.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 41,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 62.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 35.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 43.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 34.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 64,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 43.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 80.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 68.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMME",
          "score": 65.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "FActScore hallucination rate",
          "score": 7.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMLU",
          "score": 89.7117585241217,
          "source": "Multivariate regression",
          "stdDev": 0.002606469916819666
        }
      ]
    },
    {
      "name": "o4-mini",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.17212366415568,
          "source": "Multivariate regression",
          "stdDev": 0.00037205123667787704
        },
        {
          "name": "MMLU-Pro",
          "score": 84.1892518057642,
          "source": "Multivariate regression",
          "stdDev": 0.002120130922008365
        },
        {
          "name": "GPQA Diamond",
          "score": 81.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 28.970529256956418,
          "source": "Multivariate regression",
          "stdDev": 0.0016990254067841078
        },
        {
          "name": "FRAMES",
          "score": 82.88789536347817,
          "source": "Multivariate regression",
          "stdDev": 0.0002928560350971126
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 68.65659784738813,
          "source": "Multivariate regression",
          "stdDev": 0.018082195872800688
        },
        {
          "name": "Codeforces",
          "score": 2352.740827594682,
          "source": "Multivariate regression",
          "stdDev": 0.43166009540178474
        },
        {
          "name": "SWE-bench Verified",
          "score": 68.55,
          "source": "Multiple: Score 68.1 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 69 at undefined",
          "stdDev": 0.6363961030678968
        },
        {
          "name": "Aider",
          "score": 65.1,
          "source": "Multiple: Score 58.2 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 72 at undefined",
          "stdDev": 9.758073580374354
        },
        {
          "name": "AIME 2024",
          "score": 83.128142597867,
          "source": "Multivariate regression",
          "stdDev": 0.006686243686278415
        },
        {
          "name": "AIME 2025",
          "score": 92.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 85,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 81.52079204811957,
          "source": "Multivariate regression",
          "stdDev": 0.01139221225933363
        },
        {
          "name": "Terminal-Bench",
          "score": 26.18751628185285,
          "source": "Multivariate regression",
          "stdDev": 0.009649458454597755
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000024385907,
          "source": "Multivariate regression",
          "stdDev": 1.698876141824805e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.347516883501825,
          "source": "Multivariate regression",
          "stdDev": 0.008436914671803956
        },
        {
          "name": "Tau-Bench Retail",
          "score": 74.22311678178454,
          "source": "Multivariate regression",
          "stdDev": 0.022810794551113945
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 15.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU",
          "score": 81.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 73.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 72,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 79.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 56.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 66,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 57.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 44.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "COLLIE",
          "score": 96.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 60.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 70.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 40.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 56.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 67.51331404335338,
          "source": "Multivariate regression",
          "stdDev": 0.04354199738559603
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 62.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 51.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 80,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 93.9884600794627,
          "source": "Multivariate regression",
          "stdDev": 0.033315249753072325
        },
        {
          "name": "VideoMME",
          "score": 79.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 8.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "FActScore hallucination rate",
          "score": 38.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMLU",
          "score": 88.26481696115219,
          "source": "Multivariate regression",
          "stdDev": 0.0026292384290582506
        }
      ]
    },
    {
      "name": "OpenAI o3 (high)",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.07561858926427,
          "source": "Multivariate regression",
          "stdDev": 0.00037205123667787704
        },
        {
          "name": "MMLU-Pro",
          "score": 84.3809566043326,
          "source": "Multivariate regression",
          "stdDev": 0.0020918283478586997
        },
        {
          "name": "GPQA Diamond",
          "score": 83.3,
          "source": "Multiple: Score 83.3 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 83.3 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 83.3 at https://www.anthropic.com/news/claude-opus-4-1; Score 83.3 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.053557015549032,
          "source": "Multivariate regression",
          "stdDev": 0.0016680465234941648
        },
        {
          "name": "FRAMES",
          "score": 82.71184257396119,
          "source": "Multivariate regression",
          "stdDev": 0.0002781775586226573
        },
        {
          "name": "Humanity's Last Exam",
          "score": 20.4,
          "source": "Multiple: Score 20.6 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 20.2 at https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0.2828427124746205
        },
        {
          "name": "LiveCodeBench",
          "score": 77.85,
          "source": "Multiple: Score 77.3 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 78.4 at undefined",
          "stdDev": 0.7778174593052083
        },
        {
          "name": "Codeforces",
          "score": 2706,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.1,
          "source": "Multiple: Score 69.1 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 69.1 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 69.1 at https://www.anthropic.com/news/claude-opus-4-1; Score 69.1 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 79.275,
          "source": "Multiple: Score 79.6 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 81 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 79.6 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 76.9 at undefined",
          "stdDev": 1.715371679840841
        },
        {
          "name": "AIME 2024",
          "score": 91.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 88.9,
          "source": "Multiple: Score 88.9 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 88.9 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 88.9 at https://www.anthropic.com/news/claude-opus-4-1; Score 88.9 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 81.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 83.83860117270382,
          "source": "Multivariate regression",
          "stdDev": 0.011223537895694318
        },
        {
          "name": "Terminal-Bench",
          "score": 30.2,
          "source": "Multiple: Score 30.2 at https://www.anthropic.com/news/claude-opus-4-1; Score 30.2 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000004942269,
          "source": "Multivariate regression",
          "stdDev": 1.675620957143063e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 52,
          "source": "Multiple: Score 52 at https://www.anthropic.com/news/claude-opus-4-1; Score 52 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Retail",
          "score": 70.4,
          "source": "Multiple: Score 70.4 at https://www.anthropic.com/news/claude-opus-4-1; Score 70.4 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 15.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU",
          "score": 82.9,
          "source": "Multiple: Score 82.9 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 82.9 at https://www.anthropic.com/news/claude-opus-4-1; Score 82.9 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 76.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 78.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 83.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 64,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 86,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 60.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 47.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "COLLIE",
          "score": 98.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 64.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 80.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 58.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 55,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 85.07262561067267,
          "source": "Multivariate regression",
          "stdDev": 0.04389103683501054
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 77.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 72.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 88.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 80.39601508765139,
          "source": "Multivariate regression",
          "stdDev": 0.0325038475321128
        },
        {
          "name": "VideoMME",
          "score": 84.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 5.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 6.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "FActScore hallucination rate",
          "score": 23.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMLU",
          "score": 88.8,
          "source": "Multiple: Score 88.8 at https://www.anthropic.com/news/claude-opus-4-1; Score 88.8 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        }
      ]
    },
    {
      "name": "o3-mini (medium)",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.73402062819552,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 83.87738434715314,
          "source": "Multivariate regression",
          "stdDev": 0.0021687718605630023
        },
        {
          "name": "GPQA Diamond",
          "score": 76.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 28.548021635285508,
          "source": "Multivariate regression",
          "stdDev": 0.0017337521802289633
        },
        {
          "name": "FRAMES",
          "score": 83.08504442621272,
          "source": "Multivariate regression",
          "stdDev": 0.0002968045884573551
        },
        {
          "name": "Humanity's Last Exam",
          "score": 10.754505220865305,
          "source": "Multivariate regression",
          "stdDev": 0.006720658726719266
        },
        {
          "name": "LiveCodeBench",
          "score": 65.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2719,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 61.288875764816,
          "source": "Multivariate regression",
          "stdDev": 0.02137460895767686
        },
        {
          "name": "Aider",
          "score": 60.4,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 79.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 76.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 53.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 82.37794132350179,
          "source": "Multivariate regression",
          "stdDev": 0.011599606534005482
        },
        {
          "name": "Terminal-Bench",
          "score": 27.161757869843854,
          "source": "Multivariate regression",
          "stdDev": 0.01010801436845375
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999957116499,
          "source": "Multivariate regression",
          "stdDev": 1.7248685339987933e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 54.910960528427886,
          "source": "Multivariate regression",
          "stdDev": 0.008031550844292596
        },
        {
          "name": "Tau-Bench Retail",
          "score": 77.20131877912988,
          "source": "Multivariate regression",
          "stdDev": 0.023470192291034378
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 18.868460660887592,
          "source": "Multivariate regression",
          "stdDev": 0.007615557347347354
        },
        {
          "name": "MMMU",
          "score": 69.34031604171949,
          "source": "Multivariate regression",
          "stdDev": 0.012147924714260044
        },
        {
          "name": "MMMU-Pro",
          "score": 59.43233315467364,
          "source": "Multivariate regression",
          "stdDev": 0.03693851902946342
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 48.98734782601741,
          "source": "Multivariate regression",
          "stdDev": 0.025154900094623633
        },
        {
          "name": "VideoMMMU",
          "score": 59.85294081505958,
          "source": "Multivariate regression",
          "stdDev": 0.015264596810367466
        },
        {
          "name": "ERQA",
          "score": 61.8317014215108,
          "source": "Multivariate regression",
          "stdDev": 0.016252640821495096
        },
        {
          "name": "SWE-Lancer",
          "score": 30.576990191243908,
          "source": "Multivariate regression",
          "stdDev": 0.03695300383722015
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 51.89230541995495,
          "source": "Multivariate regression",
          "stdDev": 0.015733104963357926
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 57.72340936199254,
          "source": "Multivariate regression",
          "stdDev": 0.016174581033573894
        },
        {
          "name": "COLLIE",
          "score": 57.41353838222744,
          "source": "Multivariate regression",
          "stdDev": 0.03178264725989276
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 55.78636549521781,
          "source": "Multivariate regression",
          "stdDev": 0.01091251147276206
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 46.0051415367287,
          "source": "Multivariate regression",
          "stdDev": 0.020363972199271368
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 31.529155621811526,
          "source": "Multivariate regression",
          "stdDev": 0.026695217766823518
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 60.214971855332806,
          "source": "Multivariate regression",
          "stdDev": 0.035415714526556154
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 40.464905943436094,
          "source": "Multivariate regression",
          "stdDev": 0.044751726891425675
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 68.52106448563495,
          "source": "Multivariate regression",
          "stdDev": 0.0303288450363485
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 20.896157781168768,
          "source": "Multivariate regression",
          "stdDev": 0.07562230827929342
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 84.7403649820846,
          "source": "Multivariate regression",
          "stdDev": 0.004771482608062634
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 57.38963597386359,
          "source": "Multivariate regression",
          "stdDev": 0.03342955669225716
        },
        {
          "name": "VideoMME",
          "score": 57.985789804346666,
          "source": "Multivariate regression",
          "stdDev": 0.14341235468124588
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 3.082241412071447,
          "source": "Multivariate regression",
          "stdDev": 0.0017492749586600772
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 5.137070833866382,
          "source": "Multivariate regression",
          "stdDev": 0.0029335802521856776
        },
        {
          "name": "FActScore hallucination rate",
          "score": 19.357112138866228,
          "source": "Multivariate regression",
          "stdDev": 0.012184923699798407
        },
        {
          "name": "MMMLU",
          "score": 86.38034456729054,
          "source": "Multivariate regression",
          "stdDev": 0.002734801426466446
        }
      ]
    },
    {
      "name": "GPT-4.1",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.1156948488529,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.44255550734209,
          "source": "Multivariate regression",
          "stdDev": 0.002098939770287121
        },
        {
          "name": "GPQA Diamond",
          "score": 66.3,
          "source": "Multiple: Score 66.3 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 66.3 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 30.461372876871902,
          "source": "Multivariate regression",
          "stdDev": 0.0016769560301119002
        },
        {
          "name": "FRAMES",
          "score": 82.5836388540433,
          "source": "Multivariate regression",
          "stdDev": 0.00028479474085685617
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 44.7,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2226.188663394443,
          "source": "Multivariate regression",
          "stdDev": 0.43616130956594246
        },
        {
          "name": "SWE-bench Verified",
          "score": 52.6,
          "source": "Multiple: Score 54.6 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 54.6 at https://www.anthropic.com/news/claude-4; Score 48.6 at undefined",
          "stdDev": 3.4641016151377544
        },
        {
          "name": "Aider",
          "score": 52.65,
          "source": "Multiple: Score 52.9 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 52.4 at undefined",
          "stdDev": 0.3535533905932738
        },
        {
          "name": "AIME 2024",
          "score": 80.2676411310896,
          "source": "Multivariate regression",
          "stdDev": 0.006578399741402813
        },
        {
          "name": "AIME 2025",
          "score": 46.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 28.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 80.16361817104615,
          "source": "Multivariate regression",
          "stdDev": 0.01079032250361517
        },
        {
          "name": "Terminal-Bench",
          "score": 30.3,
          "source": "Multiple: Score 30.3 at https://www.anthropic.com/news/claude-4; Score 30.3 at undefined",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.000000204702005,
          "source": "Multivariate regression",
          "stdDev": 1.673594480875602e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 49.4,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Retail",
          "score": 68,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 21.600175689672426,
          "source": "Multivariate regression",
          "stdDev": 0.007615557347347354
        },
        {
          "name": "MMMU",
          "score": 74.8,
          "source": "Multiple: Score 74.8 at https://openai.com/index/introducing-gpt-5-for-developers/; Score 74.8 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 60.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 56.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 60.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 44.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 34,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 46.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 49.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "COLLIE",
          "score": 65.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 56,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 74,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 34,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 57.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 56.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 61.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 58,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 85.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 75.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMME",
          "score": 78.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "FActScore hallucination rate",
          "score": 6.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMLU",
          "score": 83.7,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        }
      ]
    },
    {
      "name": "GPT-4.1 mini",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.32472435340917,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 84.06679192247938,
          "source": "Multivariate regression",
          "stdDev": 0.0021271477261449743
        },
        {
          "name": "GPQA Diamond",
          "score": 65,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 28.50087461603134,
          "source": "Multivariate regression",
          "stdDev": 0.0016858184508767129
        },
        {
          "name": "FRAMES",
          "score": 82.67066128483393,
          "source": "Multivariate regression",
          "stdDev": 0.0002880463323303298
        },
        {
          "name": "Humanity's Last Exam",
          "score": 3.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 51.64955401918796,
          "source": "Multivariate regression",
          "stdDev": 0.018082195872800688
        },
        {
          "name": "Codeforces",
          "score": 2475.7332345056875,
          "source": "Multivariate regression",
          "stdDev": 0.43166009540178474
        },
        {
          "name": "SWE-bench Verified",
          "score": 23.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 31.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 84.2450260663363,
          "source": "Multivariate regression",
          "stdDev": 0.006686243686278415
        },
        {
          "name": "AIME 2025",
          "score": 40.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 35,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 80.681089245809,
          "source": "Multivariate regression",
          "stdDev": 0.01135027866817838
        },
        {
          "name": "Terminal-Bench",
          "score": 25.870820232434795,
          "source": "Multivariate regression",
          "stdDev": 0.009772217468825778
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000002764065,
          "source": "Multivariate regression",
          "stdDev": 1.676060889995234e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 53.304351402673184,
          "source": "Multivariate regression",
          "stdDev": 0.00832311122997214
        },
        {
          "name": "Tau-Bench Retail",
          "score": 74.44510260541381,
          "source": "Multivariate regression",
          "stdDev": 0.022727024679607858
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 16.59364868696973,
          "source": "Multivariate regression",
          "stdDev": 0.0075841859518693995
        },
        {
          "name": "MMMU",
          "score": 72.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 58.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 56.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 55.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 42.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 31,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 42.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 45.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "COLLIE",
          "score": 54.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 51,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 66,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 44,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 47.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 45.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 61.7,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 60.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 81.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMME",
          "score": 68.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.8,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "FActScore hallucination rate",
          "score": 10.9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMLU",
          "score": 85.60286211392588,
          "source": "Multivariate regression",
          "stdDev": 0.0026630262205173403
        }
      ]
    },
    {
      "name": "GPT-4.1 nano",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.93405016433789,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.08240165897118,
          "source": "Multivariate regression",
          "stdDev": 0.002189287178588728
        },
        {
          "name": "GPQA Diamond",
          "score": 50.3,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 27.929776356846865,
          "source": "Multivariate regression",
          "stdDev": 0.0017423257286846164
        },
        {
          "name": "FRAMES",
          "score": 83.19836444646705,
          "source": "Multivariate regression",
          "stdDev": 0.0002968045884573551
        },
        {
          "name": "Humanity's Last Exam",
          "score": 7.944227903240474,
          "source": "Multivariate regression",
          "stdDev": 0.006998710666019337
        },
        {
          "name": "LiveCodeBench",
          "score": 65.54243389143922,
          "source": "Multivariate regression",
          "stdDev": 0.018499313410092554
        },
        {
          "name": "Codeforces",
          "score": 2493.0523653585988,
          "source": "Multivariate regression",
          "stdDev": 0.44939452373418826
        },
        {
          "name": "SWE-bench Verified",
          "score": 41.99411796153811,
          "source": "Multivariate regression",
          "stdDev": 0.02190347213770798
        },
        {
          "name": "Aider",
          "score": 6.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 78.60107476727194,
          "source": "Multivariate regression",
          "stdDev": 0.006879568227906105
        },
        {
          "name": "AIME 2025",
          "score": 58.506886324416826,
          "source": "Multivariate regression",
          "stdDev": 0.0213739975748546
        },
        {
          "name": "HMMT 2025",
          "score": 59.893285898010845,
          "source": "Multivariate regression",
          "stdDev": 0.03825224109927792
        },
        {
          "name": "CNMO 2024",
          "score": 80.77459853178539,
          "source": "Multivariate regression",
          "stdDev": 0.011722281974639641
        },
        {
          "name": "Terminal-Bench",
          "score": 30.269038002409758,
          "source": "Multivariate regression",
          "stdDev": 0.010155078965191444
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.0000005084464,
          "source": "Multivariate regression",
          "stdDev": 1.7361459436892464e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.98221317941774,
          "source": "Multivariate regression",
          "stdDev": 0.008632461368967875
        },
        {
          "name": "Tau-Bench Retail",
          "score": 74.00298377301506,
          "source": "Multivariate regression",
          "stdDev": 0.023470192291034378
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 20.071713459551646,
          "source": "Multivariate regression",
          "stdDev": 0.007739771465847604
        },
        {
          "name": "MMMU",
          "score": 55.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 33,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 40.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMMMU",
          "score": 30.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "ERQA",
          "score": 26.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "SWE-Lancer",
          "score": 9,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 31.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 58.36522520065354,
          "source": "Multivariate regression",
          "stdDev": 0.016350508172839333
        },
        {
          "name": "COLLIE",
          "score": 42.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 14,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 21.5,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 12.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 36.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 22.6,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 25,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 9.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89.4,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 19.1,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "VideoMME",
          "score": 55.2,
          "source": "https://openai.com/index/introducing-gpt-5-for-developers/",
          "stdDev": 0
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.5130806005058233,
          "source": "Multivariate regression",
          "stdDev": 0.001774646400880553
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.953162732697713,
          "source": "Multivariate regression",
          "stdDev": 0.0030038517955188
        },
        {
          "name": "FActScore hallucination rate",
          "score": 21.0509961454826,
          "source": "Multivariate regression",
          "stdDev": 0.012379044274577103
        },
        {
          "name": "MMMLU",
          "score": 86.85273492905262,
          "source": "Multivariate regression",
          "stdDev": 0.0027673006299513392
        }
      ]
    },
    {
      "name": "Claude Opus 4.1",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.19221752523946,
          "source": "Multivariate regression",
          "stdDev": 0.0003819328518345358
        },
        {
          "name": "MMLU-Pro",
          "score": 85.04732020162348,
          "source": "Multivariate regression",
          "stdDev": 0.002106027179710805
        },
        {
          "name": "GPQA Diamond",
          "score": 80.9,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 28.7280565610347,
          "source": "Multivariate regression",
          "stdDev": 0.001645561727365987
        },
        {
          "name": "FRAMES",
          "score": 83.17202093013069,
          "source": "Multivariate regression",
          "stdDev": 0.00028315494317618465
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14.679303928587657,
          "source": "Multivariate regression",
          "stdDev": 0.006720658726719266
        },
        {
          "name": "LiveCodeBench",
          "score": 74.24733031578569,
          "source": "Multivariate regression",
          "stdDev": 0.017709160543420536
        },
        {
          "name": "Codeforces",
          "score": 2953.00678137618,
          "source": "Multivariate regression",
          "stdDev": 0.42711144677036916
        },
        {
          "name": "SWE-bench Verified",
          "score": 74.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 43.13429476768715,
          "source": "Multivariate regression",
          "stdDev": 0.03658759855448043
        },
        {
          "name": "AIME 2024",
          "score": 89.3636840426243,
          "source": "Multivariate regression",
          "stdDev": 0.006542056710200965
        },
        {
          "name": "AIME 2025",
          "score": 78,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 58.16252240408815,
          "source": "Multivariate regression",
          "stdDev": 0.036621901051382987
        },
        {
          "name": "CNMO 2024",
          "score": 86.4675796698275,
          "source": "Multivariate regression",
          "stdDev": 0.0111809717189375
        },
        {
          "name": "Terminal-Bench",
          "score": 43.3,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.0000003595913,
          "source": "Multivariate regression",
          "stdDev": 1.6511719307925425e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Retail",
          "score": 82.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 15.291621175692157,
          "source": "Multivariate regression",
          "stdDev": 0.0073608434601689
        },
        {
          "name": "MMMU",
          "score": 77.1,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 68.73310978489457,
          "source": "Multivariate regression",
          "stdDev": 0.03546325795316233
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 49.21172373086111,
          "source": "Multivariate regression",
          "stdDev": 0.02446296636509708
        },
        {
          "name": "VideoMMMU",
          "score": 69.29458029024693,
          "source": "Multivariate regression",
          "stdDev": 0.015107598889335438
        },
        {
          "name": "ERQA",
          "score": 51.01800669306982,
          "source": "Multivariate regression",
          "stdDev": 0.016252640821495096
        },
        {
          "name": "SWE-Lancer",
          "score": 39.091135624156436,
          "source": "Multivariate regression",
          "stdDev": 0.03558570448491019
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 40.06297062541283,
          "source": "Multivariate regression",
          "stdDev": 0.015672371969654923
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 62.38889981102065,
          "source": "Multivariate regression",
          "stdDev": 0.015877037773072967
        },
        {
          "name": "COLLIE",
          "score": 73.98771064879088,
          "source": "Multivariate regression",
          "stdDev": 0.030055367963298486
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 38.10834064571361,
          "source": "Multivariate regression",
          "stdDev": 0.010489184936748146
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 80.84572570548735,
          "source": "Multivariate regression",
          "stdDev": 0.019842140226592482
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 36.52133166641198,
          "source": "Multivariate regression",
          "stdDev": 0.02626302473106211
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 56.91580299031921,
          "source": "Multivariate regression",
          "stdDev": 0.033191639682328446
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 31.963832708312566,
          "source": "Multivariate regression",
          "stdDev": 0.04406451978082539
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 73.60526885680855,
          "source": "Multivariate regression",
          "stdDev": 0.02930535249726304
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 61.759578766551954,
          "source": "Multivariate regression",
          "stdDev": 0.07336920437154468
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.47123765561518,
          "source": "Multivariate regression",
          "stdDev": 0.004554172631409673
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 77.02595791772023,
          "source": "Multivariate regression",
          "stdDev": 0.0321498354707623
        },
        {
          "name": "VideoMME",
          "score": 63.652209985647005,
          "source": "Multivariate regression",
          "stdDev": 0.13643305492152358
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.1511328792797855,
          "source": "Multivariate regression",
          "stdDev": 0.0016841750096375078
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.5672656148706565,
          "source": "Multivariate regression",
          "stdDev": 0.002882337570815887
        },
        {
          "name": "FActScore hallucination rate",
          "score": 15.44457241606375,
          "source": "Multivariate regression",
          "stdDev": 0.011583058785304301
        },
        {
          "name": "MMMLU",
          "score": 89.5,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        }
      ]
    },
    {
      "name": "Claude Opus 4",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.08554304259934,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 84.12193270333117,
          "source": "Multivariate regression",
          "stdDev": 0.002148060617395799
        },
        {
          "name": "GPQA Diamond",
          "score": 79.6,
          "source": "Multiple: Score 79.6 at https://www.anthropic.com/news/claude-4; Score 79.6 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.19080940309742,
          "source": "Multivariate regression",
          "stdDev": 0.0017593474897278736
        },
        {
          "name": "FRAMES",
          "score": 82.73905690982517,
          "source": "Multivariate regression",
          "stdDev": 0.0003014745950377683
        },
        {
          "name": "Humanity's Last Exam",
          "score": 19.115490902669684,
          "source": "Multivariate regression",
          "stdDev": 0.006913020909207856
        },
        {
          "name": "LiveCodeBench",
          "score": 63.6,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2690.852644737339,
          "source": "Multivariate regression",
          "stdDev": 0.4406165429966037
        },
        {
          "name": "SWE-bench Verified",
          "score": 70.93333333333334,
          "source": "Multiple: Score 72.5 at https://www.anthropic.com/news/claude-4; Score 72.5 at https://www.anthropic.com/news/claude-opus-4-1; Score 67.8 at undefined",
          "stdDev": 2.7135462651912428
        },
        {
          "name": "Aider",
          "score": 70.7,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 81.19297330767603,
          "source": "Multivariate regression",
          "stdDev": 0.006896874479176544
        },
        {
          "name": "AIME 2025",
          "score": 75.5,
          "source": "Multiple: Score 75.5 at https://www.anthropic.com/news/claude-4; Score 75.5 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 67.81422356389189,
          "source": "Multivariate regression",
          "stdDev": 0.038451173430466154
        },
        {
          "name": "CNMO 2024",
          "score": 81.89893654460212,
          "source": "Multivariate regression",
          "stdDev": 0.011599606534005482
        },
        {
          "name": "Terminal-Bench",
          "score": 40.53333333333334,
          "source": "Multiple: Score 39.2 at https://www.anthropic.com/news/claude-4; Score 39.2 at https://www.anthropic.com/news/claude-opus-4-1; Score 43.2 at undefined",
          "stdDev": 2.309401076758503
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.999999910804995,
          "source": "Multivariate regression",
          "stdDev": 1.7404558057624944e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 59.6,
          "source": "Multiple: Score 59.6 at https://www.anthropic.com/news/claude-4; Score 59.6 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Retail",
          "score": 81.4,
          "source": "Multiple: Score 81.4 at https://www.anthropic.com/news/claude-4; Score 81.4 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 12.57800510203603,
          "source": "Multivariate regression",
          "stdDev": 0.007801136882529047
        },
        {
          "name": "MMMU",
          "score": 76.5,
          "source": "Multiple: Score 76.5 at https://www.anthropic.com/news/claude-4; Score 76.5 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 61.15541354492319,
          "source": "Multivariate regression",
          "stdDev": 0.037144487843454393
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 67.86807014540199,
          "source": "Multivariate regression",
          "stdDev": 0.025605803685185242
        },
        {
          "name": "VideoMMMU",
          "score": 54.596865245878234,
          "source": "Multivariate regression",
          "stdDev": 0.015816891397439418
        },
        {
          "name": "ERQA",
          "score": 42.97634971824833,
          "source": "Multivariate regression",
          "stdDev": 0.016942152084852703
        },
        {
          "name": "SWE-Lancer",
          "score": 48.51026722481845,
          "source": "Multivariate regression",
          "stdDev": 0.037363646378781167
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 59.623864484617485,
          "source": "Multivariate regression",
          "stdDev": 0.015973728003170953
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 56.319511338349116,
          "source": "Multivariate regression",
          "stdDev": 0.016408731399559756
        },
        {
          "name": "COLLIE",
          "score": 62.19644289934217,
          "source": "Multivariate regression",
          "stdDev": 0.031541684764518664
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 44.82721621517078,
          "source": "Multivariate regression",
          "stdDev": 0.010999557049080481
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 56.81172505564467,
          "source": "Multivariate regression",
          "stdDev": 0.020410749921683662
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 31.105132821516975,
          "source": "Multivariate regression",
          "stdDev": 0.028019884005202538
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 57.00957468754757,
          "source": "Multivariate regression",
          "stdDev": 0.03465352902242094
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 57.957435943728484,
          "source": "Multivariate regression",
          "stdDev": 0.0450914031483802
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 61.751481141178544,
          "source": "Multivariate regression",
          "stdDev": 0.030827851358209205
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 58.1606550468955,
          "source": "Multivariate regression",
          "stdDev": 0.07662454828652167
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 82.36708938345922,
          "source": "Multivariate regression",
          "stdDev": 0.004845854105970265
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 73.31039890278086,
          "source": "Multivariate regression",
          "stdDev": 0.03320054926621449
        },
        {
          "name": "VideoMME",
          "score": 72.38092736703226,
          "source": "Multivariate regression",
          "stdDev": 0.1451047370874551
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.898602018511575,
          "source": "Multivariate regression",
          "stdDev": 0.0017407356371969638
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 4.813687015552823,
          "source": "Multivariate regression",
          "stdDev": 0.00306280157341181
        },
        {
          "name": "FActScore hallucination rate",
          "score": 21.02157278801394,
          "source": "Multivariate regression",
          "stdDev": 0.012184923699798407
        },
        {
          "name": "MMMLU",
          "score": 88.8,
          "source": "Multiple: Score 88.8 at https://www.anthropic.com/news/claude-4; Score 88.8 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        }
      ]
    },
    {
      "name": "Claude Sonnet 4",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.81010131394818,
          "source": "Multivariate regression",
          "stdDev": 0.00041015173424140605
        },
        {
          "name": "MMLU-Pro",
          "score": 85.44028355606245,
          "source": "Multivariate regression",
          "stdDev": 0.0021960830295598317
        },
        {
          "name": "GPQA Diamond",
          "score": 75.4,
          "source": "Multiple: Score 75.4 at https://www.anthropic.com/news/claude-4; Score 75.4 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.08093342743763,
          "source": "Multivariate regression",
          "stdDev": 0.001746596721063631
        },
        {
          "name": "FRAMES",
          "score": 82.59558235047706,
          "source": "Multivariate regression",
          "stdDev": 0.00030301527028815206
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.673064185014482,
          "source": "Multivariate regression",
          "stdDev": 0.007015723025159587
        },
        {
          "name": "LiveCodeBench",
          "score": 67.8633207879721,
          "source": "Multivariate regression",
          "stdDev": 0.018395920726596026
        },
        {
          "name": "Codeforces",
          "score": 1835.9939943057143,
          "source": "Multivariate regression",
          "stdDev": 0.4622490540415176
        },
        {
          "name": "SWE-bench Verified",
          "score": 71.93333333333334,
          "source": "Multiple: Score 72.7 at https://www.anthropic.com/news/claude-4; Score 72.7 at https://www.anthropic.com/news/claude-opus-4-1; Score 70.4 at undefined",
          "stdDev": 1.3279056191361376
        },
        {
          "name": "Aider",
          "score": 56.4,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 83.18213769179482,
          "source": "Multivariate regression",
          "stdDev": 0.006879568227906105
        },
        {
          "name": "AIME 2025",
          "score": 70.5,
          "source": "Multiple: Score 70.5 at https://www.anthropic.com/news/claude-4; Score 70.5 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 38.62028291662671,
          "source": "Multivariate regression",
          "stdDev": 0.03855025463873146
        },
        {
          "name": "CNMO 2024",
          "score": 81.27363067659576,
          "source": "Multivariate regression",
          "stdDev": 0.011681533305887339
        },
        {
          "name": "Terminal-Bench",
          "score": 34.5,
          "source": "Multiple: Score 33.5 at https://www.anthropic.com/news/claude-4; Score 35.5 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 1.4142135623730951
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000013119184,
          "source": "Multivariate regression",
          "stdDev": 1.7388603442166504e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 60,
          "source": "Multiple: Score 60 at https://www.anthropic.com/news/claude-4; Score 60 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Retail",
          "score": 80.5,
          "source": "Multiple: Score 80.5 at https://www.anthropic.com/news/claude-4; Score 80.5 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.683336330319833,
          "source": "Multivariate regression",
          "stdDev": 0.007739771465847604
        },
        {
          "name": "MMMU",
          "score": 74.4,
          "source": "Multiple: Score 74.4 at https://www.anthropic.com/news/claude-4; Score 74.4 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 34.00082708090122,
          "source": "Multivariate regression",
          "stdDev": 0.03724704514030316
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 77.88423805472732,
          "source": "Multivariate regression",
          "stdDev": 0.0256801845715694
        },
        {
          "name": "VideoMMMU",
          "score": 53.68674565599173,
          "source": "Multivariate regression",
          "stdDev": 0.015756481359922355
        },
        {
          "name": "ERQA",
          "score": 46.81367868538051,
          "source": "Multivariate regression",
          "stdDev": 0.01688576822751829
        },
        {
          "name": "SWE-Lancer",
          "score": -14.911368238583407,
          "source": "Multivariate regression",
          "stdDev": 0.03776982458052469
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 57.29902871736883,
          "source": "Multivariate regression",
          "stdDev": 0.016092690377463702
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 50.48796905189502,
          "source": "Multivariate regression",
          "stdDev": 0.016350508172839333
        },
        {
          "name": "COLLIE",
          "score": 50.923776339235474,
          "source": "Multivariate regression",
          "stdDev": 0.03214070395060629
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 41.14711646790806,
          "source": "Multivariate regression",
          "stdDev": 0.011085919172932328
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 43.96658398258987,
          "source": "Multivariate regression",
          "stdDev": 0.021099974925522947
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 65.7671125074612,
          "source": "Multivariate regression",
          "stdDev": 0.027746263002474857
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 52.24333784602334,
          "source": "Multivariate regression",
          "stdDev": 0.035415714526556154
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 33.9379119176464,
          "source": "Multivariate regression",
          "stdDev": 0.045763192569353725
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 47.044822799375424,
          "source": "Multivariate regression",
          "stdDev": 0.0310743496862982
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 66.9846995941943,
          "source": "Multivariate regression",
          "stdDev": 0.07642515176294051
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 79.93202087960647,
          "source": "Multivariate regression",
          "stdDev": 0.004870392242463685
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 81.81665565360095,
          "source": "Multivariate regression",
          "stdDev": 0.03399532663907034
        },
        {
          "name": "VideoMME",
          "score": 68.96939178411623,
          "source": "Multivariate regression",
          "stdDev": 0.1446834973751999
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.5447006993006696,
          "source": "Multivariate regression",
          "stdDev": 0.001774646400880553
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.5770066539332674,
          "source": "Multivariate regression",
          "stdDev": 0.00306280157341181
        },
        {
          "name": "FActScore hallucination rate",
          "score": 14.532383114254799,
          "source": "Multivariate regression",
          "stdDev": 0.012455845446405982
        },
        {
          "name": "MMMLU",
          "score": 86.5,
          "source": "Multiple: Score 86.5 at https://www.anthropic.com/news/claude-4; Score 86.5 at https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        }
      ]
    },
    {
      "name": "Claude Sonnet 3.7",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.06891443006353,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 83.98128410941051,
          "source": "Multivariate regression",
          "stdDev": 0.0021618901592778046
        },
        {
          "name": "GPQA Diamond",
          "score": 78.2,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 28.63899163882688,
          "source": "Multivariate regression",
          "stdDev": 0.001746596721063631
        },
        {
          "name": "FRAMES",
          "score": 82.6243432807608,
          "source": "Multivariate regression",
          "stdDev": 0.00029758801221932256
        },
        {
          "name": "Humanity's Last Exam",
          "score": 19.278214856481426,
          "source": "Multivariate regression",
          "stdDev": 0.006895755180692209
        },
        {
          "name": "LiveCodeBench",
          "score": 65.78642585618725,
          "source": "Multivariate regression",
          "stdDev": 0.018239732823722165
        },
        {
          "name": "Codeforces",
          "score": 2603.466077086081,
          "source": "Multivariate regression",
          "stdDev": 0.4406165429966037
        },
        {
          "name": "SWE-bench Verified",
          "score": 62.3,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 54.7220719602729,
          "source": "Multivariate regression",
          "stdDev": 0.03731029522400712
        },
        {
          "name": "AIME 2024",
          "score": 83.9768999095938,
          "source": "Multivariate regression",
          "stdDev": 0.0068099034270692055
        },
        {
          "name": "AIME 2025",
          "score": 54.8,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 62.735745301380064,
          "source": "Multivariate regression",
          "stdDev": 0.03825224109927792
        },
        {
          "name": "CNMO 2024",
          "score": 78.13607633437157,
          "source": "Multivariate regression",
          "stdDev": 0.01155842538702121
        },
        {
          "name": "Terminal-Bench",
          "score": 35.2,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000031216105,
          "source": "Multivariate regression",
          "stdDev": 1.714124222319036e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 58.4,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "Tau-Bench Retail",
          "score": 81.2,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 13.713849294948716,
          "source": "Multivariate regression",
          "stdDev": 0.00777051475140173
        },
        {
          "name": "MMMU",
          "score": 75,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 81.42828965025438,
          "source": "Multivariate regression",
          "stdDev": 0.03652309693830783
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 56.417205361992416,
          "source": "Multivariate regression",
          "stdDev": 0.025531206103484833
        },
        {
          "name": "VideoMMMU",
          "score": 53.5082133333388,
          "source": "Multivariate regression",
          "stdDev": 0.015512488849772967
        },
        {
          "name": "ERQA",
          "score": 44.390777009747765,
          "source": "Multivariate regression",
          "stdDev": 0.016600976642035366
        },
        {
          "name": "SWE-Lancer",
          "score": 64.4549849704755,
          "source": "Multivariate regression",
          "stdDev": 0.03715889236314919
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 59.012954746480716,
          "source": "Multivariate regression",
          "stdDev": 0.016033319523794824
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 60.65531247990327,
          "source": "Multivariate regression",
          "stdDev": 0.016233435257038506
        },
        {
          "name": "COLLIE",
          "score": 106.85335966679611,
          "source": "Multivariate regression",
          "stdDev": 0.03129886721147858
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 32.576563566390234,
          "source": "Multivariate regression",
          "stdDev": 0.01091251147276206
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 66.19887379929921,
          "source": "Multivariate regression",
          "stdDev": 0.02068919534835477
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 59.688164227116374,
          "source": "Multivariate regression",
          "stdDev": 0.027330695692000872
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 80.06173099831005,
          "source": "Multivariate regression",
          "stdDev": 0.034982213441998214
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 77.87117225306869,
          "source": "Multivariate regression",
          "stdDev": 0.044580918235297175
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 62.196416443361954,
          "source": "Multivariate regression",
          "stdDev": 0.030391668899625537
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 53.71798089747659,
          "source": "Multivariate regression",
          "stdDev": 0.07501453709190965
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 91.06989642317959,
          "source": "Multivariate regression",
          "stdDev": 0.004771482608062634
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 49.78203208248593,
          "source": "Multivariate regression",
          "stdDev": 0.03285404523014762
        },
        {
          "name": "VideoMME",
          "score": 81.28524462520659,
          "source": "Multivariate regression",
          "stdDev": 0.14341235468124588
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.6893864485626153,
          "source": "Multivariate regression",
          "stdDev": 0.0017577727962916339
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.6387992572402013,
          "source": "Multivariate regression",
          "stdDev": 0.0029839430825487835
        },
        {
          "name": "FActScore hallucination rate",
          "score": 22.43225220324223,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 85.9,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.7842484287569,
          "source": "Multivariate regression",
          "stdDev": 0.0003915651719795637
        },
        {
          "name": "MMLU-Pro",
          "score": 84.35063967309337,
          "source": "Multivariate regression",
          "stdDev": 0.002189287178588728
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 28.450735723864092,
          "source": "Multivariate regression",
          "stdDev": 0.0017251360236401618
        },
        {
          "name": "FRAMES",
          "score": 82.54050561619194,
          "source": "Multivariate regression",
          "stdDev": 0.0002999260056723506
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.679795927830305,
          "source": "Multivariate regression",
          "stdDev": 0.006895755180692209
        },
        {
          "name": "LiveCodeBench",
          "score": 80.1,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 1790.1599363072382,
          "source": "Multivariate regression",
          "stdDev": 0.46645518323015545
        },
        {
          "name": "SWE-bench Verified",
          "score": 58.1,
          "source": "Multiple: Score 67.2 at https://www.anthropic.com/news/claude-opus-4-1; Score 49 at undefined",
          "stdDev": 12.869343417595168
        },
        {
          "name": "Aider",
          "score": 83.1,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 84.58675700682564,
          "source": "Multivariate regression",
          "stdDev": 0.0068622183310729475
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 86.60684127039764,
          "source": "Multivariate regression",
          "stdDev": 0.03825224109927792
        },
        {
          "name": "CNMO 2024",
          "score": 85.07718927058858,
          "source": "Multivariate regression",
          "stdDev": 0.011640641995188623
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999985891032,
          "source": "Multivariate regression",
          "stdDev": 1.7331458094842348e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 52.74145050296755,
          "source": "Multivariate regression",
          "stdDev": 0.008493244580000454
        },
        {
          "name": "Tau-Bench Retail",
          "score": 74.1892596558395,
          "source": "Multivariate regression",
          "stdDev": 0.023307091874510633
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 10.133235360872646,
          "source": "Multivariate regression",
          "stdDev": 0.00777051475140173
        },
        {
          "name": "MMMU",
          "score": 82,
          "source": "https://www.anthropic.com/news/claude-opus-4-1",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 69.20943526965743,
          "source": "Multivariate regression",
          "stdDev": 0.03662739418108093
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 84.3574289873498,
          "source": "Multivariate regression",
          "stdDev": 0.025828303741460088
        },
        {
          "name": "VideoMMMU",
          "score": 65.88727661793939,
          "source": "Multivariate regression",
          "stdDev": 0.015847010058518903
        },
        {
          "name": "ERQA",
          "score": 52.88379679439045,
          "source": "Multivariate regression",
          "stdDev": 0.017054360572355206
        },
        {
          "name": "SWE-Lancer",
          "score": 53.80162555025038,
          "source": "Multivariate regression",
          "stdDev": 0.037363646378781167
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 70.4748103178048,
          "source": "Multivariate regression",
          "stdDev": 0.01615184299755682
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 63.025312740490364,
          "source": "Multivariate regression",
          "stdDev": 0.016466748761540962
        },
        {
          "name": "COLLIE",
          "score": 121.37925805165082,
          "source": "Multivariate regression",
          "stdDev": 0.03214070395060629
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 48.14108585617146,
          "source": "Multivariate regression",
          "stdDev": 0.0110643918382614
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 73.61627229505109,
          "source": "Multivariate regression",
          "stdDev": 0.021054728524131688
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 62.26574974668665,
          "source": "Multivariate regression",
          "stdDev": 0.027814920597911654
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 63.7024513261041,
          "source": "Multivariate regression",
          "stdDev": 0.035415714526556154
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 77.58294776975421,
          "source": "Multivariate regression",
          "stdDev": 0.04542853966412251
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 84.6745379537312,
          "source": "Multivariate regression",
          "stdDev": 0.031012908782645912
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 36.77999762874714,
          "source": "Multivariate regression",
          "stdDev": 0.07582381609767139
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 90.09992189217735,
          "source": "Multivariate regression",
          "stdDev": 0.00480881213478927
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 79.35970780174463,
          "source": "Multivariate regression",
          "stdDev": 0.03388292842665515
        },
        {
          "name": "VideoMME",
          "score": 75.31494981156374,
          "source": "Multivariate regression",
          "stdDev": 0.1446834973751999
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.966390064703276,
          "source": "Multivariate regression",
          "stdDev": 0.0017704430764541549
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 7.880096171070932,
          "source": "Multivariate regression",
          "stdDev": 0.0030530556551295407
        },
        {
          "name": "FActScore hallucination rate",
          "score": 12.958768171273334,
          "source": "Multivariate regression",
          "stdDev": 0.012262940683323939
        },
        {
          "name": "MMMLU",
          "score": 87.80196991265915,
          "source": "Multivariate regression",
          "stdDev": 0.0027402447271348963
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro 0506",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.02737459248215,
          "source": "Multivariate regression",
          "stdDev": 0.0003819328518345358
        },
        {
          "name": "MMLU-Pro",
          "score": 84.7543502761766,
          "source": "Multivariate regression",
          "stdDev": 0.002106027179710805
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "Multiple: Score 83 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 83 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.227638346805648,
          "source": "Multivariate regression",
          "stdDev": 0.0016813930795987332
        },
        {
          "name": "FRAMES",
          "score": 82.86887534142922,
          "source": "Multivariate regression",
          "stdDev": 0.0002856111092150156
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 71.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2610.4090058040256,
          "source": "Multivariate regression",
          "stdDev": 0.43166009540178474
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.2,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 76.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 90.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "Multiple: Score 83 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 83 at https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 60.75326326331211,
          "source": "Multivariate regression",
          "stdDev": 0.036412976362208936
        },
        {
          "name": "CNMO 2024",
          "score": 86.92927461916496,
          "source": "Multivariate regression",
          "stdDev": 0.0111809717189375
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000000682319,
          "source": "Multivariate regression",
          "stdDev": 1.6582614028101114e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 50.5336695802895,
          "source": "Multivariate regression",
          "stdDev": 0.0080611814346695
        },
        {
          "name": "Tau-Bench Retail",
          "score": 69.80440913056883,
          "source": "Multivariate regression",
          "stdDev": 0.022558551732242357
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 19.280222185794727,
          "source": "Multivariate regression",
          "stdDev": 0.007393162625244652
        },
        {
          "name": "MMMU",
          "score": 79.6,
          "source": "https://www.anthropic.com/news/claude-4",
          "stdDev": 0
        },
        {
          "name": "MMMU-Pro",
          "score": 71.85572413098134,
          "source": "Multivariate regression",
          "stdDev": 0.03492127849887918
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 55.01343731917143,
          "source": "Multivariate regression",
          "stdDev": 0.024695765126368247
        },
        {
          "name": "VideoMMMU",
          "score": 75.2207576195928,
          "source": "Multivariate regression",
          "stdDev": 0.014723975427994111
        },
        {
          "name": "ERQA",
          "score": 51.74690300190048,
          "source": "Multivariate regression",
          "stdDev": 0.016016208638166485
        },
        {
          "name": "SWE-Lancer",
          "score": 57.57112038456478,
          "source": "Multivariate regression",
          "stdDev": 0.03611771499338804
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 45.42901113712095,
          "source": "Multivariate regression",
          "stdDev": 0.015240465961562259
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 62.81155035038883,
          "source": "Multivariate regression",
          "stdDev": 0.01563492673204246
        },
        {
          "name": "COLLIE",
          "score": 85.19573502857747,
          "source": "Multivariate regression",
          "stdDev": 0.03117674925630507
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 43.96525177729853,
          "source": "Multivariate regression",
          "stdDev": 0.010466430312150417
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 84.94082408848537,
          "source": "Multivariate regression",
          "stdDev": 0.01964894740795317
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 62.706016793759716,
          "source": "Multivariate regression",
          "stdDev": 0.026190299172761566
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 65.10266136859639,
          "source": "Multivariate regression",
          "stdDev": 0.033648217232515015
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 57.73029609599641,
          "source": "Multivariate regression",
          "stdDev": 0.043190137279270735
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 87.90281913558437,
          "source": "Multivariate regression",
          "stdDev": 0.029693296694415578
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 74.75649448512723,
          "source": "Multivariate regression",
          "stdDev": 0.07253254330032478
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89.5176815829178,
          "source": "Multivariate regression",
          "stdDev": 0.004554172631409673
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 58.65415746573464,
          "source": "Multivariate regression",
          "stdDev": 0.03179188162414008
        },
        {
          "name": "VideoMME",
          "score": 75.82062083110054,
          "source": "Multivariate regression",
          "stdDev": 0.13996621369180304
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.9462468298516455,
          "source": "Multivariate regression",
          "stdDev": 0.001675303895029139
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.3846307546096739,
          "source": "Multivariate regression",
          "stdDev": 0.002840677963626864
        },
        {
          "name": "FActScore hallucination rate",
          "score": 5.5919088562354204,
          "source": "Multivariate regression",
          "stdDev": 0.011787095588220466
        },
        {
          "name": "MMMLU",
          "score": 87.58908671341686,
          "source": "Multivariate regression",
          "stdDev": 0.0026348998157851074
        }
      ]
    },
    {
      "name": "Qwen3-235B",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.06784771844077,
          "source": "Multivariate regression",
          "stdDev": 0.00041913604676543486
        },
        {
          "name": "MMLU-Pro",
          "score": 84.95597785279435,
          "source": "Multivariate regression",
          "stdDev": 0.002209612028727233
        },
        {
          "name": "GPQA Diamond",
          "score": 71.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.299201833164943,
          "source": "Multivariate regression",
          "stdDev": 0.001746596721063631
        },
        {
          "name": "FRAMES",
          "score": 82.66656022330031,
          "source": "Multivariate regression",
          "stdDev": 0.0002968045884573551
        },
        {
          "name": "Humanity's Last Exam",
          "score": 11.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "LiveCodeBench",
          "score": 66.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2362.565159082711,
          "source": "Multivariate regression",
          "stdDev": 0.44939452373418826
        },
        {
          "name": "SWE-bench Verified",
          "score": 81.3129565135149,
          "source": "Multivariate regression",
          "stdDev": 0.021859888907644006
        },
        {
          "name": "Aider",
          "score": 65,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 85.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 81.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 59.60645907071688,
          "source": "Multivariate regression",
          "stdDev": 0.038845981984045486
        },
        {
          "name": "CNMO 2024",
          "score": 80.06646284103957,
          "source": "Multivariate regression",
          "stdDev": 0.011681533305887339
        },
        {
          "name": "Terminal-Bench",
          "score": 28.80246592101662,
          "source": "Multivariate regression",
          "stdDev": 0.010225269691498758
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000035382501,
          "source": "Multivariate regression",
          "stdDev": 1.7492110304457308e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 60.368490457517126,
          "source": "Multivariate regression",
          "stdDev": 0.008632461368967875
        },
        {
          "name": "Tau-Bench Retail",
          "score": 80.32352960307476,
          "source": "Multivariate regression",
          "stdDev": 0.02419053950553304
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 11.338481607446624,
          "source": "Multivariate regression",
          "stdDev": 0.007892290423860769
        },
        {
          "name": "MMMU",
          "score": 75.81484420040472,
          "source": "Multivariate regression",
          "stdDev": 0.012457988176049132
        },
        {
          "name": "MMMU-Pro",
          "score": 75.35885474568875,
          "source": "Multivariate regression",
          "stdDev": 0.037144487843454393
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 45.89491086784605,
          "source": "Multivariate regression",
          "stdDev": 0.025902045699649788
        },
        {
          "name": "VideoMMMU",
          "score": 66.80520557313253,
          "source": "Multivariate regression",
          "stdDev": 0.015847010058518903
        },
        {
          "name": "ERQA",
          "score": 43.84808580208636,
          "source": "Multivariate regression",
          "stdDev": 0.01727659136123656
        },
        {
          "name": "SWE-Lancer",
          "score": 41.90768885557145,
          "source": "Multivariate regression",
          "stdDev": 0.03726141001340874
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 56.13518653813432,
          "source": "Multivariate regression",
          "stdDev": 0.016210779773056502
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 58.82587236336998,
          "source": "Multivariate regression",
          "stdDev": 0.016639587154558502
        },
        {
          "name": "COLLIE",
          "score": 79.20838446907419,
          "source": "Multivariate regression",
          "stdDev": 0.03225917303608028
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 40.07156775893344,
          "source": "Multivariate regression",
          "stdDev": 0.011128848917349667
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 66.0656106894466,
          "source": "Multivariate regression",
          "stdDev": 0.021099974925522947
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 38.211115313148355,
          "source": "Multivariate regression",
          "stdDev": 0.028223358968448103
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 55.86460502175407,
          "source": "Multivariate regression",
          "stdDev": 0.03552326322225719
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 30.883657475283684,
          "source": "Multivariate regression",
          "stdDev": 0.04626063295424363
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 54.6057104553758,
          "source": "Multivariate regression",
          "stdDev": 0.031318907986851025
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 51.95031008767745,
          "source": "Multivariate regression",
          "stdDev": 0.0760247898105512
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 84.82622153519134,
          "source": "Multivariate regression",
          "stdDev": 0.004882615066232564
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 43.469548449876555,
          "source": "Multivariate regression",
          "stdDev": 0.03421901550833375
        },
        {
          "name": "VideoMME",
          "score": 59.93336040759931,
          "source": "Multivariate regression",
          "stdDev": 0.14636118222643418
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.6942106962004857,
          "source": "Multivariate regression",
          "stdDev": 0.0017913610727415318
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.7291187932866237,
          "source": "Multivariate regression",
          "stdDev": 0.0030530556551295407
        },
        {
          "name": "FActScore hallucination rate",
          "score": 27.893303737766416,
          "source": "Multivariate regression",
          "stdDev": 0.012379044274577103
        },
        {
          "name": "MMMLU",
          "score": 87.6132422102874,
          "source": "Multivariate regression",
          "stdDev": 0.0027780492114619693
        }
      ]
    },
    {
      "name": "Qwen3-235B-Thinking 2507",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.93563337566398,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.74067490363517,
          "source": "Multivariate regression",
          "stdDev": 0.002189287178588728
        },
        {
          "name": "GPQA Diamond",
          "score": 74.38806807168204,
          "source": "Multivariate regression",
          "stdDev": 0.011454787959452544
        },
        {
          "name": "SimpleQA",
          "score": 28.46616749934863,
          "source": "Multivariate regression",
          "stdDev": 0.0017423257286846164
        },
        {
          "name": "FRAMES",
          "score": 82.8675096068164,
          "source": "Multivariate regression",
          "stdDev": 0.00029601909134721735
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.503161576040675,
          "source": "Multivariate regression",
          "stdDev": 0.007066514367285973
        },
        {
          "name": "LiveCodeBench",
          "score": 78.2,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2777.634690533978,
          "source": "Multivariate regression",
          "stdDev": 0.42711144677036916
        },
        {
          "name": "SWE-bench Verified",
          "score": 58.7163944283289,
          "source": "Multivariate regression",
          "stdDev": 0.021640656179757464
        },
        {
          "name": "Aider",
          "score": 63.304787482167455,
          "source": "Multivariate regression",
          "stdDev": 0.038119460724839335
        },
        {
          "name": "AIME 2024",
          "score": 87.56965829526537,
          "source": "Multivariate regression",
          "stdDev": 0.006757183507105917
        },
        {
          "name": "AIME 2025",
          "score": 71.43353166252194,
          "source": "Multivariate regression",
          "stdDev": 0.021329332471905393
        },
        {
          "name": "HMMT 2025",
          "score": 59.75921197389485,
          "source": "Multivariate regression",
          "stdDev": 0.03835183624871874
        },
        {
          "name": "CNMO 2024",
          "score": 84.58080229248732,
          "source": "Multivariate regression",
          "stdDev": 0.011052289610323349
        },
        {
          "name": "Terminal-Bench",
          "score": 40.76488558444811,
          "source": "Multivariate regression",
          "stdDev": 0.01010801436845375
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000005682293,
          "source": "Multivariate regression",
          "stdDev": 1.7324450306045487e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.082312551817324,
          "source": "Multivariate regression",
          "stdDev": 0.008493244580000454
        },
        {
          "name": "Tau-Bench Retail",
          "score": 80.0269003015242,
          "source": "Multivariate regression",
          "stdDev": 0.023632167076029647
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.40365838054474,
          "source": "Multivariate regression",
          "stdDev": 0.007831639280390674
        },
        {
          "name": "MMMU",
          "score": 71.31374530148122,
          "source": "Multivariate regression",
          "stdDev": 0.01226511711369071
        },
        {
          "name": "MMMU-Pro",
          "score": 69.0514850767754,
          "source": "Multivariate regression",
          "stdDev": 0.03704164659705723
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 70.20307611108996,
          "source": "Multivariate regression",
          "stdDev": 0.025975578312953326
        },
        {
          "name": "VideoMMMU",
          "score": 78.12725641758922,
          "source": "Multivariate regression",
          "stdDev": 0.01563496106742692
        },
        {
          "name": "ERQA",
          "score": 65.88265410401308,
          "source": "Multivariate regression",
          "stdDev": 0.016715475546182607
        },
        {
          "name": "SWE-Lancer",
          "score": 27.29168412274663,
          "source": "Multivariate regression",
          "stdDev": 0.03776982458052469
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 59.395662756342546,
          "source": "Multivariate regression",
          "stdDev": 0.015913913336652156
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 46.98708148753818,
          "source": "Multivariate regression",
          "stdDev": 0.016350508172839333
        },
        {
          "name": "COLLIE",
          "score": 65.48265438695432,
          "source": "Multivariate regression",
          "stdDev": 0.03178264725989276
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 54.19241558526352,
          "source": "Multivariate regression",
          "stdDev": 0.011042822537394248
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 54.64131900448916,
          "source": "Multivariate regression",
          "stdDev": 0.02096394275796563
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 40.867918656161805,
          "source": "Multivariate regression",
          "stdDev": 0.027469916664234807
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 38.49223390885709,
          "source": "Multivariate regression",
          "stdDev": 0.03519963133846746
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 66.48898543371621,
          "source": "Multivariate regression",
          "stdDev": 0.04559617314070614
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 56.187070879475186,
          "source": "Multivariate regression",
          "stdDev": 0.031012908782645912
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 64.20947576672256,
          "source": "Multivariate regression",
          "stdDev": 0.0760247898105512
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 86.64966161292442,
          "source": "Multivariate regression",
          "stdDev": 0.004708609118549796
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 61.31252607886174,
          "source": "Multivariate regression",
          "stdDev": 0.033770156118007294
        },
        {
          "name": "VideoMME",
          "score": 73.5944728183797,
          "source": "Multivariate regression",
          "stdDev": 0.14719285406472513
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 3.098341588597762,
          "source": "Multivariate regression",
          "stdDev": 0.00177883979305393
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 6.091199721022441,
          "source": "Multivariate regression",
          "stdDev": 0.0030038517955188
        },
        {
          "name": "FActScore hallucination rate",
          "score": 7.037809825555144,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 88.02969236714297,
          "source": "Multivariate regression",
          "stdDev": 0.0027510990184589855
        }
      ]
    },
    {
      "name": "Qwen3-235B-A22B",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.53079428929345,
          "source": "Multivariate regression",
          "stdDev": 0.00040558495386635224
        },
        {
          "name": "MMLU-Pro",
          "score": 83.80047126409266,
          "source": "Multivariate regression",
          "stdDev": 0.0021341414599860596
        },
        {
          "name": "GPQA Diamond",
          "score": 71.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 28.15619676897729,
          "source": "Multivariate regression",
          "stdDev": 0.0017034049706666206
        },
        {
          "name": "FRAMES",
          "score": 82.79058817642796,
          "source": "Multivariate regression",
          "stdDev": 0.0002952315043397714
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.968757725826556,
          "source": "Multivariate regression",
          "stdDev": 0.006895755180692209
        },
        {
          "name": "LiveCodeBench",
          "score": 51.75,
          "source": "Multiple: Score 66.5 at https://huggingface.co/deepseek-ai/DeepSeek-R1-0528; Score 37 at undefined",
          "stdDev": 20.859650045003153
        },
        {
          "name": "Codeforces",
          "score": 2345.0540525912675,
          "source": "Multivariate regression",
          "stdDev": 0.4406165429966037
        },
        {
          "name": "SWE-bench Verified",
          "score": 34.4,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 59.6,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 85.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 81.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 62.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 83.68473686348273,
          "source": "Multivariate regression",
          "stdDev": 0.011599606534005482
        },
        {
          "name": "Terminal-Bench",
          "score": 19.945649132747008,
          "source": "Multivariate regression",
          "stdDev": 0.009845138177427125
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000032062918,
          "source": "Multivariate regression",
          "stdDev": 1.711516293711386e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.38546100837736,
          "source": "Multivariate regression",
          "stdDev": 0.008465126480892295
        },
        {
          "name": "Tau-Bench Retail",
          "score": 76.39736768493255,
          "source": "Multivariate regression",
          "stdDev": 0.023470192291034378
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.67380821165935,
          "source": "Multivariate regression",
          "stdDev": 0.007615557347347354
        },
        {
          "name": "MMMU",
          "score": 72.43151723169456,
          "source": "Multivariate regression",
          "stdDev": 0.012147924714260044
        },
        {
          "name": "MMMU-Pro",
          "score": 80.72842087771966,
          "source": "Multivariate regression",
          "stdDev": 0.03652309693830783
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 73.22493092116011,
          "source": "Multivariate regression",
          "stdDev": 0.025754350640144204
        },
        {
          "name": "VideoMMMU",
          "score": 73.98526412197643,
          "source": "Multivariate regression",
          "stdDev": 0.015573845348761594
        },
        {
          "name": "ERQA",
          "score": 57.19611413699337,
          "source": "Multivariate regression",
          "stdDev": 0.016600976642035366
        },
        {
          "name": "SWE-Lancer",
          "score": 102.49001609076066,
          "source": "Multivariate regression",
          "stdDev": 0.03653774643390869
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 54.04904916862141,
          "source": "Multivariate regression",
          "stdDev": 0.016092690377463702
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 41.203280595495556,
          "source": "Multivariate regression",
          "stdDev": 0.016115511874552287
        },
        {
          "name": "COLLIE",
          "score": 50.639831799121,
          "source": "Multivariate regression",
          "stdDev": 0.03214070395060629
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 72.6682559023667,
          "source": "Multivariate regression",
          "stdDev": 0.01091251147276206
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 70.04624749474979,
          "source": "Multivariate regression",
          "stdDev": 0.020596798462303785
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 49.682000377185034,
          "source": "Multivariate regression",
          "stdDev": 0.027469916664234807
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 54.44886665901333,
          "source": "Multivariate regression",
          "stdDev": 0.034982213441998214
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 58.61645342407385,
          "source": "Multivariate regression",
          "stdDev": 0.045260285316734934
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 52.91156162019183,
          "source": "Multivariate regression",
          "stdDev": 0.030516928630445694
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 59.73591707633602,
          "source": "Multivariate regression",
          "stdDev": 0.07582381609767139
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89.41284537741593,
          "source": "Multivariate regression",
          "stdDev": 0.004746433155532965
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 86.87978436407644,
          "source": "Multivariate regression",
          "stdDev": 0.03308545113863623
        },
        {
          "name": "VideoMME",
          "score": 73.29687101398866,
          "source": "Multivariate regression",
          "stdDev": 0.14212984393757516
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.497104679346805,
          "source": "Multivariate regression",
          "stdDev": 0.0017577727962916339
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 4.601426485286552,
          "source": "Multivariate regression",
          "stdDev": 0.003013756833956069
        },
        {
          "name": "FActScore hallucination rate",
          "score": 16.634424731928902,
          "source": "Multivariate regression",
          "stdDev": 0.012027371629091864
        },
        {
          "name": "MMMLU",
          "score": 85.5594025320043,
          "source": "Multivariate regression",
          "stdDev": 0.0027293472699191673
        }
      ]
    },
    {
      "name": "Qwen3-Coder 480B-A358-Instruct",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.19659621512814,
          "source": "Multivariate regression",
          "stdDev": 0.00037702441964944334
        },
        {
          "name": "MMLU-Pro",
          "score": 84.70381513662903,
          "source": "Multivariate regression",
          "stdDev": 0.0021411123496022167
        },
        {
          "name": "GPQA Diamond",
          "score": 64.42551277363847,
          "source": "Multivariate regression",
          "stdDev": 0.011454787959452544
        },
        {
          "name": "SimpleQA",
          "score": 29.618074896819806,
          "source": "Multivariate regression",
          "stdDev": 0.0016946345245226343
        },
        {
          "name": "FRAMES",
          "score": 82.27524154097549,
          "source": "Multivariate regression",
          "stdDev": 0.00028479474085685617
        },
        {
          "name": "Humanity's Last Exam",
          "score": 9.493504317665298,
          "source": "Multivariate regression",
          "stdDev": 0.006878446113254205
        },
        {
          "name": "LiveCodeBench",
          "score": 67.97658128091278,
          "source": "Multivariate regression",
          "stdDev": 0.01797640426550052
        },
        {
          "name": "Codeforces",
          "score": 2215.363677344474,
          "source": "Multivariate regression",
          "stdDev": 0.42711144677036916
        },
        {
          "name": "SWE-bench Verified",
          "score": 69.6,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 61.8,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 87.52352427334786,
          "source": "Multivariate regression",
          "stdDev": 0.006704049016184139
        },
        {
          "name": "AIME 2025",
          "score": 65.43198381195327,
          "source": "Multivariate regression",
          "stdDev": 0.020739934702657944
        },
        {
          "name": "HMMT 2025",
          "score": 63.561483839173974,
          "source": "Multivariate regression",
          "stdDev": 0.03775032419014487
        },
        {
          "name": "CNMO 2024",
          "score": 77.1952198196303,
          "source": "Multivariate regression",
          "stdDev": 0.01139221225933363
        },
        {
          "name": "Terminal-Bench",
          "score": 37.5,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999981905096,
          "source": "Multivariate regression",
          "stdDev": 1.6958740061809343e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 51.35307109588098,
          "source": "Multivariate regression",
          "stdDev": 0.00832311122997214
        },
        {
          "name": "Tau-Bench Retail",
          "score": 71.1227706615855,
          "source": "Multivariate regression",
          "stdDev": 0.022642944895085525
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.151253709877167,
          "source": "Multivariate regression",
          "stdDev": 0.0074892833487539895
        },
        {
          "name": "MMMU",
          "score": 74.5133960897098,
          "source": "Multivariate regression",
          "stdDev": 0.011829737120159516
        },
        {
          "name": "MMMU-Pro",
          "score": 59.973115765105774,
          "source": "Multivariate regression",
          "stdDev": 0.036313603799437634
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 77.06196026966299,
          "source": "Multivariate regression",
          "stdDev": 0.02523061029852669
        },
        {
          "name": "VideoMMMU",
          "score": 61.951830274426015,
          "source": "Multivariate regression",
          "stdDev": 0.015512488849772967
        },
        {
          "name": "ERQA",
          "score": 43.71423855415118,
          "source": "Multivariate regression",
          "stdDev": 0.016485682521623992
        },
        {
          "name": "SWE-Lancer",
          "score": 53.8548356797848,
          "source": "Multivariate regression",
          "stdDev": 0.036328337773783526
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 59.24168109943275,
          "source": "Multivariate regression",
          "stdDev": 0.015488744211742534
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 52.343066655579406,
          "source": "Multivariate regression",
          "stdDev": 0.015936990841448027
        },
        {
          "name": "COLLIE",
          "score": 82.5819685510728,
          "source": "Multivariate regression",
          "stdDev": 0.03142051055048308
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 52.678872870254224,
          "source": "Multivariate regression",
          "stdDev": 0.010824765956377583
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 69.19850437053125,
          "source": "Multivariate regression",
          "stdDev": 0.020596798462303785
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 41.10372869317149,
          "source": "Multivariate regression",
          "stdDev": 0.027400394600705664
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 51.06531184081632,
          "source": "Multivariate regression",
          "stdDev": 0.03398662540647822
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 60.9913355669203,
          "source": "Multivariate regression",
          "stdDev": 0.043366424192741
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 53.50558618826744,
          "source": "Multivariate regression",
          "stdDev": 0.03026589076787954
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 77.51833828923327,
          "source": "Multivariate regression",
          "stdDev": 0.07232186570801731
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 88.78024940917018,
          "source": "Multivariate regression",
          "stdDev": 0.004683223382691532
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 66.85074206291213,
          "source": "Multivariate regression",
          "stdDev": 0.03296995120584554
        },
        {
          "name": "VideoMME",
          "score": 82.31724894426424,
          "source": "Multivariate regression",
          "stdDev": 0.1412683684082161
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.9968943634102274,
          "source": "Multivariate regression",
          "stdDev": 0.001736450228890443
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.491094584732984,
          "source": "Multivariate regression",
          "stdDev": 0.0029839430825487835
        },
        {
          "name": "FActScore hallucination rate",
          "score": 16.65048597314916,
          "source": "Multivariate regression",
          "stdDev": 0.011907839659445585
        },
        {
          "name": "MMMLU",
          "score": 87.71101073554271,
          "source": "Multivariate regression",
          "stdDev": 0.002696390658915922
        }
      ]
    },
    {
      "name": "Qwen3-32B",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.10351476782395,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 84.38934019435428,
          "source": "Multivariate regression",
          "stdDev": 0.0021411123496022167
        },
        {
          "name": "GPQA Diamond",
          "score": 68.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 30.15719592151455,
          "source": "Multivariate regression",
          "stdDev": 0.0016813930795987332
        },
        {
          "name": "FRAMES",
          "score": 82.9692945379636,
          "source": "Multivariate regression",
          "stdDev": 0.00028965844048390904
        },
        {
          "name": "Humanity's Last Exam",
          "score": 12.678244025170102,
          "source": "Multivariate regression",
          "stdDev": 0.0067028975183816035
        },
        {
          "name": "LiveCodeBench",
          "score": 69.33252021283538,
          "source": "Multivariate regression",
          "stdDev": 0.017655226379738955
        },
        {
          "name": "Codeforces",
          "score": 2218.7472338715397,
          "source": "Multivariate regression",
          "stdDev": 0.43166009540178474
        },
        {
          "name": "SWE-bench Verified",
          "score": 56.42626203977153,
          "source": "Multivariate regression",
          "stdDev": 0.020969210056611273
        },
        {
          "name": "Aider",
          "score": 56.57848564938524,
          "source": "Multivariate regression",
          "stdDev": 0.03720791226569046
        },
        {
          "name": "AIME 2024",
          "score": 81.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 72.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 78.91456024829884,
          "source": "Multivariate regression",
          "stdDev": 0.03682964058580787
        },
        {
          "name": "CNMO 2024",
          "score": 86.0752013382771,
          "source": "Multivariate regression",
          "stdDev": 0.011433992062185355
        },
        {
          "name": "Terminal-Bench",
          "score": 36.980476470944865,
          "source": "Multivariate regression",
          "stdDev": 0.009869325351351845
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.000000273748434,
          "source": "Multivariate regression",
          "stdDev": 1.689917892807796e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 58.09499792807246,
          "source": "Multivariate regression",
          "stdDev": 0.008294416398293808
        },
        {
          "name": "Tau-Bench Retail",
          "score": 79.76259342246817,
          "source": "Multivariate regression",
          "stdDev": 0.023060278399230236
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 11.960536519272296,
          "source": "Multivariate regression",
          "stdDev": 0.007552684250935558
        },
        {
          "name": "MMMU",
          "score": 83.59169872890095,
          "source": "Multivariate regression",
          "stdDev": 0.011829737120159516
        },
        {
          "name": "MMMU-Pro",
          "score": 71.0985915870512,
          "source": "Multivariate regression",
          "stdDev": 0.03610289506175413
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 54.3885711950758,
          "source": "Multivariate regression",
          "stdDev": 0.024772878565931154
        },
        {
          "name": "VideoMMMU",
          "score": 68.83680105282599,
          "source": "Multivariate regression",
          "stdDev": 0.015170593028417244
        },
        {
          "name": "ERQA",
          "score": 54.00458693685239,
          "source": "Multivariate regression",
          "stdDev": 0.01613485780559915
        },
        {
          "name": "SWE-Lancer",
          "score": 10.389708265168508,
          "source": "Multivariate regression",
          "stdDev": 0.03653774643390869
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 53.650225866448764,
          "source": "Multivariate regression",
          "stdDev": 0.015733104963357926
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 55.79570130220547,
          "source": "Multivariate regression",
          "stdDev": 0.01599671921717734
        },
        {
          "name": "COLLIE",
          "score": 91.94500533580356,
          "source": "Multivariate regression",
          "stdDev": 0.030931066989808464
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 43.779359482707605,
          "source": "Multivariate regression",
          "stdDev": 0.010669475052828475
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 60.80659498535266,
          "source": "Multivariate regression",
          "stdDev": 0.01998580933237874
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 28.410982562691572,
          "source": "Multivariate regression",
          "stdDev": 0.027120524242939703
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 51.039189065181404,
          "source": "Multivariate regression",
          "stdDev": 0.03421037116990651
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 64.28090831306315,
          "source": "Multivariate regression",
          "stdDev": 0.043716865457049316
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 66.45832961728519,
          "source": "Multivariate regression",
          "stdDev": 0.029949134505776475
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 40.2478939330249,
          "source": "Multivariate regression",
          "stdDev": 0.0718986585635538
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 83.86207966955303,
          "source": "Multivariate regression",
          "stdDev": 0.004683223382691532
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 69.61398661481698,
          "source": "Multivariate regression",
          "stdDev": 0.03285404523014762
        },
        {
          "name": "VideoMME",
          "score": 67.88462623543847,
          "source": "Multivariate regression",
          "stdDev": 0.14083565457731032
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.7589998059881182,
          "source": "Multivariate regression",
          "stdDev": 0.0017321542183708193
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.256666240465691,
          "source": "Multivariate regression",
          "stdDev": 0.002923403573104198
        },
        {
          "name": "FActScore hallucination rate",
          "score": 9.155307914389198,
          "source": "Multivariate regression",
          "stdDev": 0.011827480573742348
        },
        {
          "name": "MMMLU",
          "score": 88.10933154150993,
          "source": "Multivariate regression",
          "stdDev": 0.0026741939525655686
        }
      ]
    },
    {
      "name": "Qwen3-8B",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.34673483207571,
          "source": "Multivariate regression",
          "stdDev": 0.0003962935455011187
        },
        {
          "name": "MMLU-Pro",
          "score": 84.48324429197145,
          "source": "Multivariate regression",
          "stdDev": 0.00222305869519261
        },
        {
          "name": "GPQA Diamond",
          "score": 62,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 30.022392331056437,
          "source": "Multivariate regression",
          "stdDev": 0.0016769560301119002
        },
        {
          "name": "FRAMES",
          "score": 82.37778367752027,
          "source": "Multivariate regression",
          "stdDev": 0.00028965844048390904
        },
        {
          "name": "Humanity's Last Exam",
          "score": 2.903264417789295,
          "source": "Multivariate regression",
          "stdDev": 0.007015723025159587
        },
        {
          "name": "LiveCodeBench",
          "score": 54.392458835193366,
          "source": "Multivariate regression",
          "stdDev": 0.01813486024801798
        },
        {
          "name": "Codeforces",
          "score": 1685.4763892017418,
          "source": "Multivariate regression",
          "stdDev": 0.43616130956594246
        },
        {
          "name": "SWE-bench Verified",
          "score": 64.56273391948787,
          "source": "Multivariate regression",
          "stdDev": 0.021816218609596965
        },
        {
          "name": "Aider",
          "score": 58.69656922758804,
          "source": "Multivariate regression",
          "stdDev": 0.03821940188547982
        },
        {
          "name": "AIME 2024",
          "score": 76,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 67.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 75.5603623379651,
          "source": "Multivariate regression",
          "stdDev": 0.038451173430466154
        },
        {
          "name": "CNMO 2024",
          "score": 81.87445130997045,
          "source": "Multivariate regression",
          "stdDev": 0.011722281974639641
        },
        {
          "name": "Terminal-Bench",
          "score": 15.61703252881233,
          "source": "Multivariate regression",
          "stdDev": 0.010155078965191444
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.999999679142284,
          "source": "Multivariate regression",
          "stdDev": 1.738411356831538e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.78755027473355,
          "source": "Multivariate regression",
          "stdDev": 0.00854920334371065
        },
        {
          "name": "Tau-Bench Retail",
          "score": 71.99812650529586,
          "source": "Multivariate regression",
          "stdDev": 0.02371273957127275
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 20.119145887525377,
          "source": "Multivariate regression",
          "stdDev": 0.007801136882529047
        },
        {
          "name": "MMMU",
          "score": 79.30636270139172,
          "source": "Multivariate regression",
          "stdDev": 0.01206916427224841
        },
        {
          "name": "MMMU-Pro",
          "score": 69.21800584459652,
          "source": "Multivariate regression",
          "stdDev": 0.03693851902946342
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 68.35706350829778,
          "source": "Multivariate regression",
          "stdDev": 0.026194937688210792
        },
        {
          "name": "VideoMMMU",
          "score": 56.379461181195666,
          "source": "Multivariate regression",
          "stdDev": 0.01535802522241383
        },
        {
          "name": "ERQA",
          "score": 55.122778843318585,
          "source": "Multivariate regression",
          "stdDev": 0.016998348916853402
        },
        {
          "name": "SWE-Lancer",
          "score": 65.05401618732583,
          "source": "Multivariate regression",
          "stdDev": 0.03807161452364947
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 57.011467729018975,
          "source": "Multivariate regression",
          "stdDev": 0.015913913336652156
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 53.499759450303884,
          "source": "Multivariate regression",
          "stdDev": 0.01652456242714231
        },
        {
          "name": "COLLIE",
          "score": 78.91035913910582,
          "source": "Multivariate regression",
          "stdDev": 0.031054151085793166
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 64.54065451494881,
          "source": "Multivariate regression",
          "stdDev": 0.01091251147276206
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 70.14642429009214,
          "source": "Multivariate regression",
          "stdDev": 0.021054728524131688
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 37.12411921812662,
          "source": "Multivariate regression",
          "stdDev": 0.027814920597911654
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 58.25382624307008,
          "source": "Multivariate regression",
          "stdDev": 0.03509109077576202
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 56.45463654933161,
          "source": "Multivariate regression",
          "stdDev": 0.044580918235297175
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 58.73676059284804,
          "source": "Multivariate regression",
          "stdDev": 0.030889660351474668
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 68.1145273572177,
          "source": "Multivariate regression",
          "stdDev": 0.07562230827929342
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.73198050674944,
          "source": "Multivariate regression",
          "stdDev": 0.00482119108076493
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 95.51902358647035,
          "source": "Multivariate regression",
          "stdDev": 0.03285404523014762
        },
        {
          "name": "VideoMME",
          "score": 72.62485200368775,
          "source": "Multivariate regression",
          "stdDev": 0.1459435690608513
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.785655263855972,
          "source": "Multivariate regression",
          "stdDev": 0.0017407356371969638
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 5.932660524528664,
          "source": "Multivariate regression",
          "stdDev": 0.002953828428593063
        },
        {
          "name": "FActScore hallucination rate",
          "score": 28.112369818896923,
          "source": "Multivariate regression",
          "stdDev": 0.012379044274577103
        },
        {
          "name": "MMMLU",
          "score": 85.92298918264235,
          "source": "Multivariate regression",
          "stdDev": 0.0027019113434523967
        }
      ]
    },
    {
      "name": "Phi 4 Reasoning Plus 14B",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.9378702664619,
          "source": "Multivariate regression",
          "stdDev": 0.00041466822328181224
        },
        {
          "name": "MMLU-Pro",
          "score": 84.57694305797091,
          "source": "Multivariate regression",
          "stdDev": 0.0021271477261449743
        },
        {
          "name": "GPQA Diamond",
          "score": 69.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.54777020011079,
          "source": "Multivariate regression",
          "stdDev": 0.0017508572949341344
        },
        {
          "name": "FRAMES",
          "score": 82.70748754611944,
          "source": "Multivariate regression",
          "stdDev": 0.0002991487048129461
        },
        {
          "name": "Humanity's Last Exam",
          "score": 16.17435859257718,
          "source": "Multivariate regression",
          "stdDev": 0.006964561280400202
        },
        {
          "name": "LiveCodeBench",
          "score": 58.1696168289348,
          "source": "Multivariate regression",
          "stdDev": 0.018395920726596026
        },
        {
          "name": "Codeforces",
          "score": 1819.7441524198293,
          "source": "Multivariate regression",
          "stdDev": 0.4622490540415176
        },
        {
          "name": "SWE-bench Verified",
          "score": 50.42408541093596,
          "source": "Multivariate regression",
          "stdDev": 0.02137460895767686
        },
        {
          "name": "Aider",
          "score": 73.98935168821902,
          "source": "Multivariate regression",
          "stdDev": 0.03720791226569046
        },
        {
          "name": "AIME 2024",
          "score": 81.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 78,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 53.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 85.0911936974685,
          "source": "Multivariate regression",
          "stdDev": 0.01155842538702121
        },
        {
          "name": "Terminal-Bench",
          "score": 22.46170540942967,
          "source": "Multivariate regression",
          "stdDev": 0.009796584681215532
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999959521181,
          "source": "Multivariate regression",
          "stdDev": 1.732914333521748e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.317601500730696,
          "source": "Multivariate regression",
          "stdDev": 0.008632461368967875
        },
        {
          "name": "Tau-Bench Retail",
          "score": 67.05503087884898,
          "source": "Multivariate regression",
          "stdDev": 0.023060278399230236
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.887197131382067,
          "source": "Multivariate regression",
          "stdDev": 0.00777051475140173
        },
        {
          "name": "MMMU",
          "score": 76.53625223187977,
          "source": "Multivariate regression",
          "stdDev": 0.01230393319751676
        },
        {
          "name": "MMMU-Pro",
          "score": 59.331861181194654,
          "source": "Multivariate regression",
          "stdDev": 0.03704164659705723
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 64.33509764167127,
          "source": "Multivariate regression",
          "stdDev": 0.025531206103484833
        },
        {
          "name": "VideoMMMU",
          "score": 70.10471814372997,
          "source": "Multivariate regression",
          "stdDev": 0.015604433128555147
        },
        {
          "name": "ERQA",
          "score": 41.388351886829795,
          "source": "Multivariate regression",
          "stdDev": 0.016485682521623992
        },
        {
          "name": "SWE-Lancer",
          "score": 44.90223667946384,
          "source": "Multivariate regression",
          "stdDev": 0.03653774643390869
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 57.0142471366742,
          "source": "Multivariate regression",
          "stdDev": 0.016033319523794824
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 62.228003778015335,
          "source": "Multivariate regression",
          "stdDev": 0.016292076874274603
        },
        {
          "name": "COLLIE",
          "score": 59.65138032186758,
          "source": "Multivariate regression",
          "stdDev": 0.030807491144148186
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 46.809932483257796,
          "source": "Multivariate regression",
          "stdDev": 0.010802718215900476
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 58.09523367758737,
          "source": "Multivariate regression",
          "stdDev": 0.02031708677689507
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 67.90840772076336,
          "source": "Multivariate regression",
          "stdDev": 0.0281556973665412
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 72.87342074164076,
          "source": "Multivariate regression",
          "stdDev": 0.03552326322225719
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 68.69814505674285,
          "source": "Multivariate regression",
          "stdDev": 0.04592960464887818
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 65.59626789404314,
          "source": "Multivariate regression",
          "stdDev": 0.030827851358209205
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 55.21599076003139,
          "source": "Multivariate regression",
          "stdDev": 0.07521767314427169
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 85.656760010157,
          "source": "Multivariate regression",
          "stdDev": 0.0047964012403202624
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 67.38562068188233,
          "source": "Multivariate regression",
          "stdDev": 0.033657005952748315
        },
        {
          "name": "VideoMME",
          "score": 67.2089262405841,
          "source": "Multivariate regression",
          "stdDev": 0.14636118222643418
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.4165613013866931,
          "source": "Multivariate regression",
          "stdDev": 0.0017620063463497392
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.5224498397205224,
          "source": "Multivariate regression",
          "stdDev": 0.003072516578127651
        },
        {
          "name": "FActScore hallucination rate",
          "score": 18.18566402142784,
          "source": "Multivariate regression",
          "stdDev": 0.012106403963898463
        },
        {
          "name": "MMMLU",
          "score": 86.33750886416027,
          "source": "Multivariate regression",
          "stdDev": 0.002718406127685821
        }
      ]
    },
    {
      "name": "Gemini 2.5 Flash Thinking 0520",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.13077206820454,
          "source": "Multivariate regression",
          "stdDev": 0.0003915651719795637
        },
        {
          "name": "MMLU-Pro",
          "score": 84.71038542476745,
          "source": "Multivariate regression",
          "stdDev": 0.0021756317945731537
        },
        {
          "name": "GPQA Diamond",
          "score": 82.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "SimpleQA",
          "score": 29.620411836315398,
          "source": "Multivariate regression",
          "stdDev": 0.001716476617281253
        },
        {
          "name": "FRAMES",
          "score": 82.90542184248206,
          "source": "Multivariate regression",
          "stdDev": 0.0002904611392783517
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.98127256883766,
          "source": "Multivariate regression",
          "stdDev": 0.006930243622719664
        },
        {
          "name": "LiveCodeBench",
          "score": 62.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2268.623506173906,
          "source": "Multivariate regression",
          "stdDev": 0.42711144677036916
        },
        {
          "name": "SWE-bench Verified",
          "score": 65.04316244288356,
          "source": "Multivariate regression",
          "stdDev": 0.021014640587721217
        },
        {
          "name": "Aider",
          "score": 48.84524943711392,
          "source": "Multivariate regression",
          "stdDev": 0.037818052598710294
        },
        {
          "name": "AIME 2024",
          "score": 82.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "AIME 2025",
          "score": 72,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "HMMT 2025",
          "score": 64.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
          "stdDev": 0
        },
        {
          "name": "CNMO 2024",
          "score": 84.33113232986676,
          "source": "Multivariate regression",
          "stdDev": 0.011517096991470124
        },
        {
          "name": "Terminal-Bench",
          "score": 30.670072782140522,
          "source": "Multivariate regression",
          "stdDev": 0.009893453393483962
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000006054534,
          "source": "Multivariate regression",
          "stdDev": 1.7134093359822172e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 60.535942267509434,
          "source": "Multivariate regression",
          "stdDev": 0.008351707472408949
        },
        {
          "name": "Tau-Bench Retail",
          "score": 74.88911090798378,
          "source": "Multivariate regression",
          "stdDev": 0.023470192291034378
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 20.177122111278678,
          "source": "Multivariate regression",
          "stdDev": 0.007708905576367222
        },
        {
          "name": "MMMU",
          "score": 73.87513048235552,
          "source": "Multivariate regression",
          "stdDev": 0.012381200295680846
        },
        {
          "name": "MMMU-Pro",
          "score": 68.40332754786391,
          "source": "Multivariate regression",
          "stdDev": 0.03693851902946342
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 60.22686598463744,
          "source": "Multivariate regression",
          "stdDev": 0.025605803685185242
        },
        {
          "name": "VideoMMMU",
          "score": 58.17564201453047,
          "source": "Multivariate regression",
          "stdDev": 0.015512488849772967
        },
        {
          "name": "ERQA",
          "score": 67.04424880761313,
          "source": "Multivariate regression",
          "stdDev": 0.01688576822751829
        },
        {
          "name": "SWE-Lancer",
          "score": 96.14276320988233,
          "source": "Multivariate regression",
          "stdDev": 0.03695300383722015
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 46.634936632599974,
          "source": "Multivariate regression",
          "stdDev": 0.015853872998534548
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 49.887162357059225,
          "source": "Multivariate regression",
          "stdDev": 0.016174581033573894
        },
        {
          "name": "COLLIE",
          "score": 70.28993721003519,
          "source": "Multivariate regression",
          "stdDev": 0.03129886721147858
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 42.127260855578584,
          "source": "Multivariate regression",
          "stdDev": 0.010824765956377583
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 58.48073605395294,
          "source": "Multivariate regression",
          "stdDev": 0.020781181425222426
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 81.17214257555446,
          "source": "Multivariate regression",
          "stdDev": 0.027190761895862812
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 60.78349364985627,
          "source": "Multivariate regression",
          "stdDev": 0.03476343579451002
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 51.12909710470231,
          "source": "Multivariate regression",
          "stdDev": 0.0450914031483802
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 62.1465853407297,
          "source": "Multivariate regression",
          "stdDev": 0.03045436316474359
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 70.42407523880416,
          "source": "Multivariate regression",
          "stdDev": 0.07521767314427169
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 86.54518724091814,
          "source": "Multivariate regression",
          "stdDev": 0.004708609118549796
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 59.32268369147823,
          "source": "Multivariate regression",
          "stdDev": 0.03354347410707611
        },
        {
          "name": "VideoMME",
          "score": 81.1391085077127,
          "source": "Multivariate regression",
          "stdDev": 0.1446834973751999
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.617821502797625,
          "source": "Multivariate regression",
          "stdDev": 0.0017492749586600772
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": -1.186208668764607,
          "source": "Multivariate regression",
          "stdDev": 0.0029839430825487835
        },
        {
          "name": "FActScore hallucination rate",
          "score": 5.390904746187232,
          "source": "Multivariate regression",
          "stdDev": 0.011907839659445585
        },
        {
          "name": "MMMLU",
          "score": 84.54228231870712,
          "source": "Multivariate regression",
          "stdDev": 0.002734801426466446
        }
      ]
    },
    {
      "name": "GPT-4o",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.85540841356395,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.61099734967885,
          "source": "Multivariate regression",
          "stdDev": 0.0021824701665647795
        },
        {
          "name": "GPQA Diamond",
          "score": 76.41555909564411,
          "source": "Multivariate regression",
          "stdDev": 0.011413084284259568
        },
        {
          "name": "SimpleQA",
          "score": 28.63024894946622,
          "source": "Multivariate regression",
          "stdDev": 0.001707773303247711
        },
        {
          "name": "FRAMES",
          "score": 82.85860419060607,
          "source": "Multivariate regression",
          "stdDev": 0.00029758801221932256
        },
        {
          "name": "Humanity's Last Exam",
          "score": 12.571160219998461,
          "source": "Multivariate regression",
          "stdDev": 0.006861093378889426
        },
        {
          "name": "LiveCodeBench",
          "score": 68.06254900998285,
          "source": "Multivariate regression",
          "stdDev": 0.018344005853313302
        },
        {
          "name": "Codeforces",
          "score": 1885.7614941867032,
          "source": "Multivariate regression",
          "stdDev": 0.44939452373418826
        },
        {
          "name": "SWE-bench Verified",
          "score": 30.8,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 29.374464745264618,
          "source": "Multivariate regression",
          "stdDev": 0.03731029522400712
        },
        {
          "name": "AIME 2024",
          "score": 80.89304212121529,
          "source": "Multivariate regression",
          "stdDev": 0.006827386268925354
        },
        {
          "name": "AIME 2025",
          "score": 87.98366580631637,
          "source": "Multivariate regression",
          "stdDev": 0.020877426502539837
        },
        {
          "name": "HMMT 2025",
          "score": 52.80072919668257,
          "source": "Multivariate regression",
          "stdDev": 0.038152385961903304
        },
        {
          "name": "CNMO 2024",
          "score": 80.60148028527755,
          "source": "Multivariate regression",
          "stdDev": 0.011475619756445572
        },
        {
          "name": "Terminal-Bench",
          "score": 32.38182100883938,
          "source": "Multivariate regression",
          "stdDev": 0.010037003686273015
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999998633492,
          "source": "Multivariate regression",
          "stdDev": 1.718022381795217e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 57.72900954426622,
          "source": "Multivariate regression",
          "stdDev": 0.008465126480892295
        },
        {
          "name": "Tau-Bench Retail",
          "score": 66.97111441926484,
          "source": "Multivariate regression",
          "stdDev": 0.023307091874510633
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 15.308524819299592,
          "source": "Multivariate regression",
          "stdDev": 0.007708905576367222
        },
        {
          "name": "MMMU",
          "score": 72.94371935071132,
          "source": "Multivariate regression",
          "stdDev": 0.012381200295680846
        },
        {
          "name": "MMMU-Pro",
          "score": 75.3581076696446,
          "source": "Multivariate regression",
          "stdDev": 0.036731395277439856
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 65.01914589530674,
          "source": "Multivariate regression",
          "stdDev": 0.025531206103484833
        },
        {
          "name": "VideoMMMU",
          "score": 79.46569407294334,
          "source": "Multivariate regression",
          "stdDev": 0.0155431973747597
        },
        {
          "name": "ERQA",
          "score": 74.29756311099331,
          "source": "Multivariate regression",
          "stdDev": 0.016829195465043887
        },
        {
          "name": "SWE-Lancer",
          "score": 65.613205742763,
          "source": "Multivariate regression",
          "stdDev": 0.03715889236314919
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 62.39933883127914,
          "source": "Multivariate regression",
          "stdDev": 0.015913913336652156
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 50.1193657385314,
          "source": "Multivariate regression",
          "stdDev": 0.01599671921717734
        },
        {
          "name": "COLLIE",
          "score": 94.94772679119785,
          "source": "Multivariate regression",
          "stdDev": 0.031902446009326915
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 59.10606871051647,
          "source": "Multivariate regression",
          "stdDev": 0.010780625385103817
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 61.74540732709201,
          "source": "Multivariate regression",
          "stdDev": 0.020827022112170093
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 72.590374336835,
          "source": "Multivariate regression",
          "stdDev": 0.027400394600705664
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 56.68468245197312,
          "source": "Multivariate regression",
          "stdDev": 0.034872996182867204
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 33.340830167088,
          "source": "Multivariate regression",
          "stdDev": 0.04542853966412251
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 51.840757322366244,
          "source": "Multivariate regression",
          "stdDev": 0.03064167631783493
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 40.91926817737868,
          "source": "Multivariate regression",
          "stdDev": 0.07521767314427169
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 83.36692391472533,
          "source": "Multivariate regression",
          "stdDev": 0.0046959334047385615
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 87.73970535727793,
          "source": "Multivariate regression",
          "stdDev": 0.03296995120584554
        },
        {
          "name": "VideoMME",
          "score": 53.75445867869598,
          "source": "Multivariate regression",
          "stdDev": 0.14298612926686097
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.494879185646603,
          "source": "Multivariate regression",
          "stdDev": 0.0017620063463497392
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.8106052609833654,
          "source": "Multivariate regression",
          "stdDev": 0.0029939139875197027
        },
        {
          "name": "FActScore hallucination rate",
          "score": 3.7407538548393404,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 86.56936707696829,
          "source": "Multivariate regression",
          "stdDev": 0.0027293472699191673
        }
      ]
    },
    {
      "name": "GLM-4.5",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.2404993134094,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.21831254755827,
          "source": "Multivariate regression",
          "stdDev": 0.002189287178588728
        },
        {
          "name": "GPQA Diamond",
          "score": 90.86803556413548,
          "source": "Multivariate regression",
          "stdDev": 0.011823503543521912
        },
        {
          "name": "SimpleQA",
          "score": 28.76475925363036,
          "source": "Multivariate regression",
          "stdDev": 0.0017337521802289633
        },
        {
          "name": "FRAMES",
          "score": 82.75031341234266,
          "source": "Multivariate regression",
          "stdDev": 0.00029758801221932256
        },
        {
          "name": "Humanity's Last Exam",
          "score": 10.799292242545896,
          "source": "Multivariate regression",
          "stdDev": 0.0070326942308660025
        },
        {
          "name": "LiveCodeBench",
          "score": 72.9,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 1953.2522368583304,
          "source": "Multivariate regression",
          "stdDev": 0.44939452373418826
        },
        {
          "name": "SWE-bench Verified",
          "score": 64.2,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 60.692580397383665,
          "source": "Multivariate regression",
          "stdDev": 0.038119460724839335
        },
        {
          "name": "AIME 2024",
          "score": 83.49062047841727,
          "source": "Multivariate regression",
          "stdDev": 0.0069141374126219304
        },
        {
          "name": "AIME 2025",
          "score": 79.73624643796285,
          "source": "Multivariate regression",
          "stdDev": 0.021284573640650294
        },
        {
          "name": "HMMT 2025",
          "score": 66.02540509027165,
          "source": "Multivariate regression",
          "stdDev": 0.038152385961903304
        },
        {
          "name": "CNMO 2024",
          "score": 79.45450954409606,
          "source": "Multivariate regression",
          "stdDev": 0.01155842538702121
        },
        {
          "name": "Terminal-Bench",
          "score": 37.5,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.9999998136838,
          "source": "Multivariate regression",
          "stdDev": 1.731969340595906e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 55.886076884418834,
          "source": "Multivariate regression",
          "stdDev": 0.008604798203823236
        },
        {
          "name": "Tau-Bench Retail",
          "score": 88.44678761627165,
          "source": "Multivariate regression",
          "stdDev": 0.023632167076029647
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 9.174206806663136,
          "source": "Multivariate regression",
          "stdDev": 0.007831639280390674
        },
        {
          "name": "MMMU",
          "score": 81.91289035308915,
          "source": "Multivariate regression",
          "stdDev": 0.012457988176049132
        },
        {
          "name": "MMMU-Pro",
          "score": 63.48163499526299,
          "source": "Multivariate regression",
          "stdDev": 0.03652309693830783
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 78.40391851971825,
          "source": "Multivariate regression",
          "stdDev": 0.025902045699649788
        },
        {
          "name": "VideoMMMU",
          "score": 48.102185003962745,
          "source": "Multivariate regression",
          "stdDev": 0.015756481359922355
        },
        {
          "name": "ERQA",
          "score": 70.21304110572166,
          "source": "Multivariate regression",
          "stdDev": 0.01688576822751829
        },
        {
          "name": "SWE-Lancer",
          "score": 43.7064693565934,
          "source": "Multivariate regression",
          "stdDev": 0.03746560376198223
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 55.02748325792237,
          "source": "Multivariate regression",
          "stdDev": 0.015913913336652156
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 46.96128161078897,
          "source": "Multivariate regression",
          "stdDev": 0.01652456242714231
        },
        {
          "name": "COLLIE",
          "score": 101.65714322374265,
          "source": "Multivariate regression",
          "stdDev": 0.03142051055048308
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 57.961123584018026,
          "source": "Multivariate regression",
          "stdDev": 0.0110643918382614
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 64.71565289966392,
          "source": "Multivariate regression",
          "stdDev": 0.02096394275796563
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 49.67308425460533,
          "source": "Multivariate regression",
          "stdDev": 0.027469916664234807
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 62.434758879993865,
          "source": "Multivariate regression",
          "stdDev": 0.034872996182867204
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 42.27786135929824,
          "source": "Multivariate regression",
          "stdDev": 0.04559617314070614
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 76.0330501191334,
          "source": "Multivariate regression",
          "stdDev": 0.03070386009661637
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 59.929803300741526,
          "source": "Multivariate regression",
          "stdDev": 0.07582381609767139
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 80.31747373513883,
          "source": "Multivariate regression",
          "stdDev": 0.004783958148708554
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 101.19963513620334,
          "source": "Multivariate regression",
          "stdDev": 0.034107354453670774
        },
        {
          "name": "VideoMME",
          "score": 82.74944871484979,
          "source": "Multivariate regression",
          "stdDev": 0.1459435690608513
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.742917718031947,
          "source": "Multivariate regression",
          "stdDev": 0.001774646400880553
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.3973929963997804,
          "source": "Multivariate regression",
          "stdDev": 0.003013756833956069
        },
        {
          "name": "FActScore hallucination rate",
          "score": 12.88363719758911,
          "source": "Multivariate regression",
          "stdDev": 0.012106403963898463
        },
        {
          "name": "MMMLU",
          "score": 87.75554865236398,
          "source": "Multivariate regression",
          "stdDev": 0.002734801426466446
        }
      ]
    },
    {
      "name": "GLM-4.5-Air",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.14295485547785,
          "source": "Multivariate regression",
          "stdDev": 0.00041466822328181224
        },
        {
          "name": "MMLU-Pro",
          "score": 84.33937269955558,
          "source": "Multivariate regression",
          "stdDev": 0.0021824701665647795
        },
        {
          "name": "GPQA Diamond",
          "score": 66.75033714986672,
          "source": "Multivariate regression",
          "stdDev": 0.011620106043476712
        },
        {
          "name": "SimpleQA",
          "score": 28.779866693830556,
          "source": "Multivariate regression",
          "stdDev": 0.0017337521802289633
        },
        {
          "name": "FRAMES",
          "score": 82.62451098682878,
          "source": "Multivariate regression",
          "stdDev": 0.00029758801221932256
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.268546870995145,
          "source": "Multivariate regression",
          "stdDev": 0.006861093378889426
        },
        {
          "name": "LiveCodeBench",
          "score": 70.7,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2108.0676090887882,
          "source": "Multivariate regression",
          "stdDev": 0.45371983421741424
        },
        {
          "name": "SWE-bench Verified",
          "score": 57.6,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 53.58129554540659,
          "source": "Multivariate regression",
          "stdDev": 0.037717047973397505
        },
        {
          "name": "AIME 2024",
          "score": 84.80327285797091,
          "source": "Multivariate regression",
          "stdDev": 0.0068622183310729475
        },
        {
          "name": "AIME 2025",
          "score": 87.12145456606811,
          "source": "Multivariate regression",
          "stdDev": 0.02114972882014868
        },
        {
          "name": "HMMT 2025",
          "score": 62.87303762252117,
          "source": "Multivariate regression",
          "stdDev": 0.03855025463873146
        },
        {
          "name": "CNMO 2024",
          "score": 82.84689362119309,
          "source": "Multivariate regression",
          "stdDev": 0.011681533305887339
        },
        {
          "name": "Terminal-Bench",
          "score": 30,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.000000439280385,
          "source": "Multivariate regression",
          "stdDev": 1.732926846526426e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 52.42936433068269,
          "source": "Multivariate regression",
          "stdDev": 0.008408608209513493
        },
        {
          "name": "Tau-Bench Retail",
          "score": 74.32064038915651,
          "source": "Multivariate regression",
          "stdDev": 0.023307091874510633
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 12.47522802823508,
          "source": "Multivariate regression",
          "stdDev": 0.007677915604325338
        },
        {
          "name": "MMMU",
          "score": 72.94619709163797,
          "source": "Multivariate regression",
          "stdDev": 0.012342627210013321
        },
        {
          "name": "MMMU-Pro",
          "score": 58.52646448533443,
          "source": "Multivariate regression",
          "stdDev": 0.03724704514030316
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 71.29212296990411,
          "source": "Multivariate regression",
          "stdDev": 0.025456389921451866
        },
        {
          "name": "VideoMMMU",
          "score": 50.95574710193375,
          "source": "Multivariate regression",
          "stdDev": 0.01563496106742692
        },
        {
          "name": "ERQA",
          "score": 46.21792683628286,
          "source": "Multivariate regression",
          "stdDev": 0.016772431885920456
        },
        {
          "name": "SWE-Lancer",
          "score": 54.9438790899099,
          "source": "Multivariate regression",
          "stdDev": 0.03746560376198223
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 58.44513403996473,
          "source": "Multivariate regression",
          "stdDev": 0.016092690377463702
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 53.071833723129984,
          "source": "Multivariate regression",
          "stdDev": 0.016408731399559756
        },
        {
          "name": "COLLIE",
          "score": 67.57509424080126,
          "source": "Multivariate regression",
          "stdDev": 0.03214070395060629
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 61.040355999060864,
          "source": "Multivariate regression",
          "stdDev": 0.010999557049080481
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 72.00967652130592,
          "source": "Multivariate regression",
          "stdDev": 0.02096394275796563
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 19.481739561932613,
          "source": "Multivariate regression",
          "stdDev": 0.027677435093174368
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 39.95251283688333,
          "source": "Multivariate regression",
          "stdDev": 0.03519963133846746
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 30.981440974770464,
          "source": "Multivariate regression",
          "stdDev": 0.04559617314070614
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 68.75905495040962,
          "source": "Multivariate regression",
          "stdDev": 0.030951345914113186
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 50.982236362390665,
          "source": "Multivariate regression",
          "stdDev": 0.07419643160296517
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 86.70439519228239,
          "source": "Multivariate regression",
          "stdDev": 0.0047964012403202624
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 92.10204928326667,
          "source": "Multivariate regression",
          "stdDev": 0.03342955669225716
        },
        {
          "name": "VideoMME",
          "score": 61.51622578679252,
          "source": "Multivariate regression",
          "stdDev": 0.14212984393757516
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.8034262763604687,
          "source": "Multivariate regression",
          "stdDev": 0.001753529025191503
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 5.113734082208708,
          "source": "Multivariate regression",
          "stdDev": 0.003072516578127651
        },
        {
          "name": "FActScore hallucination rate",
          "score": 22.99151544290646,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 88.4733944895871,
          "source": "Multivariate regression",
          "stdDev": 0.002718406127685821
        }
      ]
    },
    {
      "name": "Kimi-K2-Instruct",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.35602795984697,
          "source": "Multivariate regression",
          "stdDev": 0.0003915651719795637
        },
        {
          "name": "MMLU-Pro",
          "score": 84.6484180890409,
          "source": "Multivariate regression",
          "stdDev": 0.002106027179710805
        },
        {
          "name": "GPQA Diamond",
          "score": 73.7846593114217,
          "source": "Multivariate regression",
          "stdDev": 0.011413084284259568
        },
        {
          "name": "SimpleQA",
          "score": 29.492616778649783,
          "source": "Multivariate regression",
          "stdDev": 0.0016725072094717012
        },
        {
          "name": "FRAMES",
          "score": 82.90162055133011,
          "source": "Multivariate regression",
          "stdDev": 0.00028723688530835843
        },
        {
          "name": "Humanity's Last Exam",
          "score": 10.779202489574544,
          "source": "Multivariate regression",
          "stdDev": 0.006667233158044132
        },
        {
          "name": "LiveCodeBench",
          "score": 53.7,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2071.593345350053,
          "source": "Multivariate regression",
          "stdDev": 0.43166009540178474
        },
        {
          "name": "SWE-bench Verified",
          "score": 65.8,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 59.1,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 81.2013034588175,
          "source": "Multivariate regression",
          "stdDev": 0.006596496171210149
        },
        {
          "name": "AIME 2025",
          "score": 84.54490442632937,
          "source": "Multivariate regression",
          "stdDev": 0.02069390110244327
        },
        {
          "name": "HMMT 2025",
          "score": 81.5026923185994,
          "source": "Multivariate regression",
          "stdDev": 0.037139071195622764
        },
        {
          "name": "CNMO 2024",
          "score": 82.82712771361675,
          "source": "Multivariate regression",
          "stdDev": 0.011138242871444038
        },
        {
          "name": "Terminal-Bench",
          "score": 25,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999986347322,
          "source": "Multivariate regression",
          "stdDev": 1.670722135834997e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.06309218135392,
          "source": "Multivariate regression",
          "stdDev": 0.008265621950590414
        },
        {
          "name": "Tau-Bench Retail",
          "score": 72.25403113581751,
          "source": "Multivariate regression",
          "stdDev": 0.022303456334375162
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 15.336016082145761,
          "source": "Multivariate regression",
          "stdDev": 0.007230122254312079
        },
        {
          "name": "MMMU",
          "score": 83.51219090612815,
          "source": "Multivariate regression",
          "stdDev": 0.011708187621611691
        },
        {
          "name": "MMMU-Pro",
          "score": 93.41126112593003,
          "source": "Multivariate regression",
          "stdDev": 0.03578450570073983
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 62.04299653299134,
          "source": "Multivariate regression",
          "stdDev": 0.025002791928887585
        },
        {
          "name": "VideoMMMU",
          "score": 97.25133689662496,
          "source": "Multivariate regression",
          "stdDev": 0.015107598889335438
        },
        {
          "name": "ERQA",
          "score": 63.902028779956225,
          "source": "Multivariate regression",
          "stdDev": 0.01619385639802071
        },
        {
          "name": "SWE-Lancer",
          "score": 85.24960918195586,
          "source": "Multivariate regression",
          "stdDev": 0.036223179469434444
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 53.16784458528761,
          "source": "Multivariate regression",
          "stdDev": 0.01542704925201107
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 55.564207276756065,
          "source": "Multivariate regression",
          "stdDev": 0.01569580461617525
        },
        {
          "name": "COLLIE",
          "score": 103.55257753773787,
          "source": "Multivariate regression",
          "stdDev": 0.030433753087698842
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 64.13971769479167,
          "source": "Multivariate regression",
          "stdDev": 0.010602225541287067
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 84.59247958939886,
          "source": "Multivariate regression",
          "stdDev": 0.020410749921683662
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 41.988884596874584,
          "source": "Multivariate regression",
          "stdDev": 0.026623672818612106
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 70.76006374772169,
          "source": "Multivariate regression",
          "stdDev": 0.03342070815922398
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 68.61831325078657,
          "source": "Multivariate regression",
          "stdDev": 0.04423732239384807
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 55.816121166777464,
          "source": "Multivariate regression",
          "stdDev": 0.029693296694415578
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 37.972082776941875,
          "source": "Multivariate regression",
          "stdDev": 0.07378397730106104
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.05342097615811,
          "source": "Multivariate regression",
          "stdDev": 0.004644884646956948
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 80.36179052822806,
          "source": "Multivariate regression",
          "stdDev": 0.032030961994074354
        },
        {
          "name": "VideoMME",
          "score": 70.17886157941973,
          "source": "Multivariate regression",
          "stdDev": 0.1390913381566928
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.8621602520861913,
          "source": "Multivariate regression",
          "stdDev": 0.0016841750096375078
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 7.277102214175237,
          "source": "Multivariate regression",
          "stdDev": 0.0029131913439496213
        },
        {
          "name": "FActScore hallucination rate",
          "score": 28.40028090197677,
          "source": "Multivariate regression",
          "stdDev": 0.011665101776522468
        },
        {
          "name": "MMMLU",
          "score": 87.29053897634527,
          "source": "Multivariate regression",
          "stdDev": 0.002617878926165476
        }
      ]
    },
    {
      "name": "DeepSeek-V3-0324",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.1250570995627,
          "source": "Multivariate regression",
          "stdDev": 0.00041913604676543486
        },
        {
          "name": "MMLU-Pro",
          "score": 84.42188593233294,
          "source": "Multivariate regression",
          "stdDev": 0.0021824701665647795
        },
        {
          "name": "GPQA Diamond",
          "score": 72.47945985129442,
          "source": "Multivariate regression",
          "stdDev": 0.01170188929594091
        },
        {
          "name": "SimpleQA",
          "score": 28.141289300235094,
          "source": "Multivariate regression",
          "stdDev": 0.0017294494676789018
        },
        {
          "name": "FRAMES",
          "score": 82.72567416428002,
          "source": "Multivariate regression",
          "stdDev": 0.0002991487048129461
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.482356770254569,
          "source": "Multivariate regression",
          "stdDev": 0.006998710666019337
        },
        {
          "name": "LiveCodeBench",
          "score": 46.9,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2352.156973578678,
          "source": "Multivariate regression",
          "stdDev": 0.43166009540178474
        },
        {
          "name": "SWE-bench Verified",
          "score": 38.8,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 55.1,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 76.28650781325314,
          "source": "Multivariate regression",
          "stdDev": 0.006721807181889488
        },
        {
          "name": "AIME 2025",
          "score": 62.75981325626577,
          "source": "Multivariate regression",
          "stdDev": 0.0213739975748546
        },
        {
          "name": "HMMT 2025",
          "score": 50.21059669687082,
          "source": "Multivariate regression",
          "stdDev": 0.03805226878984729
        },
        {
          "name": "CNMO 2024",
          "score": 85.41938670045317,
          "source": "Multivariate regression",
          "stdDev": 0.01139221225933363
        },
        {
          "name": "Terminal-Bench",
          "score": 2.5,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.999999620392586,
          "source": "Multivariate regression",
          "stdDev": 1.7370324901850522e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 56.54640445763304,
          "source": "Multivariate regression",
          "stdDev": 0.008465126480892295
        },
        {
          "name": "Tau-Bench Retail",
          "score": 70.78693847986673,
          "source": "Multivariate regression",
          "stdDev": 0.02322511215002534
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.259007712997104,
          "source": "Multivariate regression",
          "stdDev": 0.00777051475140173
        },
        {
          "name": "MMMU",
          "score": 72.4264610387889,
          "source": "Multivariate regression",
          "stdDev": 0.012226177795866641
        },
        {
          "name": "MMMU-Pro",
          "score": 78.41397576126417,
          "source": "Multivariate regression",
          "stdDev": 0.036731395277439856
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 54.30479986143101,
          "source": "Multivariate regression",
          "stdDev": 0.025828303741460088
        },
        {
          "name": "VideoMMMU",
          "score": 60.37264007008605,
          "source": "Multivariate regression",
          "stdDev": 0.015816891397439418
        },
        {
          "name": "ERQA",
          "score": 57.621867427023105,
          "source": "Multivariate regression",
          "stdDev": 0.016772431885920456
        },
        {
          "name": "SWE-Lancer",
          "score": 44.75980002839117,
          "source": "Multivariate regression",
          "stdDev": 0.03726141001340874
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 47.16861594205896,
          "source": "Multivariate regression",
          "stdDev": 0.016092690377463702
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 47.719052219350274,
          "source": "Multivariate regression",
          "stdDev": 0.016582174526923055
        },
        {
          "name": "COLLIE",
          "score": 64.38271417762292,
          "source": "Multivariate regression",
          "stdDev": 0.03214070395060629
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 52.031329592719544,
          "source": "Multivariate regression",
          "stdDev": 0.0110643918382614
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 77.9615317734949,
          "source": "Multivariate regression",
          "stdDev": 0.021009384679044556
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 22.429981493179696,
          "source": "Multivariate regression",
          "stdDev": 0.027608435596231364
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 34.557177212676834,
          "source": "Multivariate regression",
          "stdDev": 0.03563048728952525
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 42.64790956837197,
          "source": "Multivariate regression",
          "stdDev": 0.04559617314070614
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 66.46551795868265,
          "source": "Multivariate regression",
          "stdDev": 0.029885380378697975
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 62.06913656342107,
          "source": "Multivariate regression",
          "stdDev": 0.07622523364256413
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 84.40818787525356,
          "source": "Multivariate regression",
          "stdDev": 0.004783958148708554
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 60.30885662510113,
          "source": "Multivariate regression",
          "stdDev": 0.03388292842665515
        },
        {
          "name": "VideoMME",
          "score": 62.10791932954555,
          "source": "Multivariate regression",
          "stdDev": 0.14255862951859305
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.5682850641368447,
          "source": "Multivariate regression",
          "stdDev": 0.0017577727962916339
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 5.875045239366983,
          "source": "Multivariate regression",
          "stdDev": 0.0030038517955188
        },
        {
          "name": "FActScore hallucination rate",
          "score": 20.865330684379444,
          "source": "Multivariate regression",
          "stdDev": 0.012145727283843593
        },
        {
          "name": "MMMLU",
          "score": 86.17447024187614,
          "source": "Multivariate regression",
          "stdDev": 0.002756510136341546
        }
      ]
    },
    {
      "name": "Devstral Small 1.1",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.28795404263583,
          "source": "Multivariate regression",
          "stdDev": 0.00041015173424140605
        },
        {
          "name": "MMLU-Pro",
          "score": 84.24057646739305,
          "source": "Multivariate regression",
          "stdDev": 0.00222305869519261
        },
        {
          "name": "GPQA Diamond",
          "score": 78.97952059005065,
          "source": "Multivariate regression",
          "stdDev": 0.01170188929594091
        },
        {
          "name": "SimpleQA",
          "score": 28.48146437508195,
          "source": "Multivariate regression",
          "stdDev": 0.0017593474897278736
        },
        {
          "name": "FRAMES",
          "score": 82.8767963226325,
          "source": "Multivariate regression",
          "stdDev": 0.0002991487048129461
        },
        {
          "name": "Humanity's Last Exam",
          "score": 20.573600070856997,
          "source": "Multivariate regression",
          "stdDev": 0.007066514367285973
        },
        {
          "name": "LiveCodeBench",
          "score": 65.31907439667086,
          "source": "Multivariate regression",
          "stdDev": 0.01860213143460865
        },
        {
          "name": "Codeforces",
          "score": 2893.4862069911214,
          "source": "Multivariate regression",
          "stdDev": 0.45371983421741424
        },
        {
          "name": "SWE-bench Verified",
          "score": 53.6,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 38.2092843863274,
          "source": "Multivariate regression",
          "stdDev": 0.037717047973397505
        },
        {
          "name": "AIME 2024",
          "score": 87.50011559362616,
          "source": "Multivariate regression",
          "stdDev": 0.0069141374126219304
        },
        {
          "name": "AIME 2025",
          "score": 72.29092162967675,
          "source": "Multivariate regression",
          "stdDev": 0.0214630489352169
        },
        {
          "name": "HMMT 2025",
          "score": 63.24281629965438,
          "source": "Multivariate regression",
          "stdDev": 0.038649081842163945
        },
        {
          "name": "CNMO 2024",
          "score": 83.21592978442949,
          "source": "Multivariate regression",
          "stdDev": 0.011803357290439612
        },
        {
          "name": "Terminal-Bench",
          "score": 45.350912972062645,
          "source": "Multivariate regression",
          "stdDev": 0.010155078965191444
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.9999995262896,
          "source": "Multivariate regression",
          "stdDev": 1.7486220989411327e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 54.35410915488524,
          "source": "Multivariate regression",
          "stdDev": 0.008351707472408949
        },
        {
          "name": "Tau-Bench Retail",
          "score": 77.47111347183511,
          "source": "Multivariate regression",
          "stdDev": 0.023551318932148037
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 12.908350424232793,
          "source": "Multivariate regression",
          "stdDev": 0.007831639280390674
        },
        {
          "name": "MMMU",
          "score": 68.7957429836423,
          "source": "Multivariate regression",
          "stdDev": 0.012572290656193036
        },
        {
          "name": "MMMU-Pro",
          "score": 69.3120474655874,
          "source": "Multivariate regression",
          "stdDev": 0.03745131720976288
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 64.39704246234663,
          "source": "Multivariate regression",
          "stdDev": 0.025902045699649788
        },
        {
          "name": "VideoMMMU",
          "score": 50.394325348207474,
          "source": "Multivariate regression",
          "stdDev": 0.015907076300427172
        },
        {
          "name": "ERQA",
          "score": 32.04381638637247,
          "source": "Multivariate regression",
          "stdDev": 0.01688576822751829
        },
        {
          "name": "SWE-Lancer",
          "score": 79.9154959867767,
          "source": "Multivariate regression",
          "stdDev": 0.03776982458052469
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 47.77724436171766,
          "source": "Multivariate regression",
          "stdDev": 0.016210779773056502
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 52.19890029011859,
          "source": "Multivariate regression",
          "stdDev": 0.016696802367727803
        },
        {
          "name": "COLLIE",
          "score": 80.89809215499997,
          "source": "Multivariate regression",
          "stdDev": 0.03214070395060629
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 26.488864079582186,
          "source": "Multivariate regression",
          "stdDev": 0.011085919172932328
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 82.86246232711775,
          "source": "Multivariate regression",
          "stdDev": 0.021099974925522947
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 23.90830409056008,
          "source": "Multivariate regression",
          "stdDev": 0.027608435596231364
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 38.94007871531585,
          "source": "Multivariate regression",
          "stdDev": 0.03519963133846746
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 45.872325873539324,
          "source": "Multivariate regression",
          "stdDev": 0.0465893092828414
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 60.925402518466626,
          "source": "Multivariate regression",
          "stdDev": 0.031318907986851025
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 60.547668966877154,
          "source": "Multivariate regression",
          "stdDev": 0.07761384728731394
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.76474515812762,
          "source": "Multivariate regression",
          "stdDev": 0.004858138666804361
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 60.80728229831689,
          "source": "Multivariate regression",
          "stdDev": 0.034330313381774356
        },
        {
          "name": "VideoMME",
          "score": 78.64164082462247,
          "source": "Multivariate regression",
          "stdDev": 0.14552475747349478
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.5764993155488085,
          "source": "Multivariate regression",
          "stdDev": 0.00177883979305393
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 1.3007193790136213,
          "source": "Multivariate regression",
          "stdDev": 0.003072516578127651
        },
        {
          "name": "FActScore hallucination rate",
          "score": 4.423902807745094,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 87.67233503993401,
          "source": "Multivariate regression",
          "stdDev": 0.0027673006299513392
        }
      ]
    },
    {
      "name": "Devstral Small 1.0",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.06480533867422,
          "source": "Multivariate regression",
          "stdDev": 0.00041913604676543486
        },
        {
          "name": "MMLU-Pro",
          "score": 84.49441710463034,
          "source": "Multivariate regression",
          "stdDev": 0.0021756317945731537
        },
        {
          "name": "GPQA Diamond",
          "score": 64.76130029489346,
          "source": "Multivariate regression",
          "stdDev": 0.011454787959452544
        },
        {
          "name": "SimpleQA",
          "score": 29.44695547674116,
          "source": "Multivariate regression",
          "stdDev": 0.0016813930795987332
        },
        {
          "name": "FRAMES",
          "score": 82.56160754958157,
          "source": "Multivariate regression",
          "stdDev": 0.00029758801221932256
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.852952899568578,
          "source": "Multivariate regression",
          "stdDev": 0.006756041065537639
        },
        {
          "name": "LiveCodeBench",
          "score": 76.83220705040084,
          "source": "Multivariate regression",
          "stdDev": 0.018029377663954953
        },
        {
          "name": "Codeforces",
          "score": 2120.189554783692,
          "source": "Multivariate regression",
          "stdDev": 0.42711144677036916
        },
        {
          "name": "SWE-bench Verified",
          "score": 46.8,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 44.8297164644502,
          "source": "Multivariate regression",
          "stdDev": 0.03741239800164938
        },
        {
          "name": "AIME 2024",
          "score": 86.89165820642103,
          "source": "Multivariate regression",
          "stdDev": 0.006596496171210149
        },
        {
          "name": "AIME 2025",
          "score": 74.82991737861812,
          "source": "Multivariate regression",
          "stdDev": 0.020877426502539837
        },
        {
          "name": "HMMT 2025",
          "score": 79.66771115947324,
          "source": "Multivariate regression",
          "stdDev": 0.037649137864362664
        },
        {
          "name": "CNMO 2024",
          "score": 79.48479947556325,
          "source": "Multivariate regression",
          "stdDev": 0.01155842538702121
        },
        {
          "name": "Terminal-Bench",
          "score": 39.28814438100241,
          "source": "Multivariate regression",
          "stdDev": 0.010037003686273015
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.000000109000666,
          "source": "Multivariate regression",
          "stdDev": 1.7185208592803983e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 51.68864756014655,
          "source": "Multivariate regression",
          "stdDev": 0.008493244580000454
        },
        {
          "name": "Tau-Bench Retail",
          "score": 67.54305656496769,
          "source": "Multivariate regression",
          "stdDev": 0.023307091874510633
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 18.106688922436163,
          "source": "Multivariate regression",
          "stdDev": 0.00777051475140173
        },
        {
          "name": "MMMU",
          "score": 79.40052721455234,
          "source": "Multivariate regression",
          "stdDev": 0.012187114062801587
        },
        {
          "name": "MMMU-Pro",
          "score": 67.37088907462964,
          "source": "Multivariate regression",
          "stdDev": 0.036731395277439856
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 72.23203825027022,
          "source": "Multivariate regression",
          "stdDev": 0.025605803685185242
        },
        {
          "name": "VideoMMMU",
          "score": 70.43402105597113,
          "source": "Multivariate regression",
          "stdDev": 0.01541999634776584
        },
        {
          "name": "ERQA",
          "score": 45.293190459026476,
          "source": "Multivariate regression",
          "stdDev": 0.016715475546182607
        },
        {
          "name": "SWE-Lancer",
          "score": 35.27531706667969,
          "source": "Multivariate regression",
          "stdDev": 0.03715889236314919
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 62.3036436489691,
          "source": "Multivariate regression",
          "stdDev": 0.015853872998534548
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 57.61701456273745,
          "source": "Multivariate regression",
          "stdDev": 0.015389007095491437
        },
        {
          "name": "COLLIE",
          "score": 114.05665356040095,
          "source": "Multivariate regression",
          "stdDev": 0.03142051055048308
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 44.591044560935586,
          "source": "Multivariate regression",
          "stdDev": 0.010846768881494351
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 71.37074585736028,
          "source": "Multivariate regression",
          "stdDev": 0.02068919534835477
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 51.23887708765653,
          "source": "Multivariate regression",
          "stdDev": 0.027400394600705664
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 60.615480004366646,
          "source": "Multivariate regression",
          "stdDev": 0.03509109077576202
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 72.18319821319741,
          "source": "Multivariate regression",
          "stdDev": 0.04542853966412251
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 55.61677991149713,
          "source": "Multivariate regression",
          "stdDev": 0.030391668899625537
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 66.24782348720987,
          "source": "Multivariate regression",
          "stdDev": 0.07481084946041243
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 88.41239009308201,
          "source": "Multivariate regression",
          "stdDev": 0.004461616672219324
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 79.24317249114415,
          "source": "Multivariate regression",
          "stdDev": 0.03285404523014762
        },
        {
          "name": "VideoMME",
          "score": 76.59649307739215,
          "source": "Multivariate regression",
          "stdDev": 0.14426102765549492
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.368220855239045,
          "source": "Multivariate regression",
          "stdDev": 0.00177883979305393
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.5414587652354754,
          "source": "Multivariate regression",
          "stdDev": 0.00290294318953844
        },
        {
          "name": "FActScore hallucination rate",
          "score": 8.807072007003228,
          "source": "Multivariate regression",
          "stdDev": 0.012262940683323939
        },
        {
          "name": "MMMLU",
          "score": 88.21324914031204,
          "source": "Multivariate regression",
          "stdDev": 0.002718406127685821
        }
      ]
    },
    {
      "name": "Magistral Medium 1.1",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.96906645923,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 83.80556934211344,
          "source": "Multivariate regression",
          "stdDev": 0.0021960830295598317
        },
        {
          "name": "GPQA Diamond",
          "score": 84.38351867398711,
          "source": "Multivariate regression",
          "stdDev": 0.011742567326222265
        },
        {
          "name": "SimpleQA",
          "score": 28.00113026599459,
          "source": "Multivariate regression",
          "stdDev": 0.0017251360236401618
        },
        {
          "name": "FRAMES",
          "score": 82.81188093569317,
          "source": "Multivariate regression",
          "stdDev": 0.0002944418106645466
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.331833724615564,
          "source": "Multivariate regression",
          "stdDev": 0.006913020909207856
        },
        {
          "name": "LiveCodeBench",
          "score": 59.35,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2998.030670643271,
          "source": "Multivariate regression",
          "stdDev": 0.44502717665585084
        },
        {
          "name": "SWE-bench Verified",
          "score": 65.91452980959787,
          "source": "Multivariate regression",
          "stdDev": 0.021508043936909683
        },
        {
          "name": "Aider",
          "score": 21.790900811420954,
          "source": "Multivariate regression",
          "stdDev": 0.037818052598710294
        },
        {
          "name": "AIME 2024",
          "score": 83.09102382373663,
          "source": "Multivariate regression",
          "stdDev": 0.0068448244567857275
        },
        {
          "name": "AIME 2025",
          "score": 66.90753941863176,
          "source": "Multivariate regression",
          "stdDev": 0.02114972882014868
        },
        {
          "name": "HMMT 2025",
          "score": 44.49608945840629,
          "source": "Multivariate regression",
          "stdDev": 0.038152385961903304
        },
        {
          "name": "CNMO 2024",
          "score": 77.99548875177352,
          "source": "Multivariate regression",
          "stdDev": 0.011640641995188623
        },
        {
          "name": "Terminal-Bench",
          "score": 41.15071044500564,
          "source": "Multivariate regression",
          "stdDev": 0.01010801436845375
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.999999855978565,
          "source": "Multivariate regression",
          "stdDev": 1.7263952855987025e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 54.73348248378126,
          "source": "Multivariate regression",
          "stdDev": 0.008351707472408949
        },
        {
          "name": "Tau-Bench Retail",
          "score": 77.52663350376078,
          "source": "Multivariate regression",
          "stdDev": 0.023060278399230236
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 13.619998207776021,
          "source": "Multivariate regression",
          "stdDev": 0.007831639280390674
        },
        {
          "name": "MMMU",
          "score": 68.56724253892453,
          "source": "Multivariate regression",
          "stdDev": 0.012381200295680846
        },
        {
          "name": "MMMU-Pro",
          "score": 54.13169710644223,
          "source": "Multivariate regression",
          "stdDev": 0.036731395277439856
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 69.7418154479594,
          "source": "Multivariate regression",
          "stdDev": 0.0256801845715694
        },
        {
          "name": "VideoMMMU",
          "score": 16.44518164879929,
          "source": "Multivariate regression",
          "stdDev": 0.01572618932002201
        },
        {
          "name": "ERQA",
          "score": 42.139290058334765,
          "source": "Multivariate regression",
          "stdDev": 0.016998348916853402
        },
        {
          "name": "SWE-Lancer",
          "score": 82.24693852937605,
          "source": "Multivariate regression",
          "stdDev": 0.037363646378781167
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 49.83777186630758,
          "source": "Multivariate regression",
          "stdDev": 0.015853872998534548
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 55.77016207775449,
          "source": "Multivariate regression",
          "stdDev": 0.016174581033573894
        },
        {
          "name": "COLLIE",
          "score": 87.01400398831265,
          "source": "Multivariate regression",
          "stdDev": 0.031902446009326915
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 33.85632368618354,
          "source": "Multivariate regression",
          "stdDev": 0.011021211023938304
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 77.34972949633416,
          "source": "Multivariate regression",
          "stdDev": 0.02091840212173117
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 28.55350296219001,
          "source": "Multivariate regression",
          "stdDev": 0.027400394600705664
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 62.38582115902091,
          "source": "Multivariate regression",
          "stdDev": 0.03519963133846746
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 37.447790736885594,
          "source": "Multivariate regression",
          "stdDev": 0.044580918235297175
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 61.39583992902186,
          "source": "Multivariate regression",
          "stdDev": 0.030827851358209205
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 47.21436776066554,
          "source": "Multivariate regression",
          "stdDev": 0.07582381609767139
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 89.08469077720744,
          "source": "Multivariate regression",
          "stdDev": 0.004771482608062634
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 73.20794058043447,
          "source": "Multivariate regression",
          "stdDev": 0.03342955669225716
        },
        {
          "name": "VideoMME",
          "score": 72.13326733393495,
          "source": "Multivariate regression",
          "stdDev": 0.14383731709024425
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 3.7583749577014487,
          "source": "Multivariate regression",
          "stdDev": 0.0017492749586600772
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 0.6325617465166857,
          "source": "Multivariate regression",
          "stdDev": 0.0029839430825487835
        },
        {
          "name": "FActScore hallucination rate",
          "score": 21.021845203210603,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 86.95143330555123,
          "source": "Multivariate regression",
          "stdDev": 0.002723882192281362
        }
      ]
    },
    {
      "name": "Magistral Medium 1.0",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.95579104988106,
          "source": "Multivariate regression",
          "stdDev": 0.0004009661637898005
        },
        {
          "name": "MMLU-Pro",
          "score": 84.49132055902876,
          "source": "Multivariate regression",
          "stdDev": 0.0021411123496022167
        },
        {
          "name": "GPQA Diamond",
          "score": 74.9407129969359,
          "source": "Multivariate regression",
          "stdDev": 0.011620106043476712
        },
        {
          "name": "SimpleQA",
          "score": 28.231690985614257,
          "source": "Multivariate regression",
          "stdDev": 0.0017337521802289633
        },
        {
          "name": "FRAMES",
          "score": 82.54580978370198,
          "source": "Multivariate regression",
          "stdDev": 0.0002968045884573551
        },
        {
          "name": "Humanity's Last Exam",
          "score": 7.54213413060674,
          "source": "Multivariate regression",
          "stdDev": 0.006998710666019337
        },
        {
          "name": "LiveCodeBench",
          "score": 59.36,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 1988.350861746776,
          "source": "Multivariate regression",
          "stdDev": 0.44502717665585084
        },
        {
          "name": "SWE-bench Verified",
          "score": 45.14443333172153,
          "source": "Multivariate regression",
          "stdDev": 0.0214636577814506
        },
        {
          "name": "Aider",
          "score": 76.39544358626262,
          "source": "Multivariate regression",
          "stdDev": 0.037818052598710294
        },
        {
          "name": "AIME 2024",
          "score": 80.13482764770765,
          "source": "Multivariate regression",
          "stdDev": 0.0068099034270692055
        },
        {
          "name": "AIME 2025",
          "score": 73.89103651529155,
          "source": "Multivariate regression",
          "stdDev": 0.02101401873196534
        },
        {
          "name": "HMMT 2025",
          "score": 62.985544887115026,
          "source": "Multivariate regression",
          "stdDev": 0.037951887509365546
        },
        {
          "name": "CNMO 2024",
          "score": 79.88150815812244,
          "source": "Multivariate regression",
          "stdDev": 0.01139221225933363
        },
        {
          "name": "Terminal-Bench",
          "score": 10.410331044347174,
          "source": "Multivariate regression",
          "stdDev": 0.010013221551531504
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000062928998,
          "source": "Multivariate regression",
          "stdDev": 1.72017300384748e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 52.47701839346259,
          "source": "Multivariate regression",
          "stdDev": 0.008577045818364064
        },
        {
          "name": "Tau-Bench Retail",
          "score": 66.59925026773242,
          "source": "Multivariate regression",
          "stdDev": 0.02322511215002534
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 16.801621933556618,
          "source": "Multivariate regression",
          "stdDev": 0.00777051475140173
        },
        {
          "name": "MMMU",
          "score": 75.77868756746419,
          "source": "Multivariate regression",
          "stdDev": 0.012187114062801587
        },
        {
          "name": "MMMU-Pro",
          "score": 67.13789471026894,
          "source": "Multivariate regression",
          "stdDev": 0.03693851902946342
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 71.99951717141474,
          "source": "Multivariate regression",
          "stdDev": 0.025605803685185242
        },
        {
          "name": "VideoMMMU",
          "score": 72.65769409654968,
          "source": "Multivariate regression",
          "stdDev": 0.015604433128555147
        },
        {
          "name": "ERQA",
          "score": 63.507089538693435,
          "source": "Multivariate regression",
          "stdDev": 0.01688576822751829
        },
        {
          "name": "SWE-Lancer",
          "score": 37.564972340297345,
          "source": "Multivariate regression",
          "stdDev": 0.03726141001340874
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 55.58701971075834,
          "source": "Multivariate regression",
          "stdDev": 0.015913913336652156
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 52.4108655132504,
          "source": "Multivariate regression",
          "stdDev": 0.016233435257038506
        },
        {
          "name": "COLLIE",
          "score": 81.42103240264942,
          "source": "Multivariate regression",
          "stdDev": 0.03142051055048308
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 58.22675995944002,
          "source": "Multivariate regression",
          "stdDev": 0.010846768881494351
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 60.97683991030547,
          "source": "Multivariate regression",
          "stdDev": 0.020781181425222426
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 47.7407459759508,
          "source": "Multivariate regression",
          "stdDev": 0.027469916664234807
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 53.45295235481376,
          "source": "Multivariate regression",
          "stdDev": 0.03509109077576202
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 62.56940353143446,
          "source": "Multivariate regression",
          "stdDev": 0.045763192569353725
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 62.36489411838278,
          "source": "Multivariate regression",
          "stdDev": 0.03026589076787954
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 64.372044038779,
          "source": "Multivariate regression",
          "stdDev": 0.07622523364256413
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 83.24591904965536,
          "source": "Multivariate regression",
          "stdDev": 0.0047964012403202624
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 52.96035877563034,
          "source": "Multivariate regression",
          "stdDev": 0.03354347410707611
        },
        {
          "name": "VideoMME",
          "score": 72.74539534506584,
          "source": "Multivariate regression",
          "stdDev": 0.14341235468124588
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.9038741997509234,
          "source": "Multivariate regression",
          "stdDev": 0.0017662297488635517
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 6.1311530695749,
          "source": "Multivariate regression",
          "stdDev": 0.0030236294248787
        },
        {
          "name": "FActScore hallucination rate",
          "score": 20.30814179726491,
          "source": "Multivariate regression",
          "stdDev": 0.012340464449749608
        },
        {
          "name": "MMMLU",
          "score": 88.02310534924254,
          "source": "Multivariate regression",
          "stdDev": 0.002712919009600568
        }
      ]
    },
    {
      "name": "Magistral Small 1.1",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.40807890995875,
          "source": "Multivariate regression",
          "stdDev": 0.00041913604676543486
        },
        {
          "name": "MMLU-Pro",
          "score": 83.85934129750325,
          "source": "Multivariate regression",
          "stdDev": 0.0021960830295598317
        },
        {
          "name": "GPQA Diamond",
          "score": 76.43346836492461,
          "source": "Multivariate regression",
          "stdDev": 0.011863764594768454
        },
        {
          "name": "SimpleQA",
          "score": 30.19406343849016,
          "source": "Multivariate regression",
          "stdDev": 0.0017380442409911585
        },
        {
          "name": "FRAMES",
          "score": 82.54515006388425,
          "source": "Multivariate regression",
          "stdDev": 0.00030070129724675055
        },
        {
          "name": "Humanity's Last Exam",
          "score": 19.373188636638815,
          "source": "Multivariate regression",
          "stdDev": 0.007015723025159587
        },
        {
          "name": "LiveCodeBench",
          "score": 59.17,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2457.4378798161633,
          "source": "Multivariate regression",
          "stdDev": 0.44502717665585084
        },
        {
          "name": "SWE-bench Verified",
          "score": 71.75561556538543,
          "source": "Multivariate regression",
          "stdDev": 0.021640656179757464
        },
        {
          "name": "Aider",
          "score": 58.958816275696165,
          "source": "Multivariate regression",
          "stdDev": 0.03821940188547982
        },
        {
          "name": "AIME 2024",
          "score": 82.92588329065732,
          "source": "Multivariate regression",
          "stdDev": 0.006982762381538164
        },
        {
          "name": "AIME 2025",
          "score": 68.38296802249386,
          "source": "Multivariate regression",
          "stdDev": 0.021284573640650294
        },
        {
          "name": "HMMT 2025",
          "score": 75.95426907619469,
          "source": "Multivariate regression",
          "stdDev": 0.038649081842163945
        },
        {
          "name": "CNMO 2024",
          "score": 82.01093993425152,
          "source": "Multivariate regression",
          "stdDev": 0.011640641995188623
        },
        {
          "name": "Terminal-Bench",
          "score": 43.165874418581694,
          "source": "Multivariate regression",
          "stdDev": 0.01010801436845375
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000014637198,
          "source": "Multivariate regression",
          "stdDev": 1.7364581595768754e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 54.67206487088476,
          "source": "Multivariate regression",
          "stdDev": 0.008687523444752767
        },
        {
          "name": "Tau-Bench Retail",
          "score": 76.91627498173006,
          "source": "Multivariate regression",
          "stdDev": 0.023470192291034378
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 16.72664292115205,
          "source": "Multivariate regression",
          "stdDev": 0.007677915604325338
        },
        {
          "name": "MMMU",
          "score": 76.59851471237207,
          "source": "Multivariate regression",
          "stdDev": 0.012381200295680846
        },
        {
          "name": "MMMU-Pro",
          "score": 67.20320899787009,
          "source": "Multivariate regression",
          "stdDev": 0.03662739418108093
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 65.93675617822345,
          "source": "Multivariate regression",
          "stdDev": 0.02604890335422964
        },
        {
          "name": "VideoMMMU",
          "score": 41.28725389744727,
          "source": "Multivariate regression",
          "stdDev": 0.015816891397439418
        },
        {
          "name": "ERQA",
          "score": 35.95866146327563,
          "source": "Multivariate regression",
          "stdDev": 0.016998348916853402
        },
        {
          "name": "SWE-Lancer",
          "score": 113.87164365259065,
          "source": "Multivariate regression",
          "stdDev": 0.037363646378781167
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 52.054847474693105,
          "source": "Multivariate regression",
          "stdDev": 0.016210779773056502
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 64.7339121034279,
          "source": "Multivariate regression",
          "stdDev": 0.016174581033573894
        },
        {
          "name": "COLLIE",
          "score": 81.17070707526409,
          "source": "Multivariate regression",
          "stdDev": 0.03202179657529022
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 44.537677923592696,
          "source": "Multivariate regression",
          "stdDev": 0.011107404785411924
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 76.13042253539419,
          "source": "Multivariate regression",
          "stdDev": 0.021009384679044556
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 45.53170071911586,
          "source": "Multivariate regression",
          "stdDev": 0.028223358968448103
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 73.70820970260843,
          "source": "Multivariate regression",
          "stdDev": 0.03476343579451002
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 56.800660850237705,
          "source": "Multivariate regression",
          "stdDev": 0.04542853966412251
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 68.91419935355646,
          "source": "Multivariate regression",
          "stdDev": 0.030951345914113186
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 61.358704228920885,
          "source": "Multivariate regression",
          "stdDev": 0.07582381609767139
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 93.95127253264802,
          "source": "Multivariate regression",
          "stdDev": 0.004845854105970265
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 83.59111359559074,
          "source": "Multivariate regression",
          "stdDev": 0.03342955669225716
        },
        {
          "name": "VideoMME",
          "score": 83.2896029678754,
          "source": "Multivariate regression",
          "stdDev": 0.14552475747349478
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.587382130861201,
          "source": "Multivariate regression",
          "stdDev": 0.0017913610727415318
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 0.7759484766821672,
          "source": "Multivariate regression",
          "stdDev": 0.00304327852628429
        },
        {
          "name": "FActScore hallucination rate",
          "score": 6.846011891385388,
          "source": "Multivariate regression",
          "stdDev": 0.012145727283843593
        },
        {
          "name": "MMMLU",
          "score": 86.32659184447019,
          "source": "Multivariate regression",
          "stdDev": 0.002723882192281362
        }
      ]
    },
    {
      "name": "Magistral Small 1.0",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.32390801697353,
          "source": "Multivariate regression",
          "stdDev": 0.00040558495386635224
        },
        {
          "name": "MMLU-Pro",
          "score": 84.26722258651577,
          "source": "Multivariate regression",
          "stdDev": 0.0021411123496022167
        },
        {
          "name": "GPQA Diamond",
          "score": 77.86289906746072,
          "source": "Multivariate regression",
          "stdDev": 0.011661069366831252
        },
        {
          "name": "SimpleQA",
          "score": 29.723871581108448,
          "source": "Multivariate regression",
          "stdDev": 0.0017423257286846164
        },
        {
          "name": "FRAMES",
          "score": 82.50451633214765,
          "source": "Multivariate regression",
          "stdDev": 0.0002999260056723506
        },
        {
          "name": "Humanity's Last Exam",
          "score": 12.781562573529563,
          "source": "Multivariate regression",
          "stdDev": 0.006998710666019337
        },
        {
          "name": "LiveCodeBench",
          "score": 55.84,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Codeforces",
          "score": 2100.162189276438,
          "source": "Multivariate regression",
          "stdDev": 0.4406165429966037
        },
        {
          "name": "SWE-bench Verified",
          "score": 59.65697035900331,
          "source": "Multivariate regression",
          "stdDev": 0.0214636577814506
        },
        {
          "name": "Aider",
          "score": 63.32986678156277,
          "source": "Multivariate regression",
          "stdDev": 0.038119460724839335
        },
        {
          "name": "AIME 2024",
          "score": 84.5390880047962,
          "source": "Multivariate regression",
          "stdDev": 0.0067923755864135885
        },
        {
          "name": "AIME 2025",
          "score": 78.53779470992936,
          "source": "Multivariate regression",
          "stdDev": 0.020968586853543036
        },
        {
          "name": "HMMT 2025",
          "score": 74.68404561569113,
          "source": "Multivariate regression",
          "stdDev": 0.037951887509365546
        },
        {
          "name": "CNMO 2024",
          "score": 76.77988907937288,
          "source": "Multivariate regression",
          "stdDev": 0.01139221225933363
        },
        {
          "name": "Terminal-Bench",
          "score": 24.01984236877115,
          "source": "Multivariate regression",
          "stdDev": 0.01010801436845375
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000010264997,
          "source": "Multivariate regression",
          "stdDev": 1.7323448961945195e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 53.21533165108621,
          "source": "Multivariate regression",
          "stdDev": 0.00854920334371065
        },
        {
          "name": "Tau-Bench Retail",
          "score": 71.1635061913355,
          "source": "Multivariate regression",
          "stdDev": 0.02338878425469149
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 19.94502155611984,
          "source": "Multivariate regression",
          "stdDev": 0.007862023338579025
        },
        {
          "name": "MMMU",
          "score": 83.7803089955509,
          "source": "Multivariate regression",
          "stdDev": 0.012187114062801587
        },
        {
          "name": "MMMU-Pro",
          "score": 76.21621990155262,
          "source": "Multivariate regression",
          "stdDev": 0.03693851902946342
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 63.98124918472291,
          "source": "Multivariate regression",
          "stdDev": 0.025754350640144204
        },
        {
          "name": "VideoMMMU",
          "score": 65.47837663657992,
          "source": "Multivariate regression",
          "stdDev": 0.015665429515221145
        },
        {
          "name": "ERQA",
          "score": 50.48815842210837,
          "source": "Multivariate regression",
          "stdDev": 0.016998348916853402
        },
        {
          "name": "SWE-Lancer",
          "score": 75.51251911042368,
          "source": "Multivariate regression",
          "stdDev": 0.03715889236314919
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 58.02154511843243,
          "source": "Multivariate regression",
          "stdDev": 0.015913913336652156
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 54.44932366350032,
          "source": "Multivariate regression",
          "stdDev": 0.015936990841448027
        },
        {
          "name": "COLLIE",
          "score": 97.55392879575663,
          "source": "Multivariate regression",
          "stdDev": 0.03202179657529022
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 56.91864156833219,
          "source": "Multivariate regression",
          "stdDev": 0.010868727263426815
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 81.90904062673346,
          "source": "Multivariate regression",
          "stdDev": 0.02096394275796563
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 61.99979441440286,
          "source": "Multivariate regression",
          "stdDev": 0.027746263002474857
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 77.42660244808371,
          "source": "Multivariate regression",
          "stdDev": 0.034982213441998214
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 53.281027327491046,
          "source": "Multivariate regression",
          "stdDev": 0.04642526198514933
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 67.39602461026107,
          "source": "Multivariate regression",
          "stdDev": 0.030951345914113186
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 78.78996298609246,
          "source": "Multivariate regression",
          "stdDev": 0.0760247898105512
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 84.29574210817563,
          "source": "Multivariate regression",
          "stdDev": 0.004708609118549796
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 81.27048755915996,
          "source": "Multivariate regression",
          "stdDev": 0.03399532663907034
        },
        {
          "name": "VideoMME",
          "score": 82.04498107922927,
          "source": "Multivariate regression",
          "stdDev": 0.1451047370874551
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.5203877939348516,
          "source": "Multivariate regression",
          "stdDev": 0.0017662297488635517
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": -1.0677193623628511,
          "source": "Multivariate regression",
          "stdDev": 0.00304327852628429
        },
        {
          "name": "FActScore hallucination rate",
          "score": 15.124532841711982,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 85.3530190496206,
          "source": "Multivariate regression",
          "stdDev": 0.0027402447271348963
        }
      ]
    },
    {
      "name": "gpt-oss-120b (with tools)",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.52095157051066,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 84.27659353748788,
          "source": "Multivariate regression",
          "stdDev": 0.0021341414599860596
        },
        {
          "name": "GPQA Diamond",
          "score": 63.986923441347116,
          "source": "Multivariate regression",
          "stdDev": 0.011578997804008676
        },
        {
          "name": "SimpleQA",
          "score": 29.61991465374239,
          "source": "Multivariate regression",
          "stdDev": 0.0016990254067841078
        },
        {
          "name": "FRAMES",
          "score": 82.62088822940197,
          "source": "Multivariate regression",
          "stdDev": 0.00028723688530835843
        },
        {
          "name": "Humanity's Last Exam",
          "score": 10.460934768052766,
          "source": "Multivariate regression",
          "stdDev": 0.006861093378889426
        },
        {
          "name": "LiveCodeBench",
          "score": 56.62893337249314,
          "source": "Multivariate regression",
          "stdDev": 0.018239732823722165
        },
        {
          "name": "Codeforces",
          "score": 2622,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 62,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 41.8,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 86.43463953792318,
          "source": "Multivariate regression",
          "stdDev": 0.00661454309199749
        },
        {
          "name": "AIME 2025",
          "score": 64.76478122662576,
          "source": "Multivariate regression",
          "stdDev": 0.020831696732050903
        },
        {
          "name": "HMMT 2025",
          "score": 68.71602916694161,
          "source": "Multivariate regression",
          "stdDev": 0.037649137864362664
        },
        {
          "name": "CNMO 2024",
          "score": 80.85193719699902,
          "source": "Multivariate regression",
          "stdDev": 0.011265943245573923
        },
        {
          "name": "Terminal-Bench",
          "score": 43.68607339543499,
          "source": "Multivariate regression",
          "stdDev": 0.009917522735403356
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.000000504785476,
          "source": "Multivariate regression",
          "stdDev": 1.6839020814058674e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 55.390347000305496,
          "source": "Multivariate regression",
          "stdDev": 0.008408608209513493
        },
        {
          "name": "Tau-Bench Retail",
          "score": 80.07472187775441,
          "source": "Multivariate regression",
          "stdDev": 0.022894257911510358
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 17.204250146466748,
          "source": "Multivariate regression",
          "stdDev": 0.007552684250935558
        },
        {
          "name": "MMMU",
          "score": 80.5639062413876,
          "source": "Multivariate regression",
          "stdDev": 0.012029590679408474
        },
        {
          "name": "MMMU-Pro",
          "score": 68.49057311077553,
          "source": "Multivariate regression",
          "stdDev": 0.03578450570073983
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 67.88634692620383,
          "source": "Multivariate regression",
          "stdDev": 0.025381353205993
        },
        {
          "name": "VideoMMMU",
          "score": 64.77273420576574,
          "source": "Multivariate regression",
          "stdDev": 0.015295803022381232
        },
        {
          "name": "ERQA",
          "score": 29.441784585446868,
          "source": "Multivariate regression",
          "stdDev": 0.016485682521623992
        },
        {
          "name": "SWE-Lancer",
          "score": 36.05331571928167,
          "source": "Multivariate regression",
          "stdDev": 0.03684962819435709
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 56.6059199216938,
          "source": "Multivariate regression",
          "stdDev": 0.01542704925201107
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 57.645222363031294,
          "source": "Multivariate regression",
          "stdDev": 0.01581685745699105
        },
        {
          "name": "COLLIE",
          "score": 80.18987263222107,
          "source": "Multivariate regression",
          "stdDev": 0.030931066989808464
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 45.80011228558902,
          "source": "Multivariate regression",
          "stdDev": 0.010669475052828475
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 88.62331322336696,
          "source": "Multivariate regression",
          "stdDev": 0.020503985213395335
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 23.87889616097698,
          "source": "Multivariate regression",
          "stdDev": 0.02697950037863248
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 65.16314261024388,
          "source": "Multivariate regression",
          "stdDev": 0.03409868180812157
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 60.75675657848464,
          "source": "Multivariate regression",
          "stdDev": 0.044580918235297175
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 58.86082724058451,
          "source": "Multivariate regression",
          "stdDev": 0.030076237334087205
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 65.41696272904221,
          "source": "Multivariate regression",
          "stdDev": 0.07440180132724268
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 88.05611431136835,
          "source": "Multivariate regression",
          "stdDev": 0.004683223382691532
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 99.87916998206549,
          "source": "Multivariate regression",
          "stdDev": 0.03320054926621449
        },
        {
          "name": "VideoMME",
          "score": 72.61782818697128,
          "source": "Multivariate regression",
          "stdDev": 0.14255862951859305
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": -0.12845748741715113,
          "source": "Multivariate regression",
          "stdDev": 0.0017105123297569609
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.2217664763075433,
          "source": "Multivariate regression",
          "stdDev": 0.0029335802521856776
        },
        {
          "name": "FActScore hallucination rate",
          "score": 16.210517808296856,
          "source": "Multivariate regression",
          "stdDev": 0.011827480573742348
        },
        {
          "name": "MMMLU",
          "score": 87.60511405782336,
          "source": "Multivariate regression",
          "stdDev": 0.002679760365839818
        }
      ]
    },
    {
      "name": "gpt-oss-120b (without tools)",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.06216076669664,
          "source": "Multivariate regression",
          "stdDev": 0.00041913604676543486
        },
        {
          "name": "MMLU-Pro",
          "score": 85.1395444060277,
          "source": "Multivariate regression",
          "stdDev": 0.0021824701665647795
        },
        {
          "name": "GPQA Diamond",
          "score": 69.74258013388905,
          "source": "Multivariate regression",
          "stdDev": 0.01170188929594091
        },
        {
          "name": "SimpleQA",
          "score": 27.966328852642427,
          "source": "Multivariate regression",
          "stdDev": 0.0017423257286846164
        },
        {
          "name": "FRAMES",
          "score": 82.7702145744922,
          "source": "Multivariate regression",
          "stdDev": 0.00029364999332557283
        },
        {
          "name": "Humanity's Last Exam",
          "score": 16.815512289921912,
          "source": "Multivariate regression",
          "stdDev": 0.0070326942308660025
        },
        {
          "name": "LiveCodeBench",
          "score": 58.787965594077306,
          "source": "Multivariate regression",
          "stdDev": 0.018499313410092554
        },
        {
          "name": "Codeforces",
          "score": 2463,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 56.19306950266264,
          "source": "Multivariate regression",
          "stdDev": 0.021684680041985573
        },
        {
          "name": "Aider",
          "score": 66.44172264089423,
          "source": "Multivariate regression",
          "stdDev": 0.037717047973397505
        },
        {
          "name": "AIME 2024",
          "score": 88.17104362233717,
          "source": "Multivariate regression",
          "stdDev": 0.006931357351898677
        },
        {
          "name": "AIME 2025",
          "score": 66.7593652295194,
          "source": "Multivariate regression",
          "stdDev": 0.02105935259926579
        },
        {
          "name": "HMMT 2025",
          "score": 50.51003606039595,
          "source": "Multivariate regression",
          "stdDev": 0.038649081842163945
        },
        {
          "name": "CNMO 2024",
          "score": 84.05265594935608,
          "source": "Multivariate regression",
          "stdDev": 0.011722281974639641
        },
        {
          "name": "Terminal-Bench",
          "score": 30.812192493897015,
          "source": "Multivariate regression",
          "stdDev": 0.01010801436845375
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000015083972,
          "source": "Multivariate regression",
          "stdDev": 1.7309298788661446e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 52.65444849213603,
          "source": "Multivariate regression",
          "stdDev": 0.008577045818364064
        },
        {
          "name": "Tau-Bench Retail",
          "score": 73.07813980414791,
          "source": "Multivariate regression",
          "stdDev": 0.023632167076029647
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 22.708414837847116,
          "source": "Multivariate regression",
          "stdDev": 0.007801136882529047
        },
        {
          "name": "MMMU",
          "score": 71.04360313415577,
          "source": "Multivariate regression",
          "stdDev": 0.01206916427224841
        },
        {
          "name": "MMMU-Pro",
          "score": 60.85155873798499,
          "source": "Multivariate regression",
          "stdDev": 0.036313603799437634
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 79.66980176398442,
          "source": "Multivariate regression",
          "stdDev": 0.025975578312953326
        },
        {
          "name": "VideoMMMU",
          "score": 85.68147536766898,
          "source": "Multivariate regression",
          "stdDev": 0.015665429515221145
        },
        {
          "name": "ERQA",
          "score": 52.85792739959041,
          "source": "Multivariate regression",
          "stdDev": 0.017110188869931164
        },
        {
          "name": "SWE-Lancer",
          "score": 41.66974819632998,
          "source": "Multivariate regression",
          "stdDev": 0.037363646378781167
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 54.950048201400875,
          "source": "Multivariate regression",
          "stdDev": 0.015793604415105827
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 57.08244937855966,
          "source": "Multivariate regression",
          "stdDev": 0.01652456242714231
        },
        {
          "name": "COLLIE",
          "score": 45.62026901886293,
          "source": "Multivariate regression",
          "stdDev": 0.031902446009326915
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 56.18098904098372,
          "source": "Multivariate regression",
          "stdDev": 0.011107404785411924
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 64.08743678077977,
          "source": "Multivariate regression",
          "stdDev": 0.021009384679044556
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 57.11780776278982,
          "source": "Multivariate regression",
          "stdDev": 0.027608435596231364
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 63.79215647336298,
          "source": "Multivariate regression",
          "stdDev": 0.03509109077576202
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 77.41042017394861,
          "source": "Multivariate regression",
          "stdDev": 0.04559617314070614
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 49.16259573039781,
          "source": "Multivariate regression",
          "stdDev": 0.03045436316474359
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 65.32223377990664,
          "source": "Multivariate regression",
          "stdDev": 0.0760247898105512
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 92.28990591744862,
          "source": "Multivariate regression",
          "stdDev": 0.004858138666804361
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 60.70518098724898,
          "source": "Multivariate regression",
          "stdDev": 0.03354347410707611
        },
        {
          "name": "VideoMME",
          "score": 72.58632796603433,
          "source": "Multivariate regression",
          "stdDev": 0.14636118222643418
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.4992379889087886,
          "source": "Multivariate regression",
          "stdDev": 0.001774646400880553
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 5.533504231786729,
          "source": "Multivariate regression",
          "stdDev": 0.003013756833956069
        },
        {
          "name": "FActScore hallucination rate",
          "score": 12.606721396091245,
          "source": "Multivariate regression",
          "stdDev": 0.012223994432521439
        },
        {
          "name": "MMMLU",
          "score": 86.74855900675107,
          "source": "Multivariate regression",
          "stdDev": 0.002756510136341546
        }
      ]
    },
    {
      "name": "gpt-oss-20b (with tools)",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.28701770900022,
          "source": "Multivariate regression",
          "stdDev": 0.0003962935455011187
        },
        {
          "name": "MMLU-Pro",
          "score": 84.35938617800987,
          "source": "Multivariate regression",
          "stdDev": 0.0021687718605630023
        },
        {
          "name": "GPQA Diamond",
          "score": 84.00770757895177,
          "source": "Multivariate regression",
          "stdDev": 0.011537743099446766
        },
        {
          "name": "SimpleQA",
          "score": 27.736113211852647,
          "source": "Multivariate regression",
          "stdDev": 0.0017208117674130257
        },
        {
          "name": "FRAMES",
          "score": 82.67212081486744,
          "source": "Multivariate regression",
          "stdDev": 0.00029601909134721735
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.475228690965857,
          "source": "Multivariate regression",
          "stdDev": 0.00694742364113116
        },
        {
          "name": "LiveCodeBench",
          "score": 64.23625811016676,
          "source": "Multivariate regression",
          "stdDev": 0.018187372125954733
        },
        {
          "name": "Codeforces",
          "score": 2516,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 60,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 64.58275306076615,
          "source": "Multivariate regression",
          "stdDev": 0.03751422288632764
        },
        {
          "name": "AIME 2024",
          "score": 85.11140230586814,
          "source": "Multivariate regression",
          "stdDev": 0.0067923755864135885
        },
        {
          "name": "AIME 2025",
          "score": 77.83053742750627,
          "source": "Multivariate regression",
          "stdDev": 0.02114972882014868
        },
        {
          "name": "HMMT 2025",
          "score": 57.84750260307166,
          "source": "Multivariate regression",
          "stdDev": 0.03805226878984729
        },
        {
          "name": "CNMO 2024",
          "score": 82.33134739764284,
          "source": "Multivariate regression",
          "stdDev": 0.011517096991470124
        },
        {
          "name": "Terminal-Bench",
          "score": 28.828107919004424,
          "source": "Multivariate regression",
          "stdDev": 0.010037003686273015
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000030923122,
          "source": "Multivariate regression",
          "stdDev": 1.7165829261771123e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 51.790356243351674,
          "source": "Multivariate regression",
          "stdDev": 0.008521269896788284
        },
        {
          "name": "Tau-Bench Retail",
          "score": 75.01910980266538,
          "source": "Multivariate regression",
          "stdDev": 0.023551318932148037
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 13.164270441951956,
          "source": "Multivariate regression",
          "stdDev": 0.007739771465847604
        },
        {
          "name": "MMMU",
          "score": 62.20897221994565,
          "source": "Multivariate regression",
          "stdDev": 0.012108608530583674
        },
        {
          "name": "MMMU-Pro",
          "score": 74.35067180558991,
          "source": "Multivariate regression",
          "stdDev": 0.03693851902946342
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 73.08064609059835,
          "source": "Multivariate regression",
          "stdDev": 0.025306093995355074
        },
        {
          "name": "VideoMMMU",
          "score": 77.15070020929915,
          "source": "Multivariate regression",
          "stdDev": 0.015665429515221145
        },
        {
          "name": "ERQA",
          "score": 60.74478289269422,
          "source": "Multivariate regression",
          "stdDev": 0.016772431885920456
        },
        {
          "name": "SWE-Lancer",
          "score": 112.91040150802542,
          "source": "Multivariate regression",
          "stdDev": 0.03715889236314919
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 48.18131895555628,
          "source": "Multivariate regression",
          "stdDev": 0.015973728003170953
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 44.81305434170159,
          "source": "Multivariate regression",
          "stdDev": 0.016408731399559756
        },
        {
          "name": "COLLIE",
          "score": 63.28216212470829,
          "source": "Multivariate regression",
          "stdDev": 0.031902446009326915
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 57.80872778660245,
          "source": "Multivariate regression",
          "stdDev": 0.011021211023938304
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 75.98053688556422,
          "source": "Multivariate regression",
          "stdDev": 0.020827022112170093
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 32.82395301148944,
          "source": "Multivariate regression",
          "stdDev": 0.027330695692000872
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 26.566769618603757,
          "source": "Multivariate regression",
          "stdDev": 0.03465352902242094
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 32.01085446262266,
          "source": "Multivariate regression",
          "stdDev": 0.0450914031483802
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 67.91263431535259,
          "source": "Multivariate regression",
          "stdDev": 0.030391668899625537
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 49.73122534820601,
          "source": "Multivariate regression",
          "stdDev": 0.0760247898105512
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.32576456022298,
          "source": "Multivariate regression",
          "stdDev": 0.004771482608062634
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 60.31269326698762,
          "source": "Multivariate regression",
          "stdDev": 0.033315249753072325
        },
        {
          "name": "VideoMME",
          "score": 76.23054887486921,
          "source": "Multivariate regression",
          "stdDev": 0.1446834973751999
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.9357265896747933,
          "source": "Multivariate regression",
          "stdDev": 0.0017492749586600772
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 7.464392740598143,
          "source": "Multivariate regression",
          "stdDev": 0.0030236294248787
        },
        {
          "name": "FActScore hallucination rate",
          "score": 11.820874128059586,
          "source": "Multivariate regression",
          "stdDev": 0.012184923699798407
        },
        {
          "name": "MMMLU",
          "score": 87.65954724745369,
          "source": "Multivariate regression",
          "stdDev": 0.002734801426466446
        }
      ]
    },
    {
      "name": "gpt-oss-20b (without tools)",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.1524569690591,
          "source": "Multivariate regression",
          "stdDev": 0.0003867789984072602
        },
        {
          "name": "MMLU-Pro",
          "score": 84.88398148173502,
          "source": "Multivariate regression",
          "stdDev": 0.002148060617395799
        },
        {
          "name": "GPQA Diamond",
          "score": 78.0873917164735,
          "source": "Multivariate regression",
          "stdDev": 0.011496340353017791
        },
        {
          "name": "SimpleQA",
          "score": 27.699537403360374,
          "source": "Multivariate regression",
          "stdDev": 0.0016946345245226343
        },
        {
          "name": "FRAMES",
          "score": 82.84444986021023,
          "source": "Multivariate regression",
          "stdDev": 0.00029126162589360405
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.94556408189235,
          "source": "Multivariate regression",
          "stdDev": 0.006843696645435036
        },
        {
          "name": "LiveCodeBench",
          "score": 66.95507496748495,
          "source": "Multivariate regression",
          "stdDev": 0.017546860723622482
        },
        {
          "name": "Codeforces",
          "score": 2230,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 49.31716859050471,
          "source": "Multivariate regression",
          "stdDev": 0.021240335736404038
        },
        {
          "name": "Aider",
          "score": 51.04720175827816,
          "source": "Multivariate regression",
          "stdDev": 0.03761577213478834
        },
        {
          "name": "AIME 2024",
          "score": 89.87757005635126,
          "source": "Multivariate regression",
          "stdDev": 0.006739518556217696
        },
        {
          "name": "AIME 2025",
          "score": 85.84525333215976,
          "source": "Multivariate regression",
          "stdDev": 0.02101401873196534
        },
        {
          "name": "HMMT 2025",
          "score": 63.79543054016392,
          "source": "Multivariate regression",
          "stdDev": 0.03754767885500429
        },
        {
          "name": "CNMO 2024",
          "score": 81.67062941882294,
          "source": "Multivariate regression",
          "stdDev": 0.011517096991470124
        },
        {
          "name": "Terminal-Bench",
          "score": 23.11089685720006,
          "source": "Multivariate regression",
          "stdDev": 0.00998938279784351
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999935823011,
          "source": "Multivariate regression",
          "stdDev": 1.7023825566419775e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 52.896998295951946,
          "source": "Multivariate regression",
          "stdDev": 0.008408608209513493
        },
        {
          "name": "Tau-Bench Retail",
          "score": 67.75312605255905,
          "source": "Multivariate regression",
          "stdDev": 0.02314284202762551
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 18.57495855328601,
          "source": "Multivariate regression",
          "stdDev": 0.007677915604325338
        },
        {
          "name": "MMMU",
          "score": 73.1128172118803,
          "source": "Multivariate regression",
          "stdDev": 0.012029590679408474
        },
        {
          "name": "MMMU-Pro",
          "score": 67.29039901335523,
          "source": "Multivariate regression",
          "stdDev": 0.03610289506175413
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 71.30291452765002,
          "source": "Multivariate regression",
          "stdDev": 0.025154900094623633
        },
        {
          "name": "VideoMMMU",
          "score": 95.54280870516286,
          "source": "Multivariate regression",
          "stdDev": 0.015481719413486486
        },
        {
          "name": "ERQA",
          "score": 47.991018784653676,
          "source": "Multivariate regression",
          "stdDev": 0.016600976642035366
        },
        {
          "name": "SWE-Lancer",
          "score": 63.46717353890534,
          "source": "Multivariate regression",
          "stdDev": 0.03653774643390869
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 46.984850718173874,
          "source": "Multivariate regression",
          "stdDev": 0.015793604415105827
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 53.87812662298637,
          "source": "Multivariate regression",
          "stdDev": 0.016115511874552287
        },
        {
          "name": "COLLIE",
          "score": 85.80211022170442,
          "source": "Multivariate regression",
          "stdDev": 0.031662395239708555
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 45.772573678632966,
          "source": "Multivariate regression",
          "stdDev": 0.010868727263426815
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 75.52022458015301,
          "source": "Multivariate regression",
          "stdDev": 0.02064304860066875
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 72.95762407001354,
          "source": "Multivariate regression",
          "stdDev": 0.027469916664234807
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 60.435077993675804,
          "source": "Multivariate regression",
          "stdDev": 0.03454327256031948
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 50.85447862940498,
          "source": "Multivariate regression",
          "stdDev": 0.04559617314070614
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 53.630862718536434,
          "source": "Multivariate regression",
          "stdDev": 0.02982148995462569
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 50.87711992109905,
          "source": "Multivariate regression",
          "stdDev": 0.07521767314427169
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 87.83887061083443,
          "source": "Multivariate regression",
          "stdDev": 0.0046959334047385615
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 69.39279690516398,
          "source": "Multivariate regression",
          "stdDev": 0.03238627347904642
        },
        {
          "name": "VideoMME",
          "score": 69.96261158014232,
          "source": "Multivariate regression",
          "stdDev": 0.1390913381566928
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 0.806055730543676,
          "source": "Multivariate regression",
          "stdDev": 0.001736450228890443
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 7.35543686334811,
          "source": "Multivariate regression",
          "stdDev": 0.0030236294248787
        },
        {
          "name": "FActScore hallucination rate",
          "score": 20.393737796654705,
          "source": "Multivariate regression",
          "stdDev": 0.012027371629091864
        },
        {
          "name": "MMMLU",
          "score": 87.98102800473293,
          "source": "Multivariate regression",
          "stdDev": 0.0027019113434523967
        }
      ]
    },
    {
      "name": "o3-mini (without tools)",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 92.93189092043377,
          "source": "Multivariate regression",
          "stdDev": 0.0003962935455011187
        },
        {
          "name": "MMLU-Pro",
          "score": 83.87088658338537,
          "source": "Multivariate regression",
          "stdDev": 0.0020918283478586997
        },
        {
          "name": "GPQA Diamond",
          "score": 70.33995529184277,
          "source": "Multivariate regression",
          "stdDev": 0.011159589910976802
        },
        {
          "name": "SimpleQA",
          "score": 29.799836972424963,
          "source": "Multivariate regression",
          "stdDev": 0.0016319221534712334
        },
        {
          "name": "FRAMES",
          "score": 82.42828699792332,
          "source": "Multivariate regression",
          "stdDev": 0.00028397602562965787
        },
        {
          "name": "Humanity's Last Exam",
          "score": 10.386927725237356,
          "source": "Multivariate regression",
          "stdDev": 0.0067028975183816035
        },
        {
          "name": "LiveCodeBench",
          "score": 65.50674500036249,
          "source": "Multivariate regression",
          "stdDev": 0.01749242615023407
        },
        {
          "name": "Codeforces",
          "score": 2073,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "SWE-bench Verified",
          "score": 68.16899958420737,
          "source": "Multivariate regression",
          "stdDev": 0.020832324030214438
        },
        {
          "name": "Aider",
          "score": 58.298668557783344,
          "source": "Multivariate regression",
          "stdDev": 0.03627346391496225
        },
        {
          "name": "AIME 2024",
          "score": 82.40198375705954,
          "source": "Multivariate regression",
          "stdDev": 0.006578399741402813
        },
        {
          "name": "AIME 2025",
          "score": 71.35872883067634,
          "source": "Multivariate regression",
          "stdDev": 0.020462179739061042
        },
        {
          "name": "HMMT 2025",
          "score": 50.0283211318588,
          "source": "Multivariate regression",
          "stdDev": 0.036308063195708146
        },
        {
          "name": "CNMO 2024",
          "score": 75.046448267968,
          "source": "Multivariate regression",
          "stdDev": 0.0111809717189375
        },
        {
          "name": "Terminal-Bench",
          "score": 33.55665629139014,
          "source": "Multivariate regression",
          "stdDev": 0.009747789344247268
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 36.99999948285219,
          "source": "Multivariate regression",
          "stdDev": 1.658026011401983e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 49.33596574691509,
          "source": "Multivariate regression",
          "stdDev": 0.00817863037161313
        },
        {
          "name": "Tau-Bench Retail",
          "score": 66.22932455517574,
          "source": "Multivariate regression",
          "stdDev": 0.022217773677705752
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 19.588578990093396,
          "source": "Multivariate regression",
          "stdDev": 0.007457380768052591
        },
        {
          "name": "MMMU",
          "score": 68.96972867088769,
          "source": "Multivariate regression",
          "stdDev": 0.011667389728060642
        },
        {
          "name": "MMMU-Pro",
          "score": 52.494067045318104,
          "source": "Multivariate regression",
          "stdDev": 0.0356777445155244
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 73.45310494930413,
          "source": "Multivariate regression",
          "stdDev": 0.024540811328183428
        },
        {
          "name": "VideoMMMU",
          "score": 43.434625965611986,
          "source": "Multivariate regression",
          "stdDev": 0.015201992209913414
        },
        {
          "name": "ERQA",
          "score": 43.70461319885467,
          "source": "Multivariate regression",
          "stdDev": 0.016075642686191157
        },
        {
          "name": "SWE-Lancer",
          "score": 70.49220016309005,
          "source": "Multivariate regression",
          "stdDev": 0.036223179469434444
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 59.506035246375404,
          "source": "Multivariate regression",
          "stdDev": 0.01517776182751348
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 49.68902040941646,
          "source": "Multivariate regression",
          "stdDev": 0.01599671921717734
        },
        {
          "name": "COLLIE",
          "score": 89.53596666054455,
          "source": "Multivariate regression",
          "stdDev": 0.030433753087698842
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 52.06714798592492,
          "source": "Multivariate regression",
          "stdDev": 0.01057971404481788
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 62.09693561120278,
          "source": "Multivariate regression",
          "stdDev": 0.019890145233370522
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 45.10794941291363,
          "source": "Multivariate regression",
          "stdDev": 0.026695217766823518
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 65.42502548380014,
          "source": "Multivariate regression",
          "stdDev": 0.03409868180812157
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 63.628848972850705,
          "source": "Multivariate regression",
          "stdDev": 0.043366424192741
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 63.06429972760202,
          "source": "Multivariate regression",
          "stdDev": 0.029370365715368035
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 55.954715925661446,
          "source": "Multivariate regression",
          "stdDev": 0.07274261072946508
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 84.24150846512062,
          "source": "Multivariate regression",
          "stdDev": 0.004554172631409673
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 70.70983934787142,
          "source": "Multivariate regression",
          "stdDev": 0.0321498354707623
        },
        {
          "name": "VideoMME",
          "score": 88.09475200186239,
          "source": "Multivariate regression",
          "stdDev": 0.1412683684082161
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 1.6906212890112968,
          "source": "Multivariate regression",
          "stdDev": 0.001688593090203009
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 2.212720517260628,
          "source": "Multivariate regression",
          "stdDev": 0.002882337570815887
        },
        {
          "name": "FActScore hallucination rate",
          "score": 24.88300544092192,
          "source": "Multivariate regression",
          "stdDev": 0.01170590764413567
        },
        {
          "name": "MMMLU",
          "score": 85.02496494085122,
          "source": "Multivariate regression",
          "stdDev": 0.002617878926165476
        }
      ]
    },
    {
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "benchmarks": [
        {
          "name": "MMLU-Redux",
          "score": 93.33005269820052,
          "source": "Multivariate regression",
          "stdDev": 0.00041015173424140605
        },
        {
          "name": "MMLU-Pro",
          "score": 84.55022950621108,
          "source": "Multivariate regression",
          "stdDev": 0.0021960830295598317
        },
        {
          "name": "GPQA Diamond",
          "score": 68.47586334652392,
          "source": "Multivariate regression",
          "stdDev": 0.011903889476825956
        },
        {
          "name": "SimpleQA",
          "score": 30.22303218495057,
          "source": "Multivariate regression",
          "stdDev": 0.0017294494676789018
        },
        {
          "name": "FRAMES",
          "score": 82.95284108021792,
          "source": "Multivariate regression",
          "stdDev": 0.00029758801221932256
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.580844536900265,
          "source": "Multivariate regression",
          "stdDev": 0.006964561280400202
        },
        {
          "name": "LiveCodeBench",
          "score": 56.48628356466866,
          "source": "Multivariate regression",
          "stdDev": 0.018550793656273653
        },
        {
          "name": "Codeforces",
          "score": 2363.7047717455916,
          "source": "Multivariate regression",
          "stdDev": 0.45371983421741424
        },
        {
          "name": "SWE-bench Verified",
          "score": 51.6,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "Aider",
          "score": 33.3,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "AIME 2024",
          "score": 81.31436226437165,
          "source": "Multivariate regression",
          "stdDev": 0.0069141374126219304
        },
        {
          "name": "AIME 2025",
          "score": 72.20486955426009,
          "source": "Multivariate regression",
          "stdDev": 0.02114972882014868
        },
        {
          "name": "HMMT 2025",
          "score": 54.57687166529715,
          "source": "Multivariate regression",
          "stdDev": 0.038649081842163945
        },
        {
          "name": "CNMO 2024",
          "score": 86.4444613104344,
          "source": "Multivariate regression",
          "stdDev": 0.011640641995188623
        },
        {
          "name": "Terminal-Bench",
          "score": 31.3,
          "source": "Original",
          "stdDev": 0
        },
        {
          "name": "BFCL_v3_MultiTurn",
          "score": 37.00000020127789,
          "source": "Multivariate regression",
          "stdDev": 1.7306667835625313e-7
        },
        {
          "name": "Tau-Bench Airline",
          "score": 54.78387072768327,
          "source": "Multivariate regression",
          "stdDev": 0.008436914671803956
        },
        {
          "name": "Tau-Bench Retail",
          "score": 67.65435073071374,
          "source": "Multivariate regression",
          "stdDev": 0.023307091874510633
        },
        {
          "name": "FrontierMath (python tool)",
          "score": 12.68899083419501,
          "source": "Multivariate regression",
          "stdDev": 0.007831639280390674
        },
        {
          "name": "MMMU",
          "score": 83.58895167348352,
          "source": "Multivariate regression",
          "stdDev": 0.012187114062801587
        },
        {
          "name": "MMMU-Pro",
          "score": 85.63094097403433,
          "source": "Multivariate regression",
          "stdDev": 0.0358909493156357
        },
        {
          "name": "CharXiv reasoning (python tool)",
          "score": 53.05270712652447,
          "source": "Multivariate regression",
          "stdDev": 0.025902045699649788
        },
        {
          "name": "VideoMMMU",
          "score": 66.0122166347162,
          "source": "Multivariate regression",
          "stdDev": 0.015604433128555147
        },
        {
          "name": "ERQA",
          "score": 58.47981248528856,
          "source": "Multivariate regression",
          "stdDev": 0.01688576822751829
        },
        {
          "name": "SWE-Lancer",
          "score": 71.31231219545441,
          "source": "Multivariate regression",
          "stdDev": 0.03726141001340874
        },
        {
          "name": "Scale multichallenge (o3-mini grader)",
          "score": 42.989201254058926,
          "source": "Multivariate regression",
          "stdDev": 0.01615184299755682
        },
        {
          "name": "Internal API instruction following eval (hard)",
          "score": 52.963592282398565,
          "source": "Multivariate regression",
          "stdDev": 0.016639587154558502
        },
        {
          "name": "COLLIE",
          "score": 104.54364930511258,
          "source": "Multivariate regression",
          "stdDev": 0.031541684764518664
        },
        {
          "name": "Tau2-Bench Airline",
          "score": 53.109439378973036,
          "source": "Multivariate regression",
          "stdDev": 0.011021211023938304
        },
        {
          "name": "Tau2-Bench Retail",
          "score": 97.78489326237076,
          "source": "Multivariate regression",
          "stdDev": 0.020872762124204705
        },
        {
          "name": "Tau2-Bench Telecom",
          "score": 23.767592055571868,
          "source": "Multivariate regression",
          "stdDev": 0.027050104213223562
        },
        {
          "name": "OpenAI-MRCR: 2 needle 128k",
          "score": 55.647366972900954,
          "source": "Multivariate regression",
          "stdDev": 0.034982213441998214
        },
        {
          "name": "OpenAI-MRCR: 2 needle 256k",
          "score": 61.7619640522679,
          "source": "Multivariate regression",
          "stdDev": 0.04492188607824978
        },
        {
          "name": "Graphwalks bfs <128k",
          "score": 70.75451739430588,
          "source": "Multivariate regression",
          "stdDev": 0.030765918190397243
        },
        {
          "name": "Graphwalks parents <128k",
          "score": 65.16836545024586,
          "source": "Multivariate regression",
          "stdDev": 0.07662454828652167
        },
        {
          "name": "BrowseComp Long Context 128k",
          "score": 86.34567351501116,
          "source": "Multivariate regression",
          "stdDev": 0.004783958148708554
        },
        {
          "name": "BrowseComp Long Context 256k",
          "score": 94.92053121327339,
          "source": "Multivariate regression",
          "stdDev": 0.034107354453670774
        },
        {
          "name": "VideoMME",
          "score": 68.04919485969515,
          "source": "Multivariate regression",
          "stdDev": 0.14636118222643418
        },
        {
          "name": "LongFact-Concepts hallucination rate",
          "score": 2.7254884257782948,
          "source": "Multivariate regression",
          "stdDev": 0.0017662297488635517
        },
        {
          "name": "LongFact-Objects hallucination rate",
          "score": 3.2621508717133096,
          "source": "Multivariate regression",
          "stdDev": 0.0030236294248787
        },
        {
          "name": "FActScore hallucination rate",
          "score": 22.503458646230115,
          "source": "Multivariate regression",
          "stdDev": 0.012184923699798407
        },
        {
          "name": "MMMLU",
          "score": 88.73140120942853,
          "source": "Multivariate regression",
          "stdDev": 0.0027402447271348963
        }
      ]
    }
  ]
}