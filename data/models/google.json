{
  "models": [
    {
      "name": "Gemini 3 Flash",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-3-flash/",
      "release_date": "2025-12-17",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.5,
          "source": "https://blog.google/products/gemini/gemini-3-flash/"
        },
        {
          "name": "Output cost",
          "score": 3,
          "source": "https://blog.google/products/gemini/gemini-3-flash/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 160,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 71.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 59.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 97,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 89,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 89.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 34.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 90.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 50.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 97,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 78,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 66.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 36.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 80.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 33.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 43.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ARC-AGI-2",
          "score": 33.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 90.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024",
          "score": 95.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024 (with tools)",
          "score": 99.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 81.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot-Pro",
          "score": 69.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "CharXiv Reasoning",
          "score": 80.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.121,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Video-MMMU",
          "score": 86.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 47.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 78,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 90.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Toolathlon",
          "score": 49.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MCP Atlas",
          "score": 57.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 61.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 68.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMLU",
          "score": 91.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 92.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 67.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 1M",
          "score": 22.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "LMArena Text",
          "score": 1476,
          "source": "https://lmarena.ai/"
        }
      ]
    },
    {
      "name": "Gemini 3 Flash Low",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-3-flash/",
      "release_date": "2025-12-17",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.5,
          "source": "https://blog.google/products/gemini/gemini-3-flash/"
        },
        {
          "name": "Output cost",
          "score": 3,
          "source": "https://blog.google/products/gemini/gemini-3-flash/"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 7.4,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 54.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 53.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 55.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 88.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 81.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 79.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 49.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 55.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 55.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 48,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 29.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 43.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemini 3 Pro",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-3/",
      "release_date": "2025-11-18",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 12,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 92,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 37.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ARC AGI 2",
          "score": 31.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 91.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 95,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 100,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MathArena Apex",
          "score": 23.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 81,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot Pro",
          "score": 72.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 81.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.115,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 87.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench Pro",
          "score": 2439,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 54.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 85.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VendingBench 2",
          "score": 5478.16,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 70.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 72.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMLU",
          "score": 91.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 93.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 77,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 1M",
          "score": 26.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 87.1,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "BFCL v4 MultiTurn",
          "score": 63,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "Reka Research Eval (with tools)",
          "score": 55.9,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "FRAMES",
          "score": 90.9,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "X Browse",
          "score": 26.5,
          "source": "https://x.ai/news/grok-4-1-fast"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.2,
          "source": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 54.2,
          "source": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 85.3,
          "source": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 98,
          "source": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"
        },
        {
          "name": "ARC AGI 2",
          "score": 31.1,
          "source": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 91.9,
          "source": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"
        },
        {
          "name": "MMMLU",
          "score": 91.8,
          "source": "https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"
        },
        {
          "name": "MMLU-Pro",
          "score": 90.1,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "GPQA Diamond",
          "score": 91.9,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 37.7,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "LiveCodeBench (thinking)",
          "score": 90.7,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Codeforces",
          "score": 2708,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "AIME 2025",
          "score": 95,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 97.5,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "HMMT Nov 2025",
          "score": 93.3,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 83.3,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 54.2,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.2,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 45.8,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "τ²-Bench",
          "score": 85.4,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "MCP-Universe",
          "score": 50.7,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "MCP-Mark",
          "score": 43.1,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Tool-Decathlon",
          "score": 36.4,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 58.9,
          "source": "https://www.tbench.ai/leaderboard/terminal-bench/2.0"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.2,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 54.2,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"
        },
        {
          "name": "LMArena Text",
          "score": 1490,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 72.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 62.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 95.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 89.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 90.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 37.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 91.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 56.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 95.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 70.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 70.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 39,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 87.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 37.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 45.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ARC-AGI-2",
          "score": 31.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 91.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024",
          "score": 95,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024 (with tools)",
          "score": 100,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 81,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot-Pro",
          "score": 72.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "CharXiv Reasoning",
          "score": 81.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.115,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Video-MMMU",
          "score": 87.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 54.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 90.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Toolathlon",
          "score": 36.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MCP Atlas",
          "score": 54.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 70.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 72.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMLU",
          "score": 91.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 93.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 77,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 1M",
          "score": 26.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMLU-Pro",
          "score": 90.1,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "GPQA Diamond",
          "score": 91.9,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 37.5,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 45.8,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "AIME 2025",
          "score": 95.0,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 97.5,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "HMMT Nov 2025",
          "score": 93.3,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 83.3,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "LiveCodeBench",
          "score": 90.7,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "SWE-bench Verified",
          "score": 76.2,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 39.0,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 54.2,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "τ²-Bench",
          "score": 90.7,
          "source": "https://z.ai/blog/glm-4.7"
        }
      ]
    },
    {
      "name": "Gemini 3 Pro Low",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-3/",
      "release_date": "2025-11-18",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 2,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 12,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 24,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 64.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 55.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 86.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 89.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 88.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 27.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 85.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 49.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 86.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 49.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 67.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 31.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 68.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-2-5-model-family-expands/",
      "release_date": "2025-06-17",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 100,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 60,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 69,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 82.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 59.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 54.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 87.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 82,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Vibe-Eval",
          "score": 67.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Video-MME",
          "score": 86.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 89.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 67.2,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "MMMU",
          "score": 82,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://www.anthropic.com/news/claude-opus-4-1"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.6,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "LiveCodeBench",
          "score": 74.2,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "USAMO 2025",
          "score": 34.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 82.5,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "ARC AGI 2",
          "score": 4.9,
          "source": "https://x.ai/news/grok-4"
        },
        {
          "name": "SWE-bench Verified",
          "score": 67.2,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "MMMU",
          "score": 82,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "Finance Agent",
          "score": 29.4,
          "source": "https://www.anthropic.com/news/claude-sonnet-4-5"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 57.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 9.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 32.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 60.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 56,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 28.4,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 59.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 42.6,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 39.3,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU-Pro",
          "score": 86,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 84,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 80,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 43,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 49,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 66,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 54,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 25,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA",
          "score": 86.4,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ARC AGI 2",
          "score": 4.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MathArena Apex",
          "score": 0.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 68,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot Pro",
          "score": 11.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "CharXiv reasoning (with tools)",
          "score": 69.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.145,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VideoMMMU",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench Pro",
          "score": 1775,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 32.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 59.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 54.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "VendingBench 2",
          "score": 573.64,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 63.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 54.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MMLU",
          "score": 89.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 91.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 58,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 1M",
          "score": 16.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 32.6,
          "source": "https://www.tbench.ai/leaderboard/terminal-bench/2.0"
        },
        {
          "name": "LMArena Text",
          "score": 1451,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 21.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 4.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ARC-AGI-2",
          "score": 88,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 86.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024",
          "score": 83.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024 (with tools)",
          "score": 88,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 68,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot-Pro",
          "score": 11.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "CharXiv Reasoning",
          "score": 69.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.145,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Video-MMMU",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 32.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 59.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 77.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Toolathlon",
          "score": 10.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MCP Atlas",
          "score": 8.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 63.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 54.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMLU",
          "score": 89.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 91.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 58,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 1M",
          "score": 16.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro 0506",
      "company": "Google",
      "url": "https://blog.google/products/gemini/gemini-2-5-pro-updates/",
      "release_date": "2025-05-06",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 53,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 75.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 72.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 50.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 87.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 79.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Vibe-Eval",
          "score": 65.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Video-MME",
          "score": 84.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR: 2-needle 128K",
          "score": 93,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 88.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2024",
          "score": 90.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Vibe-Eval",
          "score": 67.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "VideoMMMU",
          "score": 83.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "MRCR v2: 2-needle 128K",
          "score": 58,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 71.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 76.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.2,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "Terminal-Bench",
          "score": 25.3,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "GPQA Diamond",
          "score": 83,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "MMMU",
          "score": 79.6,
          "source": "https://www.anthropic.com/news/claude-4"
        },
        {
          "name": "AIME 2025",
          "score": 83,
          "source": "https://www.anthropic.com/news/claude-4"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Flash Thinking 0520",
      "company": "Google",
      "url": "https://blog.google/technology/google-deepmind/google-gemini-updates-io-2025/#flash-improvements",
      "release_date": "2025-03-25",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.3,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 2.5,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 93,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 51,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "AIME 2024",
          "score": 82.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 72,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 64.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 62.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA",
          "score": 82.8,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "SWE-bench Verified",
          "score": 60.4,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "MMMU",
          "score": 79.7,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "MMLU-Pro",
          "score": 81.9,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "MMLU-Redux",
          "score": 92.1,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "GPQA",
          "score": 82.8,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "SuperGPQA",
          "score": 57.8,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "AIME 2025",
          "score": 72,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 64.2,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "LiveBench",
          "score": 74.3,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "LiveCodeBench",
          "score": 61.2,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "CFEval",
          "score": 1995,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "OJ-Bench",
          "score": 23.5,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "IFEval",
          "score": 89.8,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "Arena-Hard v2",
          "score": 56.7,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "WritingBench",
          "score": 83.9,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "BFCL v3",
          "score": 68.6,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "τ-Bench Retail",
          "score": 65.2,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "τ-Bench Airline",
          "score": 54,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "τ²-Bench Retail",
          "score": 66.7,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "τ²-Bench Airline",
          "score": 52,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 31.6,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "MultiIF",
          "score": 74.4,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "MMLU-ProX",
          "score": 80.2,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "INCLUDE",
          "score": 83.9,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "PolyMATH",
          "score": 49.8,
          "source": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 11,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 21.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ARC-AGI-2",
          "score": 2.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024",
          "score": 72,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "AIME 2024 (with tools)",
          "score": 75.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMU-Pro",
          "score": 66.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "ScreenSpot-Pro",
          "score": 3.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "CharXiv Reasoning",
          "score": 63.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "OmniDocBench 1.5",
          "score": 0.154,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Video-MMMU",
          "score": 79.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 16.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 60.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "τ²-Bench",
          "score": 79.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Toolathlon",
          "score": 3.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MCP Atlas",
          "score": 3.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 50.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "SimpleQA Verified",
          "score": 28.1,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MMMLU",
          "score": 86.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "Global PIQA",
          "score": 90.2,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 128K",
          "score": 54.3,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        },
        {
          "name": "MRCR v2: 8-needle 1M",
          "score": 21,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Flash-Model-Card.pdf"
        }
      ]
    },
    {
      "name": "Gemini 2.5 Pro 0325",
      "company": "Google",
      "url": "https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/",
      "release_date": "2025-03-25",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 1.25,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 10,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 54,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 18.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 84,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 86.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 70.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 68.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 63.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 52.9,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MMMU",
          "score": 81.7,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Vibe-Eval",
          "score": 69.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "MRCR: 2-needle 128K",
          "score": 94.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 89.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        }
      ]
    },
    {
      "name": "Gemma 3 27B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-12",
      "capabilities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.119,
          "source": "https://openrouter.ai/google/gemma-3-27b-it"
        },
        {
          "name": "Output cost",
          "score": 0.2,
          "source": "https://openrouter.ai/google/gemma-3-27b-it"
        },
        {
          "name": "Size",
          "score": 27.43240664,
          "source": "https://huggingface.co/google/gemma-3-27b-it"
        },
        {
          "name": "Active parameters",
          "score": 27.43240664,
          "source": "https://huggingface.co/google/gemma-3-27b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 67.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 29.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 54.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 42.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 10,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 74.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 75.1,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 89,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 60.3,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MMMU",
          "score": 64.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 22.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 12.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 20.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 66.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 42.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 13.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 21.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 88.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 25.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 20.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 31.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 5.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 3.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 10.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU",
          "score": 76.9,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "MMLU-Pro",
          "score": 67.5,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "MATH",
          "score": 89,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "GPQA Main",
          "score": 36.83,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "GPQA Diamond",
          "score": 42.4,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "MBPP",
          "score": 74.4,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "HumanEval",
          "score": 87.8,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "SimpleQA",
          "score": 10,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "MMMU",
          "score": 64.9,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "MMMU-Pro",
          "score": 48.38,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "MathVista",
          "score": 67.6,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "ChartQA",
          "score": 76,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "DocVQA",
          "score": 86.6,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "AI2D",
          "score": 84.5,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "MM MT-Bench",
          "score": 7,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "LongBench v2",
          "score": 34.59,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "RULER 32K",
          "score": 91.1,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        },
        {
          "name": "RULER 128K",
          "score": 66,
          "source": "https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503"
        }
      ]
    },
    {
      "name": "Gemma 3 12B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-12",
      "capabilities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.05,
          "source": "https://openrouter.ai/google/gemma-3-12b-it"
        },
        {
          "name": "Output cost",
          "score": 0.1,
          "source": "https://openrouter.ai/google/gemma-3-12b-it"
        },
        {
          "name": "Size",
          "score": 12.18732504,
          "source": "https://huggingface.co/google/gemma-3-12b-it"
        },
        {
          "name": "Active parameters",
          "score": 12.18732504,
          "source": "https://huggingface.co/google/gemma-3-12b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 60.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 24.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 47.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 40.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 6.3,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 75.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 69.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 83.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 54.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MMMU",
          "score": 59.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 20.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 10.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 18.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 59.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 34.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 13.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 17.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 85.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 22,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 18.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 36.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 6.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 10.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Arena-Hard",
          "score": 43.6,
          "source": "https://huggingface.co/mistralai/Ministral-3-14B-Reasoning-2512"
        },
        {
          "name": "WildBench",
          "score": 63.2,
          "source": "https://huggingface.co/mistralai/Ministral-3-14B-Reasoning-2512"
        },
        {
          "name": "MATH",
          "score": 85.4,
          "source": "https://huggingface.co/mistralai/Ministral-3-14B-Reasoning-2512"
        }
      ]
    },
    {
      "name": "Gemma 3 4B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-12",
      "capabilities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.04,
          "source": "https://openrouter.ai/google/gemma-3-4b-it"
        },
        {
          "name": "Output cost",
          "score": 0.08,
          "source": "https://openrouter.ai/google/gemma-3-4b-it"
        },
        {
          "name": "Size",
          "score": 4.300079472,
          "source": "https://huggingface.co/google/gemma-3-4b-it"
        },
        {
          "name": "Active parameters",
          "score": 4.300079472,
          "source": "https://huggingface.co/google/gemma-3-4b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 43.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 12.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 36.3,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 30.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 70.1,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 54.5,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 75.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 43,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MMMU",
          "score": 48.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 14.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 6.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 12.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 41.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 29.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 11.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 7.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 76.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 6.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 12.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 28.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 5.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Arena-Hard",
          "score": 31.8,
          "source": "https://huggingface.co/mistralai/Ministral-3-14B-Reasoning-2512"
        },
        {
          "name": "WildBench",
          "score": 49.1,
          "source": "https://huggingface.co/mistralai/Ministral-3-14B-Reasoning-2512"
        },
        {
          "name": "MATH",
          "score": 75.9,
          "source": "https://huggingface.co/mistralai/Ministral-3-14B-Reasoning-2512"
        },
        {
          "name": "MM MT-Bench",
          "score": 5.23,
          "source": "https://huggingface.co/mistralai/Ministral-3-14B-Reasoning-2512"
        }
      ]
    },
    {
      "name": "Gemma 3 1B Instruct",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-03-13",
      "capabilities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 1,
          "source": "https://huggingface.co/google/gemma-3-1b-it"
        },
        {
          "name": "Active parameters",
          "score": 1,
          "source": "https://huggingface.co/google/gemma-3-1b-it"
        },
        {
          "name": "MMLU-Pro",
          "score": 14.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 1.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "BIRD-SQL",
          "score": 6.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 19.2,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 2.2,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 36.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "Global MMLU Lite",
          "score": 34.2,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "MATH",
          "score": 48,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "HiddenMath",
          "score": 15.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemma/Gemma3Report.pdf"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 6.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 0.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 3.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 13.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 23.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 1.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 0.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 48.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 3.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 19.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemma 3 270M",
      "company": "Google",
      "url": "https://deepmind.google/models/gemma/gemma-3/",
      "release_date": "2025-08-14",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Output cost",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Size",
          "score": 0.27,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "Active parameters",
          "score": 0.27,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "HellaSwag",
          "score": 37.7,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "PIQA",
          "score": 66.2,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "ARC-Challenge",
          "score": 28.2,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "WinoGrande",
          "score": 52.3,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "BIG-Bench Hard",
          "score": 26.7,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "IFEval",
          "score": 51.2,
          "source": "https://huggingface.co/google/gemma-3-270m-it"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 5.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 0.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 2.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 5.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 22.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 4.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 0.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 2.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 12.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 0,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 9.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "Gemini 2.0 Flash",
      "company": "Google",
      "url": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
      "release_date": "2024-12-11",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "thinking",
          "tool",
          "image",
          "audio"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.35,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 1.5,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 7.4,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 34,
          "source": "https://artificialanalysis.ai/?intelligence=artificial-analysis-intelligence-index#artificial-analysis-intelligence-index"
        },
        {
          "name": "MMLU-Pro",
          "score": 76.4,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "Natural2Code",
          "score": 92.9,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "BIRD-SQL",
          "score": 56.9,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "LiveCodeBench",
          "score": 35.1,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "FACTS Grounding",
          "score": 83.6,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "MATH",
          "score": 89.7,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "HiddenMath",
          "score": 63,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "GPQA Diamond",
          "score": 62.1,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "MRCR: 2 needle 1M",
          "score": 69.2,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "MMMU",
          "score": 70.7,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "Vibe-Eval",
          "score": 56.3,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "CoVoST2",
          "score": 39.2,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "EgoSchema",
          "score": 71.5,
          "source": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/#project-astra"
        },
        {
          "name": "GPQA",
          "score": 64.7,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 36,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU-Pro",
          "score": 79.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LOFT (128k)",
          "score": 75.6,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 44.3,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMMU",
          "score": 72.7,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "EgoSchema",
          "score": 71.9,
          "source": "https://x.ai/news/grok-3"
        }
      ]
    },
    {
      "name": "Gemini 1.5 Flash 8B",
      "company": "Google",
      "url": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/",
      "release_date": "2024-10-03",
      "capabilities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.0375,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Output cost",
          "score": 0.15,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Size",
          "score": 8,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Active parameters",
          "score": 8,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MMLU-Pro",
          "score": 58.7,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Natural2Code",
          "score": 75.5,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MATH",
          "score": 58.7,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "HiddenMath",
          "score": 32.8,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "GPQA",
          "score": 38.4,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "WMT23",
          "score": 72.6,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MRCR 1M",
          "score": 54.7,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MMMU",
          "score": 53.7,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Vibe-Eval",
          "score": 40.9,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MathVista",
          "score": 54.7,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "FLEURS (55 lang)",
          "score": 13.6,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Video-MME",
          "score": 66.2,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "XSTest",
          "score": 92.6,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MMMU (thinking)",
          "score": 50.7,
          "source": "https://huggingface.co/mistralai/Pixtral-12B-2409"
        },
        {
          "name": "Mathvista (thinking)",
          "score": 56.9,
          "source": "https://huggingface.co/mistralai/Pixtral-12B-2409"
        },
        {
          "name": "ChartQA (thinking)",
          "score": 78,
          "source": "https://huggingface.co/mistralai/Pixtral-12B-2409"
        },
        {
          "name": "DocVQA",
          "score": 79.5,
          "source": "https://huggingface.co/mistralai/Pixtral-12B-2409"
        },
        {
          "name": "VQAv2",
          "score": 65.5,
          "source": "https://huggingface.co/mistralai/Pixtral-12B-2409"
        }
      ]
    },
    {
      "name": "Gemma 2 27B",
      "company": "Google",
      "url": "https://blog.google/technology/developers/google-gemma-2/",
      "release_date": "2024-06-27",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.65,
          "source": "https://openrouter.ai/google/gemma-2-27b-it"
        },
        {
          "name": "Output cost",
          "score": 0.65,
          "source": "https://openrouter.ai/google/gemma-2-27b-it"
        },
        {
          "name": "Size",
          "score": 27.22712832,
          "source": "https://huggingface.co/google/gemma-2-27b"
        },
        {
          "name": "Active parameters",
          "score": 27.22712832,
          "source": "https://huggingface.co/google/gemma-2-27b"
        },
        {
          "name": "MMLU",
          "score": 75.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Challenge",
          "score": 71.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "GSM8K",
          "score": 74,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "AGIEval",
          "score": 55.1,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "DROP",
          "score": 74.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BBH",
          "score": 74.9,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "WinoGrande",
          "score": 83.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HellaSwag",
          "score": 86.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MATH",
          "score": 42.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Easy",
          "score": 88.6,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "PIQA",
          "score": 83.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "SIQA",
          "score": 53.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BoolQ",
          "score": 84.8,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "TriviaQA",
          "score": 83.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "NaturalQuestions",
          "score": 34.5,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HumanEval",
          "score": 51.8,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MBPP",
          "score": 62.6,
          "source": "https://arxiv.org/abs/2408.00118"
        }
      ]
    },
    {
      "name": "Gemma 2 9B",
      "company": "Google",
      "url": "https://blog.google/technology/developers/google-gemma-2/",
      "release_date": "2024-06-27",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.03,
          "source": "https://openrouter.ai/google/gemma-2-9b-it"
        },
        {
          "name": "Output cost",
          "score": 0.09,
          "source": "https://openrouter.ai/google/gemma-2-9b-it"
        },
        {
          "name": "Size",
          "score": 9.241705984,
          "source": "https://huggingface.co/google/gemma-2-9b"
        },
        {
          "name": "Active parameters",
          "score": 9.241705984,
          "source": "https://huggingface.co/google/gemma-2-9b"
        },
        {
          "name": "MMLU",
          "score": 71.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Challenge",
          "score": 68.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "GSM8K",
          "score": 68.6,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "AGIEval",
          "score": 52.8,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "DROP",
          "score": 69.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BBH",
          "score": 68.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "WinoGrande",
          "score": 80.6,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HellaSwag",
          "score": 81.9,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MATH",
          "score": 36.6,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Easy",
          "score": 88,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "PIQA",
          "score": 81.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "SIQA",
          "score": 53.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BoolQ",
          "score": 84.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "TriviaQA",
          "score": 76.6,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "NaturalQuestions",
          "score": 29.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HumanEval",
          "score": 40.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MBPP",
          "score": 52.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MT-Bench",
          "score": 7.6,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "Arena-Hard",
          "score": 68.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "WildBench",
          "score": 43.8,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MBPP",
          "score": 68.5,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "HumanEval",
          "score": 67.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MATH",
          "score": 47.4,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MMLU",
          "score": 68.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "AGIEval",
          "score": 68.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "WinoGrande",
          "score": 74.2,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "ARC-Challenge",
          "score": 68.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "TriviaQA",
          "score": 67.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "HellaSwag",
          "score": 80.1,
          "source": "https://mistral.ai/news/mistral-nemo"
        },
        {
          "name": "WinoGrande",
          "score": 74,
          "source": "https://mistral.ai/news/mistral-nemo"
        },
        {
          "name": "NaturalQuestions",
          "score": 29.8,
          "source": "https://mistral.ai/news/mistral-nemo"
        },
        {
          "name": "TriviaQA",
          "score": 71.3,
          "source": "https://mistral.ai/news/mistral-nemo"
        },
        {
          "name": "MMLU",
          "score": 71.5,
          "source": "https://mistral.ai/news/mistral-nemo"
        },
        {
          "name": "OpenBookQA",
          "score": 50.8,
          "source": "https://mistral.ai/news/mistral-nemo"
        },
        {
          "name": "CommonSenseQA",
          "score": 60.8,
          "source": "https://mistral.ai/news/mistral-nemo"
        },
        {
          "name": "TruthfulQA",
          "score": 46.6,
          "source": "https://mistral.ai/news/mistral-nemo"
        }
      ]
    },
    {
      "name": "Gemma 2 2B",
      "company": "Google",
      "url": "https://blog.google/technology/developers/google-gemma-2/",
      "release_date": "2024-06-27",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 2.614341888,
          "source": "https://huggingface.co/google/gemma-2-2b"
        },
        {
          "name": "Active parameters",
          "score": 2.614341888,
          "source": "https://huggingface.co/google/gemma-2-2b"
        },
        {
          "name": "MMLU",
          "score": 52.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Challenge",
          "score": 55.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "GSM8K",
          "score": 24.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "AGIEval",
          "score": 31.5,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "DROP",
          "score": 51.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BBH",
          "score": 41.9,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "WinoGrande",
          "score": 71.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HellaSwag",
          "score": 72.9,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MATH",
          "score": 16,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Easy",
          "score": 80.6,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "PIQA",
          "score": 78.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "SIQA",
          "score": 51.9,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BoolQ",
          "score": 72.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "TriviaQA",
          "score": 60.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "NaturalQuestions",
          "score": 17.1,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HumanEval",
          "score": 20.1,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MBPP",
          "score": 30.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MT-Bench",
          "score": 7.5,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "Arena-Hard",
          "score": 51.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "WildBench",
          "score": 32.5,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MBPP",
          "score": 54.5,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "HumanEval",
          "score": 42.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MATH",
          "score": 22.8,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MMLU",
          "score": 52.4,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "AGIEval",
          "score": 33.8,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "WinoGrande",
          "score": 68.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "ARC-Challenge",
          "score": 42.6,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "TriviaQA",
          "score": 47.8,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MMLU (fr)",
          "score": 41,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MMLU (de)",
          "score": 40.1,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        },
        {
          "name": "MMLU (es)",
          "score": 41.7,
          "source": "https://huggingface.co/mistralai/Ministral-8B-Instruct-2410"
        }
      ]
    },
    {
      "name": "Gemini 1.5 Pro",
      "company": "Google",
      "url": "https://developers.googleblog.com/en/gemini-15-pro-and-15-flash-now-available/",
      "release_date": "2024-05-30",
      "capabilities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.35,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "Output cost",
          "score": 1.5,
          "source": "https://ai.google.dev/gemini-api/docs/pricing"
        },
        {
          "name": "MMLU-Pro",
          "score": 69,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Natural2Code",
          "score": 82.6,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MATH",
          "score": 67.7,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "HiddenMath",
          "score": 28,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "GPQA",
          "score": 46,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "WMT23",
          "score": 75.3,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MRCR 1M",
          "score": 70.5,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MMMU",
          "score": 62.2,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Vibe-Eval",
          "score": 48.9,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MathVista",
          "score": 63.9,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "FLEURS (55 lang)",
          "score": 6.5,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Video-MME",
          "score": 77.9,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "XSTest",
          "score": 88.4,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        }
      ]
    },
    {
      "name": "Gemini 1.5 Flash",
      "company": "Google",
      "url": "https://developers.googleblog.com/en/gemini-15-pro-and-15-flash-now-available/",
      "release_date": "2024-05-30",
      "capabilities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.075,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-updates-google-ai-studio-gemini-api/"
        },
        {
          "name": "Output cost",
          "score": 0.3,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-updates-google-ai-studio-gemini-api/"
        },
        {
          "name": "MMLU-Pro",
          "score": 59.1,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Natural2Code",
          "score": 77.2,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MATH",
          "score": 54.9,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "HiddenMath",
          "score": 20.3,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "GPQA",
          "score": 41.4,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "WMT23",
          "score": 74.1,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MRCR 1M",
          "score": 70.1,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MMMU",
          "score": 56.1,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Vibe-Eval",
          "score": 44.8,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "MathVista",
          "score": 58.4,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "FLEURS (55 lang)",
          "score": 9.8,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "Video-MME",
          "score": 74.7,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        },
        {
          "name": "XSTest",
          "score": 86.9,
          "source": "https://developers.googleblog.com/en/gemini-15-flash-8b-is-now-generally-available-for-use/"
        }
      ]
    },
    {
      "name": "Gemma 1 7B",
      "company": "Google",
      "url": "https://blog.google/technology/developers/gemma-open-models/",
      "release_date": "2024-02-21",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 8.537680896,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "Active parameters",
          "score": 8.537680896,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "MMLU",
          "score": 64.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "HellaSwag",
          "score": 81.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "PIQA",
          "score": 81.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "SocialIQA",
          "score": 51.8,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "BoolQ",
          "score": 83.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "WinoGrande",
          "score": 72.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "CommonSenseQA",
          "score": 71.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "OpenBookQA",
          "score": 52.8,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "ARC-Easy",
          "score": 81.5,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "ARC-Challenge",
          "score": 53.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "TriviaQA",
          "score": 63.4,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "Natural Questions",
          "score": 23,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "HumanEval",
          "score": 32.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "MBPP",
          "score": 44.4,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "GSM8K",
          "score": 46.4,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "MATH",
          "score": 24.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "AGIEval",
          "score": 41.7,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "BIG-Bench",
          "score": 55.1,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "MMLU",
          "score": 64.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Challenge",
          "score": 61.1,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "GSM8K",
          "score": 51.8,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "AGIEval",
          "score": 44.9,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "DROP",
          "score": 56.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BBH",
          "score": 59,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "WinoGrande",
          "score": 79,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HellaSwag",
          "score": 82.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MATH",
          "score": 24.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Easy",
          "score": 81.5,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "PIQA",
          "score": 81.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "SIQA",
          "score": 51.8,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BoolQ",
          "score": 83.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "TriviaQA",
          "score": 63.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "NaturalQuestions",
          "score": 23,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HumanEval",
          "score": 32.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MBPP",
          "score": 44.4,
          "source": "https://arxiv.org/abs/2408.00118"
        }
      ]
    },
    {
      "name": "Gemma 1 2B",
      "company": "Google",
      "url": "https://blog.google/technology/developers/gemma-open-models/",
      "release_date": "2024-02-21",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "benchmarks": [
        {
          "name": "Size",
          "score": 2.506172416,
          "source": "https://huggingface.co/google/gemma-2b-it"
        },
        {
          "name": "Active parameters",
          "score": 2.506172416,
          "source": "https://huggingface.co/google/gemma-2b-it"
        },
        {
          "name": "MMLU",
          "score": 42.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "HellaSwag",
          "score": 71.4,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "PIQA",
          "score": 77.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "SocialIQA",
          "score": 49.7,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "BoolQ",
          "score": 69.4,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "WinoGrande",
          "score": 65.4,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "CommonSenseQA",
          "score": 65.3,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "OpenBookQA",
          "score": 47.8,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "ARC-Easy",
          "score": 73.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "ARC-Challenge",
          "score": 42.1,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "TriviaQA",
          "score": 53.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "Natural Questions",
          "score": 12.5,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "HumanEval",
          "score": 22,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "MBPP",
          "score": 29.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "GSM8K",
          "score": 17.7,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "MATH",
          "score": 11.8,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "AGIEval",
          "score": 24.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "BIG-Bench",
          "score": 35.2,
          "source": "https://huggingface.co/google/gemma-7b-it"
        },
        {
          "name": "MMLU",
          "score": 42.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Challenge",
          "score": 48.5,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "GSM8K",
          "score": 15.1,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "AGIEval",
          "score": 24.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "DROP",
          "score": 48.5,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BBH",
          "score": 35.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "WinoGrande",
          "score": 66.8,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HellaSwag",
          "score": 71.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MATH",
          "score": 11.8,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "ARC-Easy",
          "score": 73.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "PIQA",
          "score": 77.3,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "SIQA",
          "score": 49.7,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "BoolQ",
          "score": 69.4,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "TriviaQA",
          "score": 53.2,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "NaturalQuestions",
          "score": 12.5,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "HumanEval",
          "score": 22,
          "source": "https://arxiv.org/abs/2408.00118"
        },
        {
          "name": "MBPP",
          "score": 29.2,
          "source": "https://arxiv.org/abs/2408.00118"
        }
      ]
    },
    {
      "name": "Gemini 1.0 Ultra",
      "company": "Google",
      "url": "https://blog.google/technology/ai/google-gemini-ai",
      "release_date": "2023-12-06",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "image"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 10,
          "source": "https://www.walturn.com/insights/what-is-gemini-features-pricing-and-use-cases"
        },
        {
          "name": "Output cost",
          "score": 30,
          "source": "https://www.walturn.com/insights/what-is-gemini-features-pricing-and-use-cases"
        },
        {
          "name": "MMLU",
          "score": 83.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "MATH",
          "score": 53.2,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "BIG-Bench Hard",
          "score": 83.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "HumanEval",
          "score": 74.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "Natural2Code",
          "score": 74.9,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "DROP",
          "score": 82.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "HellaSwag",
          "score": 87.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "WMT23",
          "score": 74.4,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "MMLU",
          "score": 83.7,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "GSM8K",
          "score": 94.4,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MATH",
          "score": 53.2,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MGSM",
          "score": 79,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "HumanEval",
          "score": 74.4,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "DROP",
          "score": 82.4,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "BIG-Bench Hard",
          "score": 83.6,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "HellaSwag",
          "score": 87.8,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MMMU",
          "score": 59.4,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "ANLS",
          "score": 90.9,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MathVista",
          "score": 53,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "AI2D",
          "score": 79.5,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "ChartQA",
          "score": 80.8,
          "source": "https://www.anthropic.com/news/claude-3-family"
        }
      ]
    },
    {
      "name": "Gemini 1.0 Pro",
      "company": "Google",
      "url": "https://blog.google/technology/ai/google-gemini-ai",
      "release_date": "2023-12-06",
      "capabilities": {
        "input": [
          "text",
          "image",
          "video",
          "audio"
        ],
        "output": [
          "text",
          "image"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.125,
          "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
        },
        {
          "name": "Output cost",
          "score": 0.375,
          "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing"
        },
        {
          "name": "MMLU",
          "score": 71.8,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "MATH",
          "score": 32.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "BIG-Bench Hard",
          "score": 75,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "HumanEval",
          "score": 67.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "Natural2Code",
          "score": 69.6,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "DROP",
          "score": 74.1,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "HellaSwag",
          "score": 84.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "WMT23",
          "score": 71.7,
          "source": "https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
        },
        {
          "name": "MMLU",
          "score": 71.8,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "GSM8K",
          "score": 86.5,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MATH",
          "score": 32.6,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MGSM",
          "score": 63.5,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "HumanEval",
          "score": 67.7,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "DROP",
          "score": 74.1,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "BIG-Bench Hard",
          "score": 75,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "HellaSwag",
          "score": 84.7,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MMMU",
          "score": 47.9,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "ANLS",
          "score": 88.1,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MathVista",
          "score": 45.2,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "AI2D",
          "score": 73.9,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "ChartQA",
          "score": 74.1,
          "source": "https://www.anthropic.com/news/claude-3-family"
        },
        {
          "name": "MMLU",
          "score": 71.8,
          "source": "https://mistral.ai/news/mistral-large"
        },
        {
          "name": "HellaSwag",
          "score": 84.7,
          "source": "https://mistral.ai/news/mistral-large"
        },
        {
          "name": "TruthfulQA",
          "score": null,
          "source": "https://mistral.ai/news/mistral-large"
        },
        {
          "name": "HumanEval",
          "score": 67.7,
          "source": "https://mistral.ai/news/mistral-large"
        },
        {
          "name": "GSM8K",
          "score": 86.5,
          "source": "https://mistral.ai/news/mistral-large"
        }
      ]
    }
  ]
}
