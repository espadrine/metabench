{
  "models": [
    {
      "name": "DeepSeek V3.2",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news251201",
      "release_date": "2025-12-01",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "thinking",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.28,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Output cost",
          "score": 0.42,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.4,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 25.1,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "LiveCodeBench (thinking)",
          "score": 83.3,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Codeforces",
          "score": 2386,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "AIME 2025",
          "score": 93.1,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 92.5,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "HMMT Nov 2025",
          "score": 90.2,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 78.3,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 46.4,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "SWE-bench Verified",
          "score": 73.1,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "SWE Multilingual",
          "score": 70.2,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "BrowseComp",
          "score": 67.6,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 65,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "τ²-Bench",
          "score": 80.3,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "MCP-Universe",
          "score": 45.9,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "MCP-Mark",
          "score": 38,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Tool-Decathlon",
          "score": 35.2,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "SWE-bench Verified",
          "score": 73.1,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 70.2,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 46.4,
          "source": "https://huggingface.co/mistralai/Devstral-Small-2-24B-Instruct-2512"
        },
        {
          "name": "LMArena Text",
          "score": 1418,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "GPQA Diamond",
          "score": 82.4,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 25.1,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 40.8,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "AIME 2025",
          "score": 93.1,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 92.5,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "HMMT Nov 2025",
          "score": 90.2,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 78.3,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "LiveCodeBench",
          "score": 83.3,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "SWE-bench Verified",
          "score": 73.1,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 70.2,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 35.4,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 46.4,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "BrowseComp",
          "score": 51.4,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 65,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "τ²-Bench",
          "score": 85.3,
          "source": "https://z.ai/blog/glm-4.7"
        },
        {
          "name": "SWE-bench Verified",
          "score": 73.1,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "SWT-bench",
          "score": 62,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "SWE-Perf",
          "score": 0.9,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "SWE-Review",
          "score": 6.4,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "OctoCodingbench",
          "score": 26,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "VIBE",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "VIBE-Web",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "VIBE-Simulation",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "VIBE-Android",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "VIBE-iOS",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "VIBE-Backend",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "Toolathlon",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "BrowseComp",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "AIME 2025",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "MMLU-Pro",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "GPQA Diamond",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "LiveCodeBench",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "SciCode",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "IFBench",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "LCR",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 92,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 37.4,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 70.2,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 46.4,
          "source": "https://www.minimax.io/news/minimax-m21"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 41.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 36.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 92,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 86.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 84,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 22.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 86.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 38.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 92,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 60.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 65,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 35.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 90.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 25.1,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 40.8,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "AIME 2025",
          "score": 93.1,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 78.3,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "GPQA-Diamond",
          "score": 82.4,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "SWE-Bench Verified",
          "score": 73.1,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "SWE-Bench Multilingual",
          "score": 70.2,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "Terminal-Bench 2.0",
          "score": 46.4,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "PaperBench",
          "score": 47.1,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "CyberGym",
          "score": 17.3,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "SciCode",
          "score": 38.9,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "OJBench",
          "score": 54.7,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "LiveCodeBench",
          "score": 83.3,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "Longbench v2",
          "score": 59.8,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "AA-LCR",
          "score": 64.3,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "BrowseComp",
          "score": 51.4,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "BrowseComp",
          "score": 67.6,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "WideSearch",
          "score": 32.5,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "DeepSearchQA",
          "score": 60.9,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "FinSearchComp-global",
          "score": 59.1,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "Seal-0",
          "score": 49.5,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        },
        {
          "name": "WebArena",
          "score": 26.4,
          "source": "https://www.kimi.com/blog/kimi-k2-5.html"
        }
      ]
    },
    {
      "name": "DeepSeek V3.2 Speciale",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news251201",
      "release_date": "2025-12-01",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "thinking",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.28,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Output cost",
          "score": 0.42,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "AIME 2025",
          "score": 96,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 99.2,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "HMMT Nov 2025",
          "score": 90.2,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 84.5,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "LiveCodeBench (thinking)",
          "score": 88.7,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Codeforces",
          "score": 2701,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "GPQA Diamond",
          "score": 85.7,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 30.6,
          "source": "https://api-docs.deepseek.com/news/news251201"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 34.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 37.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 96.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 86.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 87.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 26.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 89.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 44,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 96.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 63.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 59.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 34.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "DeepSeek V3.2 Exp",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250929",
      "release_date": "2025-09-29",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "thinking",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.28,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Output cost",
          "score": 0.42,
          "source": "https://api-docs.deepseek.com/news/news250929"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 62,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 67.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 30.6,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 57.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench",
          "score": 37.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "ArtifactsBench",
          "score": 55.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp",
          "score": 40.1,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 47.9,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GAIA (text)",
          "score": 63.5,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "xbench-DeepSearch",
          "score": 71,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (with tools)",
          "score": 27.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench",
          "score": 66.7,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "FinSearchComp-global",
          "score": 26.2,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AgentCompany",
          "score": 34,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "AIME 2025",
          "score": 88,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "GPQA Diamond",
          "score": 80,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.8,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LiveCodeBench",
          "score": 79,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "SciCode",
          "score": 38,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "IFBench",
          "score": 54,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "LCR",
          "score": 69,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "τ²-Bench Telecom",
          "score": 34,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 29,
          "source": "https://huggingface.co/MiniMaxAI/MiniMax-M2"
        },
        {
          "name": "Humanity's Last Exam (text)",
          "score": 19.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Humanity's Last Exam (text) (with tools)",
          "score": 20.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025",
          "score": 89.3,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "AIME 2025 (with tools)",
          "score": 58.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 83.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HMMT Feb 2025 (with tools)",
          "score": 49.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "IMO-AnswerBench",
          "score": 76,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA Diamond",
          "score": 79.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "MMLU-Redux",
          "score": 93.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Longform Writing",
          "score": 72.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "HealthBench",
          "score": 46.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp",
          "score": 40.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "BrowseComp (zh)",
          "score": 47.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Seal-0",
          "score": 38.5,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FinSearchComp-T3",
          "score": 27,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "FRAMES",
          "score": 80.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Verified (with tools)",
          "score": 67.8,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SWE-bench Multilingual (with tools)",
          "score": 57.9,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Multi-SWE-bench (with tools)",
          "score": 30.6,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "SciCode",
          "score": 37.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "LiveCodeBench",
          "score": 74.1,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "OJ-Bench",
          "score": 38.2,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "Terminal-Bench",
          "score": 37.7,
          "source": "https://moonshotai.github.io/Kimi-K2/thinking.html"
        },
        {
          "name": "GPQA",
          "score": 79.9,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "LMArena Text",
          "score": 1423,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 32.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 33.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 87.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 79.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 78.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 37.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 87.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 54.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 69,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 31.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 33.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "DeepSeek V3.1",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250821",
      "release_date": "2025-08-21",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "thinking",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.56,
          "source": "https://api-docs.deepseek.com/news/news250821"
        },
        {
          "name": "Output cost",
          "score": 1.68,
          "source": "https://api-docs.deepseek.com/news/news250821"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3.1"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 63,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "SWE-bench Verified",
          "score": 66,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 54.5,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Multi-SWE-bench",
          "score": 29,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "Terminal-Bench",
          "score": 31.3,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "SWE-Dev",
          "score": 53.3,
          "source": "https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905"
        },
        {
          "name": "GPQA",
          "score": 74.9,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "LMArena Text",
          "score": 1417,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "HumanEval",
          "score": 93.3,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 42.9,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "MultiPL-E",
          "score": 84.9,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "Arena-Hard",
          "score": 97.3,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "IFEval",
          "score": 89.1,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "MATH",
          "score": 93.8,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "GPQA Diamond",
          "score": 61.1,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "MMLU-Pro",
          "score": 81.1,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "RULER 32K",
          "score": 95.8,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "RULER 128K",
          "score": 91.9,
          "source": "https://mistral.ai/news/mistral-medium-3"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 27.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 29.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 89.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 85.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 77.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 13,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 78.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 39.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 89.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 41.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 53.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 25,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 37.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "DeepSeek-V3-0324",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250325",
      "release_date": "2025-03-24",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.27,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Output cost",
          "score": 1.1,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 11,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "AIME 2025",
          "score": 39.2,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "GPQA",
          "score": 59.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "LiveCodeBench",
          "score": 33.1,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "MMLU-Pro",
          "score": 75.9,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "SimpleQA",
          "score": 24.9,
          "source": "https://x.ai/news/grok-3"
        },
        {
          "name": "DROP",
          "score": 91.6,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "LMArena Text",
          "score": 1394,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "Terminal-Bench",
          "score": 2.5,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "SWE-bench Verified",
          "score": 38.8,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "SWE-bench Live",
          "score": 13,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "SWE-bench Multilingual",
          "score": 13,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "Multi-SWE-bench mini",
          "score": 7.5,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "Aider",
          "score": 56.9,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "Spider2",
          "score": 17.7,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "WebArena",
          "score": 40,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "Mind2Web",
          "score": 36,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "BFCL v3",
          "score": 64.7,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "τ-Bench Retail",
          "score": 59.1,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "τ-Bench Airline",
          "score": 40,
          "source": "https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 21.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 22,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 41,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 81.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 65.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 40.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 35.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 94.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 52,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 41,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 41,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 41,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 15.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 47.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "DeepSeek R1 0528",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250528",
      "release_date": "2025-05-28",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "thinking",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.55,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Output cost",
          "score": 2.19,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 99,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "MMLU-Redux",
          "score": 93.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "MMLU-Pro",
          "score": 85,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 81,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SimpleQA",
          "score": 27.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "FRAMES",
          "score": 83,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 17.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 73.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Codeforces",
          "score": 1930,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SWE-bench Verified",
          "score": 57.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 71.6,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2024",
          "score": 91.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 87.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 79.4,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "CNMO 2024",
          "score": 86.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "GPQA Diamond",
          "score": 81,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "AIME 2025",
          "score": 87.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "LiveCodeBench",
          "score": 70.5,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Aider",
          "score": 71.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SWE-bench Verified",
          "score": 57.6,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "SimpleQA",
          "score": 27.8,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "FACTS Grounding",
          "score": 82.4,
          "source": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Pro-Model-Card.pdf"
        },
        {
          "name": "Terminal-Bench",
          "score": 17.5
        },
        {
          "name": "GPQA",
          "score": 81,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "LMArena Text",
          "score": 1418,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 27,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 24,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 76,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 84.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 81.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 14.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 77,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 40.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 98.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 89.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 76,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 39.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 54.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 15.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 36.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "DeepSeek R1",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250120",
      "release_date": "2025-01-20",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "thinking",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.55,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Output cost",
          "score": 2.19,
          "source": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 72,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "Aider",
          "score": 56.9
        },
        {
          "name": "MMLU-Redux",
          "score": 92.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "MMLU-Pro",
          "score": 84,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 71.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SimpleQA",
          "score": 30.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "FRAMES",
          "score": 82.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 8.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 63.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Codeforces",
          "score": 1530,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "SWE-bench Verified",
          "score": 49.2,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "Aider",
          "score": 53.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2024",
          "score": 79.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 70,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 41.7,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "CNMO 2024",
          "score": 78.8,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "BFCL v3 MultiTurn",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "τ-Bench Airline",
          "score": 53.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "τ-Bench Retail",
          "score": 63.9,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA",
          "score": 73.3,
          "source": "https://llm-stats.com/benchmarks"
        },
        {
          "name": "LMArena Text",
          "score": 1397,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 18.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 15.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 68,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 84.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 70.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 9.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 61.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 35.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 96.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 68.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 68,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 39,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 52.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 6.1,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 11.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "DeepSeek-R1-0528-Qwen3-8B",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news250528",
      "release_date": "2025-01-20",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "thinking",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.18,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Output cost",
          "score": 2.1,
          "source": "https://www.alibabacloud.com/help/en/model-studio/models"
        },
        {
          "name": "Size",
          "score": 8.19073536,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
        },
        {
          "name": "Active parameters",
          "score": 8.19073536,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 94,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "AIME 2024",
          "score": 86,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "AIME 2025",
          "score": 76.3,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "HMMT Feb 2025",
          "score": 61.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "GPQA Diamond",
          "score": 61.1,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "LiveCodeBench",
          "score": 60.5,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 16.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 7.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 63.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 73.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 61.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 5.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 51.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 20.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 93.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 65,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 63.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 19.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 13,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 1.5,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    },
    {
      "name": "DeepSeek V3",
      "company": "DeepSeek",
      "url": "https://api-docs.deepseek.com/news/news1226",
      "release_date": "2024-12-26",
      "capabilities": {
        "input": [
          "text"
        ],
        "output": [
          "text",
          "tool"
        ]
      },
      "benchmarks": [
        {
          "name": "Input cost",
          "score": 0.27,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Output cost",
          "score": 1.1,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Size",
          "score": 684.531386,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"
        },
        {
          "name": "Active parameters",
          "score": 37,
          "source": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324"
        },
        {
          "name": "ArtificialAnalysis Consumed Tokens (Millions)",
          "score": 62,
          "source": "https://artificialanalysis.ai/"
        },
        {
          "name": "MMLU",
          "score": 88.5,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "MMLU-Redux",
          "score": 89.1,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "MMLU-Pro",
          "score": 75.9,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "DROP",
          "score": 91.6,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "IFEval",
          "score": 86.1,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "GPQA Diamond",
          "score": 59.1,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "SimpleQA",
          "score": 24.9,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "FRAMES",
          "score": 73.3,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "LongBench v2",
          "score": 48.7,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "HumanEval-Mul",
          "score": 82.6,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "LiveCodeBench (thinking)",
          "score": 40.5,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "LiveCodeBench",
          "score": 37.6,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Codeforces percentile",
          "score": 51.6,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "SWE-bench Verified",
          "score": 42,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Aider-Edit",
          "score": 79.7,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Aider",
          "score": 49.6,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "AIME 2024",
          "score": 39.2,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "MATH",
          "score": 90.2,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "CNMO 2024",
          "score": 43.2,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "CLUEWSC",
          "score": 90.9,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "Eval Chinese",
          "score": 86.5,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "SimpleQA Chinese",
          "score": 64.1,
          "source": "https://api-docs.deepseek.com/news/news1226"
        },
        {
          "name": "LMArena Text",
          "score": 1358,
          "source": "https://lmarena.ai/"
        },
        {
          "name": "ArtificialAnalysis Intelligence Index",
          "score": 16.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Coding Index",
          "score": 16.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "ArtificialAnalysis Math Index",
          "score": 26,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MMLU-Pro",
          "score": 75.2,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "GPQA Diamond",
          "score": 55.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Humanity's Last Exam",
          "score": 3.6,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LiveCodeBench",
          "score": 35.9,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "SciCode",
          "score": 35.4,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "MATH",
          "score": 88.7,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2024",
          "score": 25.3,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "AIME 2025",
          "score": 26,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "IFBench",
          "score": 34.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "LCR",
          "score": 29,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "Terminal-Bench-Hard",
          "score": 6.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        },
        {
          "name": "τ²-Bench",
          "score": 22.8,
          "source": "https://artificialanalysis.ai/api/v2/data/llms/models"
        }
      ]
    }
  ]
}